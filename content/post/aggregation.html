---
title: "What's wrong with aggregating data?"
author: ~
date: "2019-03-04"
bibliography: [_bib.bib]
slug: aggregating
categories: ["rstats"]
tags: ["r", "lmer", "mixed effects", "anova", "aggregation", "simulation"]
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p class="info">
<a href="http://shiny.psy.gla.ac.uk/debruine/anova_vs_lmer/">Shiny app</a> for a face-rating example.
</p>
<pre class="r"><code>library(tidyverse)
library(lmerTest)
set.seed(90210)</code></pre>
<p>Imagine you want to find out if Armenian women born on an even-numbered day are taller than women born on an odd-numbered day. (I’ve chosen Armenian women because they’re the first row in <a href="https://doi.org/10.1371/journal.pone.0018962">this paper</a>.)</p>
<p>First, let’s simulate a group of 20 women born on even-numbered days and 20 women born on odd-numbered days.</p>
<pre class="r"><code>stim_n &lt;- 20
# height stats from https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018962
height_m &lt;- 158.1
height_sd &lt;- 5.7

stim &lt;- tibble(
  stim_id = 1:(stim_n*2),
  birthday = rep(c(&quot;odd&quot;, &quot;even&quot;), stim_n),
  height = rnorm(stim_n*2, height_m, height_sd)
)</code></pre>
<p><img src="/post/aggregation_files/figure-html/unnamed-chunk-3-1.png" width="100%" /></p>
<p>Obviously, the oddness of date of birth is not going to have any effect on women’s actual height and a two-sample t-test confirms this. However, there is a small difference between the means of the groups just due to chance (2.81 cm).</p>
<pre class="r"><code>t.test(stim$height ~ stim$birthday)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  stim$height by stim$birthday
## t = -1.5, df = 38, p-value = 0.1
## alternative hypothesis: true difference in means between group even and group odd is not equal to 0
## 95 percent confidence interval:
##  -6.4997  0.8767
## sample estimates:
## mean in group even  mean in group odd 
##              154.9              157.7</code></pre>
<div id="measurement-with-error" class="section level3">
<h3>Measurement with Error</h3>
<p>But what if we don’t measure height from each women once, but have a few different raters estimate it? The raters will each have their own bias, systematically overestimating or underestimating height on average. Let’s simulate 20 raters who have biases with an SD of 2 cm.</p>
<pre class="r"><code>rater_n &lt;- 20
rater_bias_sd &lt;- 2

rater &lt;- tibble(
  rater_id = 1:rater_n,
  rater_bias = rnorm(rater_n, 0, rater_bias_sd)
)</code></pre>
<p><img src="/post/aggregation_files/figure-html/unnamed-chunk-6-1.png" width="100%" /></p>
<p>New we can get each rater to estimate the height of each woman. Their estimate is the woman’s actual height, plus the rater’s bias, plus some error (sampled from a normal distribution with a mean of 0 and an SD of 4 cm, since estimating height is hard).</p>
<pre class="r"><code>dat &lt;- expand.grid(
  rater_id = rater$rater_id,
  stim_id = stim$stim_id
) %&gt;%
  left_join(rater, by = &quot;rater_id&quot;) %&gt;%
  left_join(stim, by = &quot;stim_id&quot;) %&gt;%
  mutate(
    error = rnorm(nrow(.), 0, 4),
    estimate = height + rater_bias + error
  )</code></pre>
</div>
<div id="aggregating-by-stimuli" class="section level3">
<h3>Aggregating by Stimuli</h3>
<p>You can aggregate by stimuli, that is, average the 20 raters’ estimate for each stimulus. You now have 40 mean estimates that are fairly well-correlated with the women’s actual heights.</p>
<pre class="r"><code>dat_agg_by_stim &lt;- dat %&gt;%
  group_by(stim_id, birthday, height) %&gt;%
  summarise(mean_estimate = mean(estimate))</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;stim_id&#39;, &#39;birthday&#39;. You can override using the `.groups` argument.</code></pre>
<p><img src="/post/aggregation_files/figure-html/unnamed-chunk-9-1.png" width="100%" /></p>
<p>You get pretty much the same result when you compare these mean estimates between the groups of women with odd and even birthdays.</p>
<pre class="r"><code>t.test(dat_agg_by_stim$mean_estimate ~ dat_agg_by_stim$birthday)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  dat_agg_by_stim$mean_estimate by dat_agg_by_stim$birthday
## t = -1.4, df = 38, p-value = 0.2
## alternative hypothesis: true difference in means between group even and group odd is not equal to 0
## 95 percent confidence interval:
##  -6.473  1.130
## sample estimates:
## mean in group even  mean in group odd 
##              155.2              157.9</code></pre>
</div>
<div id="aggregating-by-raters" class="section level3">
<h3>Aggregating by Raters</h3>
<p>Alternatively, you can aggregate by raters, that is, average the 20 odd-group estimates and 20 even-group estimates for each rater. Now raters are your unit of analysis, so you’ve increased your power by having 20 raters and a within-subject design (each rater estimates heights for both odd- and even-birthday groups).</p>
<pre class="r"><code>dat_agg_by_rater &lt;- dat %&gt;%
  group_by(rater_id, birthday) %&gt;%
  summarise(mean_estimate = mean(estimate)) %&gt;%
  spread(birthday, mean_estimate)</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rater_id&#39;. You can override using the `.groups` argument.</code></pre>
<pre class="r"><code>t.test(dat_agg_by_rater$odd, dat_agg_by_rater$even, paired = TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  dat_agg_by_rater$odd and dat_agg_by_rater$even
## t = 11, df = 19, p-value = 0.000000002
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  2.145 3.198
## sample estimates:
## mean of the differences 
##                   2.672</code></pre>
<p>Now the difference between the odd- and even-birthday groups is highly significant! What’s going is that you now have a relatively accurate estimate of the chance mean difference between the 20 women in the odd-birthday group and the 20 women in the even-birthday group. Since raters are the unit of analysis, this effect is likely to generalise to the larger population of potential raters, but only when they are rating <strong>these exact stimuli</strong>. Your conclusions cannot generalise beyond the stimulus set used here.</p>
<p>While this seems like an obvious problem when the question is whether Armenian women with odd birthdays are taller or shorter than Armenian women with even birthdays, the problem is not so obvious for other questions, like whether boxers who won their last match have more masculine faces than boxers who lost their last match. The point of this tutorial isn’t to call out any particular studies (I’ve certainly done this wrong myself plenty of times in the past), but to illustrate the enormous problem with this method and to explain the solution.</p>
<p>The larger the number of raters, the larger this false positive problem becomes because you’re increasing power to detect the small chance diffference between the two groups. You can play around with how changing parameters changes the power and false positive rates for by-stimulus, by-rater, and mixed effect designs at <a href="http://shiny.psy.gla.ac.uk/debruine/anova_vs_lmer/">this shiny app</a>.</p>
</div>
<div id="mixed-effect-model" class="section level3">
<h3>Mixed Effect Model</h3>
<p>In the particular case above, we’re only interested in the between-stimulus (and within-rater) main effect of birthday oddness. Therefore, aggregating by stimuli doesn’t inflate your false positive rate, while aggregating by rater does. However, other designs might have increased false positives for aggregating by stimuli but not by rater, or when aggregating by either.</p>
<p>A mixed effects model avoids the problems of aggregation completely by modelling random variation for both the stimuli and raters, as well as random variation in the size of within-group effects.</p>
<p class="info">
I <a href="https://debruine.github.io/posts/coding-schemes/">effect code</a> the <code>birthday</code> variable to make interpretation of the effects easier).
</p>
<pre class="r"><code># effect-code birthday
dat$birthday.e &lt;- recode(dat$birthday, &quot;odd&quot; = 0.5, &quot;even&quot; = -0.5)

mod &lt;- lmer(estimate ~ birthday.e +
              # random slope for effect of birthday, random intercept for rater bias
              (1 + birthday.e || rater_id) + 
              # random intercept for variation in stim height
              (1 | stim_id), 
            data = dat)

summary(mod)</code></pre>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: estimate ~ birthday.e + (1 + birthday.e || rater_id) + (1 | stim_id)
##    Data: dat
## 
## REML criterion at convergence: 4687
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.8414 -0.6590  0.0102  0.6776  2.6231 
## 
## Random effects:
##  Groups     Name        Variance      Std.Dev.
##  stim_id    (Intercept) 34.4640965341 5.870613
##  rater_id   birthday.e   0.0000000214 0.000146
##  rater_id.1 (Intercept) 10.0890113704 3.176320
##  Residual               15.8201186615 3.977451
## Number of obs: 800, groups:  stim_id, 40; rater_id, 20
## 
## Fixed effects:
##             Estimate Std. Error     df t value Pr(&gt;|t|)    
## (Intercept)   156.55       1.18  55.02  132.98   &lt;2e-16 ***
## birthday.e      2.67       1.88  38.00    1.42     0.16    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##            (Intr)
## birthday.e 0.000 
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see ?isSingular</code></pre>
<p>The estimate for <code>(Intercept)</code> is just the mean height estimate (156.55 cm) and the estimate for <code>birthday.e</code> is the mean difference between the odd and even birthday groups (2.67 cm). You can now generalise the conclusions of this mixed effects model to both the population of raters and the population of stimuli.</p>
<p class="info">
Thanks to <a href="https://twitter.com/lpsatchell">Liam Satchell</a>, <a href="https://twitter.com/AlexJonesPhD">Alex Jones</a>, and <a href="https://twitter.com/Ben_C_J">Ben Jones</a> for the stimulating late-night Twitter discussion that prompted this blog post!
</p>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<p>Plenty of papers have made this point much more thoroughly <span class="citation"><a href="#ref-Wolsiefer2017" role="doc-biblioref">Wolsiefer, Westfall, and Judd</a> (<a href="#ref-Wolsiefer2017" role="doc-biblioref">2017</a>)</span>.</p>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-KeepItMaximal" class="csl-entry">
Barr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. <span>“Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.”</span> <em>Journal of Memory and Language</em> 68 (3): 10.1016/j.jml.2012.11.001.
</div>
<div id="ref-Coleman1964" class="csl-entry">
Coleman, E. B. 1964. <span>“Generalizing to a Language Population.”</span> <em>Psychological Reports</em> 14 (1): 219–26. <a href="https://doi.org/10.2466/pr0.1964.14.1.219">https://doi.org/10.2466/pr0.1964.14.1.219</a>.
</div>
<div id="ref-Judd2012" class="csl-entry">
Judd, Charles M., Jacob Westfall, and David A. Kenny. 2012. <span>“Treating Stimuli as a Random Factor in Social Psychology: A New and Comprehensive Solution to a Pervasive but Largely Ignored Problem.”</span> <em>Journal of Personality and Social Psychology</em> 103 (1): 54–69. <a href="https://doi.org/doi:10.1037/a0028347">https://doi.org/doi:10.1037/a0028347</a>.
</div>
<div id="ref-Wolsiefer2017" class="csl-entry">
Wolsiefer, Katie, Jacob Westfall, and Charles M. Judd. 2017. <span>“Modeling Stimulus Variation in Three Common Implicit Attitude Tasks.”</span> <em>Behavior Research Methods</em> 49 (4): 1193–1209. <a href="https://doi.org/10.3758/s13428-016-0779-0">https://doi.org/10.3758/s13428-016-0779-0</a>.
</div>
</div>
</div>
