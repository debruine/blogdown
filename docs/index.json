[{"authors":null,"categories":null,"content":"Lisa DeBruine is a professor of psychology at the University of Glasgow School of Psychology and Neuroscience. She is a founding member and current Associate Director of the Psychological Science Accelerator and a member of the psyTeachR team.\n","date":1634659200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1634659200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://debruine.github.io/author/lisa-debruine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lisa-debruine/","section":"authors","summary":"Lisa DeBruine is a professor of psychology at the University of Glasgow School of Psychology and Neuroscience. She is a founding member and current Associate Director of the Psychological Science Accelerator and a member of the psyTeachR team.","tags":null,"title":"Lisa DeBruine","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor Lisa DeBruine FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://debruine.github.io/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, 'Hello world']  Tuples\n Tuples are immutable - they can\u0026rsquo;t be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, 'Hello world')   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://debruine.github.io/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026quot;country == 'Canada'\u0026quot;) fig = px.bar(data_canada, x='year', y='pop') fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://debruine.github.io/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://debruine.github.io/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":["Lisa DeBruine"],"categories":null,"content":"","date":1634659200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634659200,"objectID":"82eeb0fce88c66e45549001e557ffb47","permalink":"https://debruine.github.io/talk/everything-is-cool-when-youre-part-of-a-team/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/talk/everything-is-cool-when-youre-part-of-a-team/","section":"event","summary":"How large-scale collaborations such as the Psychological Science Accelerator can improve both replicability and generalisability.","tags":["PSA","team science"],"title":"Everything is cool when you're part of a team","type":"event"},{"authors":["Lisa DeBruine","Dale Barr","Phil McAleer","Emily Nordmann"],"categories":null,"content":"","date":1634648400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634648400,"objectID":"0b005b2c205a4fe57722ea1b8c291f45","permalink":"https://debruine.github.io/talk/open-science-practices-in-the-school-of-psychology-and-neuroscience/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/talk/open-science-practices-in-the-school-of-psychology-and-neuroscience/","section":"event","summary":"Open science practices in the University of Glasgow's School of Psychology and Neuroscience","tags":["open science"],"title":"Open Science Practices in the School of Psychology and Neuroscience","type":"event"},{"authors":null,"categories":null,"content":"   I saw this a few days ago and sympathised, because I‚Äôve often wanted to use data that is trapped in images or PDFs. If it‚Äôs not too much, I‚Äôll manually transcribe it, but that‚Äôs so tedious!\ncrucial data being published as images ‚Ä¶ üò≠üò≠üò≠üò≠ https://t.co/9CKg9NhYtA ‚Äî Shel üá∞üá™ (@Shel_Kariuki) October 15, 2021   A tweet by Abiyu Giday reminded me that the magick package has OCR (optical character recognition), so I decided to try it out.\nlibrary(magick) # for image processing library(tesseract) # for OCR image reading library(dplyr) # for data wrangling and pipes library(tidyr) # for data wrangling library(stringr) # for string manipulation library(ggplot2) # for plots First, you need to read in the image and convert it to text using two functions from the magick package.\nI use ImageMagick for webmorph development, so had it installed previously. I‚Äôm not sure if installing the R package also sets up the ImageMagick installation. If you‚Äôre on a Windows machine, the easiest way is to use installr::install.imagemagick(). On a Mac, you can install it with Homebrew using brew install imagemagick@6.\nNow You can read in the image with image_read() and run OCR on it with image_ocr(). If you haven‚Äôt installed the tesseract package yet, the second function will prompt you to.\n# original image source: # https://pbs.twimg.com/media/FBv8P8XXEBgCBvS?format=jpg\u0026amp;name=medium imgtext \u0026lt;- magick::image_read(\u0026quot;data_image.jpg\u0026quot;) %\u0026gt;% magick::image_ocr() The result is a single character string that looks like this, so we‚Äôre going to need to do quite a bit of processing to get it into a tabular format.\n rs COUNTY VACCINES AL | 1. Nairobi 957,147 (31.4%) 25. Homa Bay 33,290 (5.5%) 2. Kiambu 298,723 (18.4%) 26. Migori 32,670 (5.9%) 3. Nakuru 170,684 (13.4%) 27. Kilifi 31,611 (4.0%) 4. Nyeri 134,166 (26.3%) 28. Kisii 30,204 (4.3%) 5. Murang‚Äôa 110,825 (16.4%) 29. Nyamira 29,142 (8.5%) 6. Machakos 100,671 (11.1%) 30. Busia 26,792 (5.8%) 7. Uasin Gishu 92,142 (13.3%) 31. Vihiga 25,172 (7.6%) 8. Kisumu 90,495 (13.8%) 32. Tharaka Nithi 24,386 (9.9%) 9. Mombasa 82,814 (10.3%) 33. Baringo 21,176 (6.2%) 10. Kirinyaga 81,233 (19.6%) 34. Bomet 20,885 (4.5%) ll. Kajiado 75,960 (11.5%) 35. Elgeyo Marakwet 17,574 (7.2%) 12. Bungoma 66,688 (7.9%) 36. Kwale 17,185 (3.8%) 13. Meru 66,270 (7.0%) 37. Narok 15,410 (2.8%) 14. Kakamega 62,043 (6.3%) 38. Turkana 9,249 (2.0%) 15. Nyandarua 60,574 (16.1%) 39. West Pokot 8,207 (2.9%) 16. Laikipia 58,141 (19.0%) 40. Garissa 7,694 (1.9%) 17. Makueni 57,435 (9.8%) 41. Samburu 6,686 (4.6%) 18. Embu 56,082 (14.2%) 42. Mandera 6,220 (1.8%) 19. Trans Nzoia 45,228 (8.7%) 43. Isiolo 5,653 (4.2%) 20. Kitui 40,663 (6.5%) 44. Wajir 5,003 (1.5%) 21. Kericho 38,497 (7.6%) 45. Lamu 4,692 (5.6%) 22. Siaya 38,313 (7.1%) 46. Tana River 3,440 (2.3%) 23. Nandi 38,243 (7.8%) 47. Marsabit 2,953 ( 1.3%) 24. Taita Taveta 34,478 (16.2%)  First, I‚Äôll get rid of the first three lines.\nYou need to put two backslashes before the \\\\| to mark it as a literal |, since | has a special meaning in regular expressions (it means ‚Äúor‚Äù). This is called escaping the character. The combination \\n represents a line break.\ntrimmed \u0026lt;- gsub(\u0026quot;rs\\nCOUNTY VACCINES AL \\\\|\\n\\n\u0026quot;, \u0026quot;\u0026quot;, imgtext) trimmed ## [1] \u0026quot;1. Nairobi 957,147 (31.4%) 25. Homa Bay 33,290 (5.5%)\\n2. Kiambu 298,723 (18.4%) 26. Migori 32,670 (5.9%)\\n3. Nakuru 170,684 (13.4%) 27. Kilifi 31,611 (4.0%)\\n4. Nyeri 134,166 (26.3%) 28. Kisii 30,204 (4.3%)\\n5. Murang‚Äôa 110,825 (16.4%) 29. Nyamira 29,142 (8.5%)\\n6. Machakos 100,671 (11.1%) 30. Busia 26,792 (5.8%)\\n7. Uasin Gishu 92,142 (13.3%) 31. Vihiga 25,172 (7.6%)\\n8. Kisumu 90,495 (13.8%) 32. Tharaka Nithi 24,386 (9.9%)\\n9. Mombasa 82,814 (10.3%) 33. Baringo 21,176 (6.2%)\\n10. Kirinyaga 81,233 (19.6%) 34. Bomet 20,885 (4.5%)\\nll. Kajiado 75,960 (11.5%) 35. Elgeyo Marakwet 17,574 (7.2%)\\n12. Bungoma 66,688 (7.9%) 36. Kwale 17,185 (3.8%)\\n13. Meru 66,270 (7.0%) 37. Narok 15,410 (2.8%)\\n14. Kakamega 62,043 (6.3%) 38. Turkana 9,249 (2.0%)\\n15. Nyandarua 60,574 (16.1%) 39. West Pokot 8,207 (2.9%)\\n16. Laikipia 58,141 (19.0%) 40. Garissa 7,694 (1.9%)\\n17. Makueni 57,435 (9.8%) 41. Samburu 6,686 (4.6%)\\n18. Embu 56,082 (14.2%) 42. Mandera 6,220 (1.8%)\\n19. Trans Nzoia 45,228 (8.7%) 43. Isiolo 5,653 (4.2%)\\n20. Kitui 40,663 (6.5%) 44. Wajir 5,003 (1.5%)\\n21. Kericho 38,497 (7.6%) 45. Lamu 4,692 (5.6%)\\n22. Siaya 38,313 (7.1%) 46. Tana River 3,440 (2.3%)\\n23. Nandi 38,243 (7.8%) 47. Marsabit 2,953 ( 1.3%)\\n24. Taita Taveta 34,478 (16.2%)\\n\u0026quot; Since there are two rows of data on each row, I‚Äôll convert all of the line breaks (\\n) into spaces and then split the result wherever there is 0 or 1 spaces (?), followed by 1 or more digits ([0-9]+), followed by a full stop and a space (\\\\.).\nsplit_base \u0026lt;- gsub(\u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, trimmed) %\u0026gt;% strsplit(\u0026quot; ?[0-9]+\\\\. \u0026quot;) If you prefer stringr functions to base functions, you can do it this way:\nsplit_stringr \u0026lt;- trimmed %\u0026gt;% stringr::str_replace(\u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;) %\u0026gt;% stringr::str_split(\u0026quot; ?s[0-9]+\\\\. \u0026quot;) Make sure you look through all of your data at this point. The first time I did this, I didn‚Äôt notice that 11. got read in as ll., so line 21 didn‚Äôt split.\nsplit_base[[1]][21] ## [1] \u0026quot;Bomet 20,885 (4.5%) ll. Kajiado 75,960 (11.5%)\u0026quot; You can fix that by replacing ll. with 11. before you split the data.\nsplit_base \u0026lt;- trimmed %\u0026gt;% gsub(\u0026quot;ll. \u0026quot;, \u0026quot;11. \u0026quot;, .) %\u0026gt;% gsub(\u0026quot;\\n\u0026quot;, \u0026quot; \u0026quot;, .) %\u0026gt;% strsplit(\u0026quot; ?[0-9]+\\\\. \u0026quot;) Now we need to get this into a tabular format. The objects split_base and split_stringr are 1-item lists where the first item contains the vector of our rows. The first row is blank (the content before the first split at 1.) so we have to omit that. The code below creates a data frame.\ndata1 \u0026lt;- data.frame(x = split_base[[1]][-1])    x      Nairobi 957,147 (31.4%)    Homa Bay 33,290 (5.5%)    Kiambu 298,723 (18.4%)    Migori 32,670 (5.9%)    Nakuru 170,684 (13.4%)    Kilifi 31,611 (4.0%)     Now we have to separate the columns out. There are several ways to do this. Using gsub() to create new columns by replacing parts of the original column is a straightforward way (HT Tan Ho).\nCreate the county column by replacing all characters from the space before the first digit ([0-9]) plus any characters after that (.*) until the end of the string ($). Create the number column by replacing from the start of the string (^) plus any non-numbers ([^0-9]+) that follow it.\ndata2 \u0026lt;- data1 %\u0026gt;% mutate(county = gsub(\u0026quot; [0-9].*$\u0026quot;, \u0026quot;\u0026quot;, x), number = gsub(\u0026quot;^[^0-9]+\u0026quot;, \u0026quot;\u0026quot;, x))   x  county  number      Nairobi 957,147 (31.4%)  Nairobi  957,147 (31.4%)    Homa Bay 33,290 (5.5%)  Homa Bay  33,290 (5.5%)    Kiambu 298,723 (18.4%)  Kiambu  298,723 (18.4%)    Migori 32,670 (5.9%)  Migori  32,670 (5.9%)    Nakuru 170,684 (13.4%)  Nakuru  170,684 (13.4%)    Kilifi 31,611 (4.0%)  Kilifi  31,611 (4.0%)     The county column looks fine, but the number column needs to be split into the number of vaccinations and the percent. Use the separate() function to split this column on the left parenthesis (remember to escape the parenthesis).\ndata3 \u0026lt;- data2 %\u0026gt;% separate(col = number, into = c(\u0026quot;number\u0026quot;, \u0026quot;percent\u0026quot;), sep = \u0026quot;\\\\(\u0026quot;, extra = \u0026quot;drop\u0026quot;)    x  county  number  percent      Nairobi 957,147 (31.4%)  Nairobi  957,147  31.4%)    Homa Bay 33,290 (5.5%)  Homa Bay  33,290  5.5%)    Kiambu 298,723 (18.4%)  Kiambu  298,723  18.4%)    Migori 32,670 (5.9%)  Migori  32,670  5.9%)    Nakuru 170,684 (13.4%)  Nakuru  170,684  13.4%)    Kilifi 31,611 (4.0%)  Kilifi  31,611  4.0%)     Now we just need to clean up some extra characters in the number and percent columns. Get rid of the comma in the number column and the%)in thepercent` column (remember to escape the parenthesis).\ndata4 \u0026lt;- data3 %\u0026gt;% mutate(number = gsub(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;, number), percent = gsub(\u0026quot;%\\\\)\u0026quot;, \u0026quot;\u0026quot;, percent)) %\u0026gt;% select(-x)   county  number  percent      Nairobi  957147  31.4    Homa Bay  33290  5.5    Kiambu  298723  18.4    Migori  32670  5.9    Nakuru  170684  13.4    Kilifi  31611  4.0     This looks good, but there is still a problem. We can‚Äôt do anything useful with this data set because the number and percent columns are actually still character r glossary(\"data type\", \"data types\").\nsummary(data4) ## county number percent ## Length:47 Length:47 Length:47 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character m \u0026lt;- mean(data4$number) ## Warning in mean.default(data4$number): argument is not numeric or logical: ## returning NA Convert the number column to an integer and the percent column to a double.\ndata \u0026lt;- data4 %\u0026gt;% mutate(number = as.integer(number), percent = as.double(percent))   county  number  percent      Nairobi  957147  31.4    Homa Bay  33290  5.5    Kiambu  298723  18.4    Migori  32670  5.9    Nakuru  170684  13.4    Kilifi  31611  4.0     Now you‚Äôre ready to plot the data or use it in analyses.\nggplot(data, aes(x = number, y = percent)) + geom_point(color = \u0026quot;dodgerblue\u0026quot;) + scale_x_continuous(\u0026quot;Number of Vaccinated People\u0026quot;, breaks = seq(0, 1e6, 2e5), labels = c(paste0(seq(0, 800, 200), \u0026quot;K\u0026quot;), \u0026quot;1M\u0026quot;), limits = c(0, 1e6)) + scale_y_continuous(\u0026quot;Percent of County\u0026quot;, breaks = seq(0, 40, 10), labels = paste0(seq(0, 40, 10), \u0026quot;%\u0026quot;)) + theme_bw() Glossary    term  definition      character  A data type representing strings of text.    double  A data type representing a real decimal number    escape  Include special characters like \" inside of a string by prefacing them with a backslash.    integer  A data type representing whole numbers.    list  A container data type that allows items with different data types to be grouped together.    tabular data  Data in a rectangular table format, where each row has an entry for each column.    vector  A type of data structure that collects values with the same data type, like T/F values, numbers, or strings.      ","date":1634428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634466133,"objectID":"a4107fefe445bcf744dade19e5ee7868","permalink":"https://debruine.github.io/post/data-from-images/","publishdate":"2021-10-17T00:00:00Z","relpermalink":"/post/data-from-images/","section":"post","summary":"I saw this a few days ago and sympathised, because I‚Äôve often wanted to use data that is trapped in images or PDFs. If it‚Äôs not too much, I‚Äôll manually transcribe it, but that‚Äôs so tedious!","tags":null,"title":"Data from Images","type":"post"},{"authors":["Heather Cleland Woods","Phil McAleer","Lisa DeBruine","Kate Reid"],"categories":null,"content":"","date":1634137200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634137200,"objectID":"2510b729fc289c25911cb718f78cba84","permalink":"https://debruine.github.io/talk/an-ounce-of-prevention-is-worth-a-pound-of-cure/","publishdate":"2021-10-10T00:00:00Z","relpermalink":"/talk/an-ounce-of-prevention-is-worth-a-pound-of-cure/","section":"event","summary":"Things you can do during the planning stage of your project to help you develop healthy research habits.","tags":["research","teaching","project planning"],"title":"An ounce of prevention is worth a pound of cure","type":"event"},{"authors":["Lisa DeBruine"],"categories":null,"content":"","date":1633449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633449600,"objectID":"b4fe08035cb0122b5c50be4979057f25","permalink":"https://debruine.github.io/talk/mixed-effects-models-for-designs-with-randomly-sampled-stimuli/","publishdate":"2021-10-05T00:00:00Z","relpermalink":"/talk/mixed-effects-models-for-designs-with-randomly-sampled-stimuli/","section":"event","summary":"How and why to use linear mixed effects models.","tags":["mixed effects","simulation","R"],"title":"Mixed effects models for designs with randomly sampled stimuli","type":"event"},{"authors":["Lisa DeBruine","Dale J. Barr"],"categories":null,"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"6bfee2e3db74f5db7b294b859a4483e9","permalink":"https://debruine.github.io/publication/reprores/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/reprores/","section":"publication","summary":"This book provides an overview of skills needed for reproducible research and open science using the statistical programming language R and tidyverse packages. It covers data visualisation, data tidying and wrangling, archiving, iteration and functions, probability and data simulations, general linear models, and reproducible workflows.","tags":["R","teaching","psyTeachR"],"title":"Data Skills for Reproducible Research","type":"publication"},{"authors":["Lisa DeBruine","Dale J Barr"],"categories":null,"content":"","date":1616457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616457600,"objectID":"8a2d227443cbc88e4fdc34ffe846b551","permalink":"https://debruine.github.io/publication/lmem-ampps/","publishdate":"2021-03-23T00:00:00Z","relpermalink":"/publication/lmem-ampps/","section":"publication","summary":"How to simulate data with random-effects structure and analyze the data using linear mixed-effects regression, with a focus on interpreting the output in light of the simulated parameters..","tags":["mixed models","simulation","R","tutorial"],"title":"Understanding mixed effects models through data simulation","type":"publication"},{"authors":null,"categories":["rstats"],"content":" You‚Äôve probably been directed here because you asked someone about how to test the normality of predictors in an analysis. However, statistical tests like t-tests, ANOVAs, and other GLM-based tests assume that the residuals will be normally distributed and it doesn‚Äôt matter at all if the predictors and even the dependent variable aren‚Äôt.\nlibrary(tidyverse) # for data wrangling library(faux) # for data simulation library(afex) # for anova library(cowplot) # for dataviz set.seed(8675309) # to make sure simulation values don\u0026#39;t vary between runs In this blog post, I‚Äôm going to use data simulation to show you how you can visualise the normality of residuals with QQ plots. We‚Äôre going to simulate data from a totally hypothetical population of ferrets and cats. We‚Äôre going to try to predict the energy levels of these pets from their weight. In my limited experience, tiny ferrets are way more energetic than big ferrets. I know nothing about cats.\nTiny, energetic Darwin and her big, lazy brother, Oy\n Simulate Data We‚Äôll use faux to simulate data based on data parameters like means, SDs and correlations for each group. At the moment, faux can only simulate multivariate normal distributions and then you can convert them to other distributions. So we‚Äôll simulate weights from a normal distribution with a mean of 0 and SD of 1, and then convert these to a uniform distribution for each pet type based on ranges I found online. Energy will be simulated from normal distributions with different means and SDs for cats and ferrets. Energy will be uncorrelated with weight for cats and negatively correlated for ferrets.\ndata \u0026lt;- faux::sim_design( within = list(vars = c(\u0026quot;weight\u0026quot;, \u0026quot;energy\u0026quot;)), between = list(species = c(\u0026quot;cat\u0026quot;, \u0026quot;ferret\u0026quot;)), n = 50, mu = list(weight = c(cat = 0, ferret = 0), energy = c(cat = 50, energy = 100)), sd = list(weight = c(cat = 1, ferret = 1), energy = c(cat = 15, energy = 20)), r = list(cat = 0, ferret = -0.5), plot = FALSE ) %\u0026gt;% mutate(weight = case_when( species == \u0026quot;cat\u0026quot; ~ norm2unif(weight, 3.6, 4.5), species == \u0026quot;ferret\u0026quot; ~ norm2unif(weight, 0.7, 2.0) )) N.B. If you‚Äôre more used to simulating data using model parameters, this way might make more sense to you, but it‚Äôs often difficult to figure out what the parameters should be if you don‚Äôt already have pilot data.\nn \u0026lt;- 50 # values approximated from an lm analysis b_0 \u0026lt;- 92 # intercept b_w \u0026lt;- -13 # fixed effect of weight b_s \u0026lt;- 85 # fixed effect of species b_ws \u0026lt;- -26 # weight*species interaction err_sd \u0026lt;- 16 # SD of error term # simulate populations of cats and ferrets # with weights from uniform distributions cat \u0026lt;- data.frame( id = paste0(\u0026quot;C\u0026quot;, 1:n), species = \u0026quot;cat\u0026quot;, weight = runif(n, 3.6, 4.5) ) ferret \u0026lt;- data.frame( id = paste0(\u0026quot;F\u0026quot;, 1:n), species = \u0026quot;ferret\u0026quot;, weight = runif(n, 0.7, 2.0) ) # join data and calculate DV based on GLM data \u0026lt;- bind_rows(cat, ferret) %\u0026gt;% mutate( # effect-code species species.e = recode(species, cat = -0.5, ferret = 0.5), # simulate error term err = rnorm(2*n, 0, err_sd), # calculate DV energy = b_0 + species.e*b_s + weight*b_w + species.e*weight*b_ws + err ) So weight is bimodal and made of two uniform distributions, while energy is bimodal and made of two normal distributions.\n Figure 1: Distibutions overall and within species.  If you run a Shapiro-Wilk test on these variables, you‚Äôd conclude they are definitely not normally distributed, but this doesn‚Äôt matter at all!\nshapiro.test(data$energy) ## ## Shapiro-Wilk normality test ## ## data: data$energy ## W = 0.95486, p-value = 0.001759 shapiro.test(data$weight) ## ## Shapiro-Wilk normality test ## ## data: data$weight ## W = 0.82694, p-value = 1.821e-09  Calculate Residuals We will predict energy from weight, species, and their interaction using a linear model. We‚Äôll effect code species to make the output more similar to what you‚Äôd get from ANOVA (and it doesn‚Äôt really make sense to treatment code them, since neither cats nor ferrets are a meaningful ‚Äúbaseline‚Äù).\n# effect-code species data$species.e \u0026lt;- recode(data$species, cat = -0.5, ferret = 0.5) m1 \u0026lt;- lm(energy ~ weight*species.e, data = data)   term estimate std.error statistic p.value    (Intercept) 85.414 16.204 5.271 0.000  weight -7.928 4.674 -1.696 0.093  species.e 76.821 32.407 2.370 0.020  weight:species.e -18.107 9.348 -1.937 0.056    You can use the resid() function to get the residual error term from your model. This is the difference between the predicted value (based on the weight and species for each subject and the model parameters) and the actual value. Those values should be normally distributed.\nerr \u0026lt;- resid(m1) ggplot() + geom_density(aes(err))  Shapiro-Wilk I don‚Äôt recommend using statistical tests for normality. Essentially, they are underpowered in small samples and overpowered in large samples. Robert Greener has a good discussion of this.. However, the residuals do ‚Äúpass‚Äù the Shapiro-Wilk normality test.\nshapiro.test(err) ## ## Shapiro-Wilk normality test ## ## data: err ## W = 0.99579, p-value = 0.9905  QQ plots It‚Äôs better to assess normality visually, but it‚Äôs quite hard to judge normality from a density plot, especially when you have small samples, so we can use a QQ plot to visualise how close a distribution is to normal. This is a scatterplot created by plotting two sets of quantiles against each other, used to check if data come from a specified distribution (here the normal distribution).\nThese data are simulated, so will show an almost perfect straight line. Real data are always a bit messier. But even here, the points at the extremes are often not exactly on the line. It takes practice to tell if a QQ-plot shows clear signs of non-normality.\n# ggplot function for more customisation qplot(sample = err) + stat_qq_line(colour = \u0026quot;dodgerblue\u0026quot;) + labs(x = \u0026quot;Theoretical distribution\u0026quot;, y = \u0026quot;Sample distribution\u0026quot;, title = \u0026quot;QQ Plot for Residual Error\u0026quot;) Our bimodal energy data are a good example of a QQ plot showing a non-normal distribution (see how the points move away from the line at the ends), but that doesn‚Äôt matter for your model at all.\nggplot(data, aes(sample = energy)) + stat_qq() + stat_qq_line(colour = \u0026quot;dodgerblue\u0026quot;) + labs(x = \u0026quot;Theoretical distribution\u0026quot;, y = \u0026quot;Sample distribution\u0026quot;, title = \u0026quot;QQ Plot for Energy\u0026quot;)  Other tests So how do you get the residuals for other tests? All functions that return models in R should have a resid() function. T-tests are a little trickier, but you can just convert them to their GLM equivalents (Jonas Lindel√∏v has a great tutorial) or use the formulas below.\n# simulated data to use below A \u0026lt;- rnorm(50, 0, 1) B \u0026lt;- rnorm(50, 0.5, 1) One-sample t-test The residuals for a one-samples t-test are the scores minus the mean difference. (You don‚Äôt have to subtract the mean difference, since the distribution won‚Äôt change if you add a constant value.)\n# one-sample t-test against 0 mu = 0 t_o \u0026lt;- t.test(A, mu = mu) err_t \u0026lt;- A - mean(A) plot_t \u0026lt;- qplot(sample = err_t) + stat_qq_line() # lm equivalent to one-sample t-test m_o \u0026lt;- lm(A - mu ~ 1) err_lm \u0026lt;- resid(m_o) plot_lm \u0026lt;- qplot(sample = err_lm) + stat_qq_line() cowplot::plot_grid(plot_t, plot_lm, labels = c(\u0026quot;t\u0026quot;, \u0026quot;lm\u0026quot;))  Paired samples t-test The residuals for a paired-samples t-test are the difference between the paired values, minus the mean difference.\n# paired samples t-test t_p \u0026lt;- t.test(A, B, paired = TRUE) diff \u0026lt;- A - B err_t \u0026lt;- diff - mean(diff) plot_t \u0026lt;- qplot(sample = err_t) + stat_qq_line() # lm equivalent to paired-samples t-test m_p \u0026lt;- lm(A-B ~ 1) err_lm \u0026lt;- resid(m_p) plot_lm \u0026lt;- qplot(sample = err_lm) + stat_qq_line() cowplot::plot_grid(plot_t, plot_lm, labels = c(\u0026quot;t\u0026quot;, \u0026quot;lm\u0026quot;))  Independent-samples t-test The residuals for an independent-samples t-test are the scores minus their own group mean.\n# independent-sample t-test t_i \u0026lt;- t.test(A, B) err_t \u0026lt;- c(A-mean(A), B-mean(B)) plot_t \u0026lt;- qplot(sample = err_t) + stat_qq_line() # lm equivalent to one-sample t-test dat \u0026lt;- data.frame( val = c(A, B), grp = rep(0:1, each = 50) ) m_o \u0026lt;- lm(val ~ 1 + grp, dat) err_lm \u0026lt;- resid(m_o) plot_lm \u0026lt;- qplot(sample = err_lm) + stat_qq_line() cowplot::plot_grid(plot_t, plot_lm, labels = c(\u0026quot;t\u0026quot;, \u0026quot;lm\u0026quot;))  ANOVA You can use the resid() function on the models output by ANOVAs or ANCOVAs.\nm_aov \u0026lt;- afex::aov_4(energy ~ weight*species.e + (1|id), data = data, factorize = FALSE ) plot_aov \u0026lt;- qplot(sample = resid(m_aov)) + stat_qq_line() m_lm \u0026lt;- lm(energy ~ weight*species.e, data = data) plot_lm \u0026lt;- qplot(sample = resid(m_lm)) + stat_qq_line() cowplot::plot_grid(plot_aov, plot_lm, labels = c(\u0026quot;aov\u0026quot;, \u0026quot;lm\u0026quot;)) Dale Barr has a great blog post on checking assumptions for multilevel data.\n  Glossary     term definition    dependent-variable The target variable that is being analyzed, whose value is assumed to depend on other variables.  effect-code A coding scheme for categorical variables that contrasts each group mean with the mean of all the group means.  general-linear-model A mathematical model comparing how one or more independent variables affect a continuous dependent variable  normal-distribution A symmetric distribution of data where values near the centre are most probable.  parameter A value that describes a distribution, such as the mean or SD  predictor-variable A variable whose value is used (in a model) to predict the value of a response variable.  q-q-plot A scatterplot created by plotting two sets of quantiles against each other, used to check if data come from a specified distribution  quantile Cutoffs dividing the range of a distribution into continuous intervals with equal probabilities.  residual-error That part of an observation that cannot be captured by the statistical model, and thus is assumed to reflect unknown factors.  treatment-code A coding scheme for categorical variables that creates (n_levels -1) dichotomous variables where each level of the categorical variable is contrasted to a reference level.  uniform-distribution All numbers in the range have an equal probability of being sampled     ","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"04674e2d5a41c90be3720f7ada5b583c","permalink":"https://debruine.github.io/post/normality/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/post/normality/","section":"post","summary":"You‚Äôve probably been directed here because you asked someone about how to test the normality of predictors in an analysis. However, statistical tests like t-tests, ANOVAs, and other GLM-based tests assume that the residuals will be normally distributed and it doesn‚Äôt matter at all if the predictors and even the dependent variable aren‚Äôt.","tags":["r","normality","qqplot"],"title":"Testing for normality","type":"post"},{"authors":null,"categories":["rstats"],"content":"   (updated 2021-01-21)\nExperimentum studies require that you download data from questionnaires and experiments separately, since the data have different formats. You can participate anonymously in the demo study (the median completion time is 3.8 minutes). The links below update dynamically, so your data will be available immediately.\n questionnaire data experiment data project structure  The project structure file above is a JSON-formatted file that contains all of the information needed to run a study in Experimentum. In future versions of Experimentum, you will be able to directly edit this file, for example translating the questions into another language, and set up a study by simply uploading the file.\nproj \u0026lt;- jsonlite::read_json(\u0026quot;data/project_520_structure.json\u0026quot;) Questionnaire Data The study has two questionnaires: Groups, a few questions you can use to divide the participants into groups of varying sizes, and BMIS, the Brief Mood Introspection Scale.\nLoad Data quest_data \u0026lt;- read_csv(\u0026quot;data/Demo-Data-quests_2021-01-21.csv\u0026quot;) glimpse(quest_data) ## Rows: 2,807 ## Columns: 14 ## $ session_id \u0026lt;dbl\u0026gt; 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60‚Ä¶ ## $ project_id \u0026lt;dbl\u0026gt; 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520‚Ä¶ ## $ quest_name \u0026lt;chr\u0026gt; \u0026quot;Groups\u0026quot;, \u0026quot;Groups\u0026quot;, \u0026quot;Groups\u0026quot;, \u0026quot;Groups\u0026quot;, \u0026quot;Groups\u0026quot;, \u0026quot;Groups\u0026quot;‚Ä¶ ## $ quest_id \u0026lt;dbl\u0026gt; 2921, 2921, 2921, 2921, 2921, 2921, 2921, 2920, 2920, 2920‚Ä¶ ## $ user_id \u0026lt;dbl\u0026gt; 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43‚Ä¶ ## $ user_sex \u0026lt;chr\u0026gt; \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;‚Ä¶ ## $ user_status \u0026lt;chr\u0026gt; \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;r‚Ä¶ ## $ user_age \u0026lt;dbl\u0026gt; 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6‚Ä¶ ## $ q_name \u0026lt;chr\u0026gt; \u0026quot;fiber_arts\u0026quot;, \u0026quot;native_english\u0026quot;, \u0026quot;hats\u0026quot;, \u0026quot;pets\u0026quot;, \u0026quot;colour\u0026quot;, ‚Ä¶ ## $ q_id \u0026lt;dbl\u0026gt; 92833810, 92833809, 92833814, 92833811, 92833813, 92833815‚Ä¶ ## $ order \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ dv \u0026lt;chr\u0026gt; \u0026quot;1\u0026quot;, \u0026quot;0\u0026quot;, \u0026quot;5\u0026quot;, \u0026quot;Yes\u0026quot;, \u0026quot;Red\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;today\u0026quot;, \u0026quot;2\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;2\u0026quot;, ‚Ä¶ ## $ starttime \u0026lt;dttm\u0026gt; 2021-01-19 17:48:15, 2021-01-19 17:48:15, 2021-01-19 17:4‚Ä¶ ## $ endtime \u0026lt;dttm\u0026gt; 2021-01-19 17:48:31, 2021-01-19 17:48:31, 2021-01-19 17:4‚Ä¶  session_id a unique ID generated each time someone starts a study project_id a unique ID for this study quest_name the name of each questionnaire (not guaranteed to be unique) quest_id uniquely identifies each questionnaire user_id registered participants have a unique ID that is the same across logins, while guest participants get a new ID each time they log in user_sex gender from the options ‚Äúmale‚Äù, ‚Äúfemale‚Äù, ‚Äúnonbinary‚Äù, ‚Äúna‚Äù (specifically chose not to answer), or NA (did not complete the question) user_status whether use is a researcher (‚Äúadmin‚Äù, ‚Äúsuper‚Äù, ‚Äúres‚Äù, ‚Äústudent‚Äù), a ‚Äúregistered‚Äù user, a ‚Äúguest‚Äù user, or ‚Äútest‚Äù user_age the user‚Äôs age; registered accounts are asked for their birthdate, and their age is calculated to the nearest 0.1 years; guest users may be asked their age in years q_name name of the question q_id uniquely identifies each question order the order the question was presented in (not necessarily answered in) or questionnaires with randomised order dv the response starttime the time that the questionnaire was started endtime the time that the questionnaire was submitted   Removing duplicate answers Although Experimentum tries to prevent people accidentally using the back button during a study, there are some ways around this, so sometimes a person will submit the same questionnaire twice in a row. You can filter your data down to only the first time each person completed each question with the following code (do not use this if your study actually gives people the same questionnaire more than once).\nThe questions are recorded in the order that they were answered, so we can just group by participant (user_id) and question (q_id) and choose the first answer. If you have a longitudinal study, group by session_id to allow multiple sessions per user.\nquest_distinct \u0026lt;- quest_data %\u0026gt;% group_by(user_id, q_id) %\u0026gt;% # or add session_id # chooses the first time each user answered each question filter(row_number() == 1) %\u0026gt;% ungroup() Check how many duplicate rows were excluded.\nsetdiff(quest_data, quest_distinct) %\u0026gt;% nrow() ## [1] 0  Groups Here, we select just the data from the Groups questionnaire and keep only the session_id, user_id, q_name, and dv columns, and convert the data to wide format. If you restricted your data to only one session per user, as above, then user_id and session_id are redundant. The code below works for both types of data, though.\nIf the dv column contains both numeric and character data, the new columns will all be characters, so add convert = TRUE if you are using spread(). If you use the pivot_wider() function, it doesn‚Äôt have a convert argument, so you have to pipe the data frame to a separate function, type.convert().\ngroups \u0026lt;- quest_distinct %\u0026gt;% filter(quest_name == \u0026quot;Groups\u0026quot;) %\u0026gt;% select(session_id, user_id, q_name, dv) %\u0026gt;% spread(q_name, dv, convert = TRUE)   session_id  user_id  colour  exercise  fiber_arts  hats  native_english  pets  spiders      60481  43533  Red  today  1  5  0  Yes  1    60495  31625  Green  today  1  3  1  Yes  5    60509  53422  black  more  0  5  1  Yes  2    60550  53458  purplE  today  1  12  1  No  3    60552  53460  green  today  0  3  0  No  2    60553  53461  Blue  today  0  5  1  Yes  2      Questionnaire options I usually recommend recording the actual text chosen from drop-down menus, rather than integers that you will have to remember how you mapped onto the answers. If you need to check how you set up the coding, you can look at the info page on Experimentum or check the project json file that we loaded above. It‚Äôs a nested list and contains all the info, but can be a little tricky to parse (I‚Äôll work on making an R package to make this easier in the future).\n# get question names, text and type, plus options if select qs \u0026lt;- proj$quest_2921$question %\u0026gt;% map(~{ x \u0026lt;- .x[c(\u0026quot;name\u0026quot;, \u0026quot;question\u0026quot;, \u0026quot;type\u0026quot;)] if (!is.null(.x$options)) { x$options \u0026lt;- sapply(.x$options, `[[`, \u0026quot;display\u0026quot;) names(x$options) \u0026lt;- sapply(.x$options, `[[`, \u0026quot;opt_value\u0026quot;) } x })  name: native_english question: Is English your native language? type: select options:  1: Yes 0: No    name: fiber_arts question: Do you know how to knit or crochet? type: select options:  1: Yes 0: No    name: pets question: Do you have a pet? type: select options:  Yes: Yes No: No    name: exercise question: When was the last time you exercised? type: select options:  today: today or yesterday week: in the past week more: more than a week ago    name: colour question: What is your favourite colour? type: text   name: hats question: How many hats do you own (approximately)? type: selectnum   name: spiders question: Are you afraid of spiders? type: radioanchor   Plots and tables Plot your data or create summary tables to help you spot any problems. The count() function is useful for variables with a small number of options.\n# count a single column count(groups, exercise)   exercise  n      more  24    today  69    week  31     # count multiple columns count(groups, fiber_arts, native_english, pets)   fiber_arts  native_english  pets  n      0  0  No  10    0  0  Yes  8    0  1  No  20    0  1  Yes  20    1  0  No  4    1  0  Yes  5    1  1  No  18    1  1  Yes  39     Histograms or density plots are best for columns with many continuous values.\nggplot(groups, aes(hats)) + geom_histogram(binwidth = 1, fill = \u0026quot;dodgerblue\u0026quot;, color = \u0026quot;white\u0026quot;) ggplot(groups, aes(spiders)) + geom_histogram(binwidth = 1, fill = \u0026quot;violetred\u0026quot;, color = \u0026quot;white\u0026quot;)  Recode variables You might want to do some recoding of variables here. The pets column contains the words ‚ÄúYes‚Äù and ‚ÄúNo‚Äù; maybe you want to code this as 1s and 0s.The column fiber_arts has a 1 if a person knows how to knit or crochet, and a 0 if they don‚Äôt. You might want to change this to the words ‚ÄúYes‚Äù and ‚ÄúNo‚Äù. The recode() function is useful for this. I like to give the binary-coded version of a variable the suffix ‚Äú.b‚Äù.\nNote that in the recode() function, numbers that are on the left side of an equal sign need to be in quotes. This just has to do with the way R treats argument names and doesn‚Äôt mean that the recoded column has to be a character type.\ngroups_coded \u0026lt;- groups %\u0026gt;% mutate( pets.b = recode(pets, \u0026quot;Yes\u0026quot; = 1, \u0026quot;No\u0026quot; = 0), fiber_arts.b = fiber_arts, fiber_arts = recode(fiber_arts, \u0026quot;1\u0026quot; = \u0026quot;Yes\u0026quot;, \u0026quot;0\u0026quot; = \u0026quot;No\u0026quot;) )   session_id  user_id  colour  exercise  fiber_arts  hats  native_english  pets  spiders  pets.b  fiber_arts.b      60481  43533  Red  today  Yes  5  0  Yes  1  1  1    60495  31625  Green  today  Yes  3  1  Yes  5  1  1    60509  53422  black  more  No  5  1  Yes  2  1  0    60550  53458  purplE  today  Yes  12  1  No  3  0  1    60552  53460  green  today  No  3  0  No  2  0  0    60553  53461  Blue  today  No  5  1  Yes  2  1  0      Free text If you have any free-text responses, you will probably need to code them. I always start by looking at all of the possible values after transforming the value to lowercase and getting rid of spaces around the text.\ncolours \u0026lt;- groups_coded %\u0026gt;% mutate(colour = tolower(colour) %\u0026gt;% trimws()) %\u0026gt;% count(colour) %\u0026gt;% arrange(n, colour) %\u0026gt;% group_by(n) %\u0026gt;% summarise(colours = paste(colour, collapse = \u0026quot;, \u0026quot;), .groups = \u0026quot;drop\u0026quot;)   n  colours      1  amber, cornflower, grey, indian orange, magenta, monochrome grey/white tones, petroleum blue, teal, violet, white, yes.    4  pink, turquoise    6  orange    7  black    8  yellow    12  red    17  purple    26  green    29  blue     You can then decide to recode some colours to fix misspellings, etc. One tricky part of using recode() is that all replaced values have to be the same data type, so use NA_character_ if you are replacing values with strings, NA_real_ for doubles, and NA_integer_ for integers.\ngroups_colours \u0026lt;- groups_coded %\u0026gt;% mutate(colour = tolower(colour) %\u0026gt;% trimws()) %\u0026gt;% mutate(colours_fixed = recode(colour, \u0026quot;amber\u0026quot; = \u0026quot;yellow\u0026quot;, \u0026quot;yes.\u0026quot; = NA_character_, \u0026quot;violet\u0026quot; = \u0026quot;purple\u0026quot;, \u0026quot;petroleum blue\u0026quot; = \u0026quot;blue\u0026quot;))   BMIS The second questionnaire is the Brief Mood Introspection Scale (BMIS). The BMIS has 16 questions divided into positive and negative adjectives. The question names are all in the format valence_adjective, so you can easily separate the question name into two columns.\nBecause the original quest_data had both character and numeric values in the dv column, it is still a character type even now that the dv column only contains numbers. You can fix this using the type_convert() function. Set col_types manually or use cols() to automatically guess.\nbmis_raw \u0026lt;- quest_distinct %\u0026gt;% filter(quest_name == \u0026quot;BMIS\u0026quot;) %\u0026gt;% select(session_id, user_id, q_name, dv) %\u0026gt;% separate(q_name, c(\u0026quot;valence\u0026quot;, \u0026quot;adjective\u0026quot;)) %\u0026gt;% type_convert(col_types = cols())   session_id  user_id  valence  adjective  dv      60481  43533  neg  nervous  2    60481  43533  pos  caring  1    60481  43533  pos  peppy  2    60481  43533  neg  tired  3    60481  43533  neg  grouchy  4    60481  43533  neg  sad  3     Summary scores The BMIS is coded as the sum of the forward-coded scores for all the positive adjectives and the reverse-coded scores for all negative adjectives. Experimentum has a function to reverse code selected items in the ‚Äúradiopage‚Äù questionnaire type, but we didn‚Äôt do that here so you can see how to manually recode. The scores are 1 to 4, so subjtract them from 5 to get the reverse-coded value. Make sure to look at a few of your recoded values to make sure it‚Äôs doing what you expect.\nbmis_coded \u0026lt;- bmis_raw %\u0026gt;% mutate(recoded_dv = case_when( valence == \u0026quot;pos\u0026quot; ~ dv, valence == \u0026quot;neg\u0026quot; ~ 5 - dv ))   session_id  user_id  valence  adjective  dv  recoded_dv      60481  43533  neg  nervous  2  3    60481  43533  pos  caring  1  1    60481  43533  pos  peppy  2  2    60481  43533  neg  tired  3  2    60481  43533  neg  grouchy  4  1    60481  43533  neg  sad  3  2     Create the summary score by grouping by user_id and session_id and summing the responses. We use sum() here because the BMIS is not valid if people skipped any questions, so we want the result to be NA if they did. Some questionnaire scoring allows you to calculate an average score omitting missed questions, so you could use mean(recoded_dv, na.rm = TRUE).\nbmis \u0026lt;- bmis_coded %\u0026gt;% group_by(session_id, user_id) %\u0026gt;% summarise(bmis = sum(recoded_dv), .groups = \u0026quot;drop\u0026quot;)   Plots Always plot your summary scores. This helps you to double-check your logic and identify outliers.\nggplot(bmis, aes(bmis)) + geom_histogram(binwidth = 1, fill = \u0026quot;dodgerblue\u0026quot;, color = \u0026quot;white\u0026quot;)   User Demographics Experimentum data always contains user demographic data, which is collected when the user signs up for a registered account or logs in as a guest. This study did not ask users for their age or sex, so that info is only available from registered users.\nFirst, we select the session_id and all of the user variables, then make sure we have only one row for each participant.\nuser \u0026lt;- quest_distinct %\u0026gt;% select(session_id, starts_with(\u0026quot;user_\u0026quot;)) %\u0026gt;% distinct()   session_id  user_id  user_sex  user_status  user_age      60481  43533  female  res  26.6    60495  31625  female  student  22.1    60509  53422  female  guest  61.0    60550  53458  NA  guest  0.0    60552  53460  NA  guest  0.0    60553  53461  NA  guest  0.0      Rejoining Now you can rejoin your questionnaire data. Start with the user table and only join on matching data from the individual questionnaires. Use session_id and user_id to join.\nq_data \u0026lt;- user %\u0026gt;% left_join(bmis, by = c(\u0026quot;session_id\u0026quot;, \u0026quot;user_id\u0026quot;)) %\u0026gt;% left_join(groups_colours, by = c(\u0026quot;session_id\u0026quot;, \u0026quot;user_id\u0026quot;))  Exclusions You will usually want to exclude participants with user_status that are not ‚Äúregistered‚Äù or ‚Äúguest‚Äù. Statuses ‚Äúadmin‚Äù, ‚Äúsuper‚Äù, ‚Äúres‚Äù, and ‚Äústudent‚Äù refer to different types of researchers (with different privileges on the Experimentum platform). The status ‚Äútest‚Äù is for test runs with different user demographics. You can also apply other exclusion criteria here like age restrictions or requiring that summary score not be missing.\nq_data_excl \u0026lt;- q_data %\u0026gt;% filter(user_status %in% c(\u0026quot;guest\u0026quot;, \u0026quot;registered\u0026quot;))   user_status  n      guest  121       Experiment Data Our study has one rating experiment with two between-subject conditions: cuteness ratings and appropriateness as pet ratings.\nLoad Data exp_data \u0026lt;- read_csv(\u0026quot;data/Demo-Data-exps_2021-01-21.csv\u0026quot;) glimpse(exp_data) ## Rows: 1,476 ## Columns: 15 ## $ session_id \u0026lt;dbl\u0026gt; 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60‚Ä¶ ## $ project_id \u0026lt;dbl\u0026gt; 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520‚Ä¶ ## $ exp_name \u0026lt;chr\u0026gt; \u0026quot;Animals: Cuteness\u0026quot;, \u0026quot;Animals: Cuteness\u0026quot;, \u0026quot;Animals: Cutene‚Ä¶ ## $ exp_id \u0026lt;dbl\u0026gt; 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707‚Ä¶ ## $ user_id \u0026lt;dbl\u0026gt; 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43‚Ä¶ ## $ user_sex \u0026lt;chr\u0026gt; \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;‚Ä¶ ## $ user_status \u0026lt;chr\u0026gt; \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;r‚Ä¶ ## $ user_age \u0026lt;dbl\u0026gt; 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6‚Ä¶ ## $ trial_name \u0026lt;chr\u0026gt; \u0026quot;animal-967657_640\u0026quot;, \u0026quot;surprised-3786845_640\u0026quot;, \u0026quot;penguins-42‚Ä¶ ## $ trial_n \u0026lt;dbl\u0026gt; 2, 12, 9, 3, 8, 10, 5, 6, 7, 11, 4, 1, 4, 10, 7, 11, 12, 9‚Ä¶ ## $ order \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7‚Ä¶ ## $ dv \u0026lt;dbl\u0026gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 7, 7, 3, 4, 2, 7, 4‚Ä¶ ## $ rt \u0026lt;dbl\u0026gt; 1756, 1103, 842, 735, 755, 845, 878, 842, 812, 1421, 1003,‚Ä¶ ## $ side \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶ ## $ dt \u0026lt;dttm\u0026gt; 2021-01-19 17:48:35, 2021-01-19 17:48:36, 2021-01-19 17:4‚Ä¶ Experiment data have the same session and user columns as questionnaire data, plus columns for the experiment name (exp_name) and unique id (exp_id). The remaining columns give data specific to each trial:\n trial_name not necessarily unique trial_n uniquely identifies each trial within an experiment order (the order the trial was shown to that participant dv the response rt the rough reaction time in milliseconds (web data have many sources of possible bias so do not use Experimentum to do RT experiments that require millisecond precision) side if the experiment has multiple images, the order of the images if side is set to random (not relevant here) dt the timestamp of the response  glimpse(exp_data) ## Rows: 1,476 ## Columns: 15 ## $ session_id \u0026lt;dbl\u0026gt; 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60481, 60‚Ä¶ ## $ project_id \u0026lt;dbl\u0026gt; 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520, 520‚Ä¶ ## $ exp_name \u0026lt;chr\u0026gt; \u0026quot;Animals: Cuteness\u0026quot;, \u0026quot;Animals: Cuteness\u0026quot;, \u0026quot;Animals: Cutene‚Ä¶ ## $ exp_id \u0026lt;dbl\u0026gt; 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707, 707‚Ä¶ ## $ user_id \u0026lt;dbl\u0026gt; 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43533, 43‚Ä¶ ## $ user_sex \u0026lt;chr\u0026gt; \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;‚Ä¶ ## $ user_status \u0026lt;chr\u0026gt; \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;res\u0026quot;, \u0026quot;r‚Ä¶ ## $ user_age \u0026lt;dbl\u0026gt; 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6, 26.6‚Ä¶ ## $ trial_name \u0026lt;chr\u0026gt; \u0026quot;animal-967657_640\u0026quot;, \u0026quot;surprised-3786845_640\u0026quot;, \u0026quot;penguins-42‚Ä¶ ## $ trial_n \u0026lt;dbl\u0026gt; 2, 12, 9, 3, 8, 10, 5, 6, 7, 11, 4, 1, 4, 10, 7, 11, 12, 9‚Ä¶ ## $ order \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7‚Ä¶ ## $ dv \u0026lt;dbl\u0026gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 7, 7, 3, 4, 2, 7, 4‚Ä¶ ## $ rt \u0026lt;dbl\u0026gt; 1756, 1103, 842, 735, 755, 845, 878, 842, 812, 1421, 1003,‚Ä¶ ## $ side \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶ ## $ dt \u0026lt;dttm\u0026gt; 2021-01-19 17:48:35, 2021-01-19 17:48:36, 2021-01-19 17:4‚Ä¶ Most researchers don‚Äôt want all that data, so we can select just the important columns. The exp_name contains info we don‚Äôt need, so we‚Äôll also process that.\nexp_selected \u0026lt;- exp_data %\u0026gt;% select(session_id, user_id, exp_name, trial_name, dv) %\u0026gt;% mutate(exp_name = sub(\u0026quot;Animals: \u0026quot;, \u0026quot;\u0026quot;, exp_name)) count(exp_selected, exp_name)   exp_name  n      Appropriate  696    Cuteness  780     count(exp_selected, trial_name)   trial_name  n      adorable-5059091_640  123    animal-967657_640  123    bird-349035_640  123    dolphin-203875_640  123    frog-3312038_640  123    hedgehog-468228_640  123    kitty-2948404_640  123    meerkat-459171_640  123    penguins-429134_640  123    pug-690566_640  123    spider-2313079_640  123    surprised-3786845_640  123      Adding trial data It‚Äôs common that you need to add some data about each trial.\n Figure 1: images from the experiment  You will probably have you trial information in a separate table, so you can load that here. In this case, we‚Äôll use the tribble() function to create a table by rows.\ntrial_info \u0026lt;- tribble( ~photo, ~name, ~is_baby, ~mammal, \u0026quot;adorable-5059091_640\u0026quot;, \u0026quot;kitten1\u0026quot;, 1, 1, \u0026quot;animal-967657_640\u0026quot;, \u0026quot;fox\u0026quot;, 0, 1, \u0026quot;bird-349035_640\u0026quot;, \u0026quot;chicken\u0026quot;, 1, 0, \u0026quot;dolphin-203875_640\u0026quot;, \u0026quot;dolphin\u0026quot;, 0, 1, \u0026quot;frog-3312038_640\u0026quot;, \u0026quot;frog\u0026quot;, 0, 0, \u0026quot;hedgehog-468228_640\u0026quot;, \u0026quot;hedgehog\u0026quot;, 0, 1, \u0026quot;kitty-2948404_640\u0026quot;, \u0026quot;kitten2\u0026quot;, 1, 1, \u0026quot;meerkat-459171_640\u0026quot;, \u0026quot;meerkat\u0026quot;, 0, 1, \u0026quot;penguins-429134_640\u0026quot;, \u0026quot;penguin\u0026quot;, 1, 0, \u0026quot;pug-690566_640\u0026quot;, \u0026quot;dog\u0026quot;, 1, 1, \u0026quot;spider-2313079_640\u0026quot;, \u0026quot;spider\u0026quot;, 0, 0, \u0026quot;surprised-3786845_640\u0026quot;, \u0026quot;squirrel\u0026quot;, 0, 1 ) Then you can join it to the experiment data.\nexp_full \u0026lt;- exp_selected %\u0026gt;% left_join(trial_info, by = c(\u0026quot;trial_name\u0026quot; = \u0026quot;photo\u0026quot;)) And create some plots.\nggplot(exp_full, aes(dv, colour = exp_name)) + geom_freqpoly(binwidth = 1) + facet_wrap(~name) + scale_x_continuous(breaks = 1:7) + labs(colour = \u0026quot;Rating Type\u0026quot;, x = \u0026quot;\u0026quot;)  Demographs, exclusions and rejoin As for the questionnaire data above, you can pull out the user demographics, apply exclusions, and rejoin to the experiment data.\n# user table with exclusions user_excl \u0026lt;- exp_data %\u0026gt;% select(session_id, starts_with(\u0026quot;user_\u0026quot;)) %\u0026gt;% distinct() %\u0026gt;% filter(user_status %in% c(\u0026quot;guest\u0026quot;, \u0026quot;registered\u0026quot;)) e_data_excl \u0026lt;- user_excl %\u0026gt;% left_join(exp_full, by = c(\u0026quot;session_id\u0026quot;, \u0026quot;user_id\u0026quot;)) glimpse(e_data_excl) ## Rows: 1,440 ## Columns: 11 ## $ session_id \u0026lt;dbl\u0026gt; 60509, 60509, 60509, 60509, 60509, 60509, 60509, 60509, 60‚Ä¶ ## $ user_id \u0026lt;dbl\u0026gt; 53422, 53422, 53422, 53422, 53422, 53422, 53422, 53422, 53‚Ä¶ ## $ user_sex \u0026lt;chr\u0026gt; \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;female\u0026quot;‚Ä¶ ## $ user_status \u0026lt;chr\u0026gt; \u0026quot;guest\u0026quot;, \u0026quot;guest\u0026quot;, \u0026quot;guest\u0026quot;, \u0026quot;guest\u0026quot;, \u0026quot;guest\u0026quot;, \u0026quot;guest\u0026quot;, \u0026quot;gue‚Ä¶ ## $ user_age \u0026lt;dbl\u0026gt; 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 0, 0, 0, 0‚Ä¶ ## $ exp_name \u0026lt;chr\u0026gt; \u0026quot;Appropriate\u0026quot;, \u0026quot;Appropriate\u0026quot;, \u0026quot;Appropriate\u0026quot;, \u0026quot;Appropriate\u0026quot;‚Ä¶ ## $ trial_name \u0026lt;chr\u0026gt; \u0026quot;penguins-429134_640\u0026quot;, \u0026quot;bird-349035_640\u0026quot;, \u0026quot;hedgehog-468228‚Ä¶ ## $ dv \u0026lt;dbl\u0026gt; 1, 4, 5, 1, 7, 1, 7, 6, 1, 7, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4‚Ä¶ ## $ name \u0026lt;chr\u0026gt; \u0026quot;penguin\u0026quot;, \u0026quot;chicken\u0026quot;, \u0026quot;hedgehog\u0026quot;, \u0026quot;squirrel\u0026quot;, \u0026quot;kitten2\u0026quot;, \u0026quot;‚Ä¶ ## $ is_baby \u0026lt;dbl\u0026gt; 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0‚Ä¶ ## $ mammal \u0026lt;dbl\u0026gt; 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1‚Ä¶   Joining Questionnaire and Experiment Data Often, it makes most sense to process questionnaire data in wide format and experiment data in long format. If you need to add wide questionnaire data to a long experiment table, left join the questionnaire like this:\nall_data \u0026lt;- e_data_excl %\u0026gt;% left_join(q_data_excl, by = c(\u0026quot;session_id\u0026quot;, \u0026quot;user_id\u0026quot;)) names(all_data) ## [1] \u0026quot;session_id\u0026quot; \u0026quot;user_id\u0026quot; \u0026quot;user_sex.x\u0026quot; \u0026quot;user_status.x\u0026quot; ## [5] \u0026quot;user_age.x\u0026quot; \u0026quot;exp_name\u0026quot; \u0026quot;trial_name\u0026quot; \u0026quot;dv\u0026quot; ## [9] \u0026quot;name\u0026quot; \u0026quot;is_baby\u0026quot; \u0026quot;mammal\u0026quot; \u0026quot;user_sex.y\u0026quot; ## [13] \u0026quot;user_status.y\u0026quot; \u0026quot;user_age.y\u0026quot; \u0026quot;bmis\u0026quot; \u0026quot;colour\u0026quot; ## [17] \u0026quot;exercise\u0026quot; \u0026quot;fiber_arts\u0026quot; \u0026quot;hats\u0026quot; \u0026quot;native_english\u0026quot; ## [21] \u0026quot;pets\u0026quot; \u0026quot;spiders\u0026quot; \u0026quot;pets.b\u0026quot; \u0026quot;fiber_arts.b\u0026quot; ## [25] \u0026quot;colours_fixed\u0026quot; Now go explore your data!\n ","date":1611100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611100800,"objectID":"62e09ab7a7c2357295c8ff8acf4f7912","permalink":"https://debruine.github.io/post/experimentum-data/","publishdate":"2021-01-20T00:00:00Z","relpermalink":"/post/experimentum-data/","section":"post","summary":"(updated 2021-01-21)\nExperimentum studies require that you download data from questionnaires and experiments separately, since the data have different formats. You can participate anonymously in the demo study (the median completion time is 3.","tags":["R","data","tidyverse","experimentum"],"title":"Experimentum Data Wrangling Demo","type":"post"},{"authors":null,"categories":["stats"],"content":"  I see a lot of functions from people new to coding that look like this and I want to point out a few common conceptual mistakes with writing functions.\n# my data-generating parameters my_n \u0026lt;- 50 my_mu \u0026lt;- c(0, 0.2) my_sd \u0026lt;- c(1, 1) my_r \u0026lt;- 0.5 my_func \u0026lt;- function(n = my_n) { # simulate data dat \u0026lt;- faux::rnorm_multi( n = my_n, vars = 2, mu = my_mu, sd = my_sd, r = my_r, varnames = c(\u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;) ) # test high-low difference t.test(dat$high, dat$low, paired = TRUE) } my_func(n = 100) ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 1.9282, df = 49, p-value = 0.05964 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.01142952 0.55308436 ## sample estimates: ## mean of the differences ## 0.2708274 Definitions First, it‚Äôs helpful to define a few terms I‚Äôll use below.\nVariables are words that identify and store the value of some data for later use. For example, in the code above, my_n is a variable and its value is set to 50.\nThe function is my_func() and is defined by the code inside the curly brackets {...}.\nThe arguments are the variables that are set by the function. In the function above, function(n = my_n) has one argument: n. Arguments can have a default value. In the code above, the argument n has a default value of my_n, which is the value that argument takes if it‚Äôs not explicitly defined (e.g., if you just run my_func() instead of my_func(n = 25)).\nThe global environment is the set of variables and functions that you create during your R session. It is what you can see in the Environment tab in RStudio.\n Not using an argument The biggest thing wrong with this code is that it defines an argument called n, but doesn‚Äôt use it in the code. It uses the variable my_n instead. So when I ran my_func(n = 100) above, I still got the result for n = 50 (check the df in the output), because my_n still equals 50 and that‚Äôs what the function is using, not the value of n.\nIt‚Äôs easy for this to happen when you‚Äôre first developing a function because you probably are modifying non-function code, where it does make sense to use my_n in the rnorm_multi() function. You can either make the name of the argument match (e.g., function(my_n) {...}) or change the name of the variable in the function code (e.g., dat \u0026lt;- faux::rnorm_multi(n = n, ...)).\n Externally defined variables The code in a function should usually be able to run without depending on having variables with correct names in the environment. This code doesn‚Äôt run if you don‚Äôt define my_mu, my_sd and my_r before running it. It‚Äôs tempting to just use those variables inside the function, because it saves you typing the values as arguments to the function when you use it, especially in a script where you know you won‚Äôt need to change those values, but this makes the function less useful in other contexts (including reuse by future you).\nThere can definitely be exceptions to this, but first master the rule that any variables used inside a function have to be defined as arguments.\n Variables as default values Normally, don‚Äôt set function argument defaults to a variable (again, there can be exceptions, but you need to master that rule before you understand when you can use exceptions). It will work fine when you‚Äôre testing it in context and all the variables you expect to be in the environment are there, but the point of a function is to be reusable in different contexts, so it‚Äôs best not to depend on external things.\nYou don‚Äôt always have to set a default value for an argument, but it‚Äôs often useful to set the default value to a ‚Äúneutral‚Äù thing that makes the code run even if the user doesn‚Äôt set all the arguments. So n should be a sensible number like 100 (e.g., if you set it to 0, then the code won‚Äôt run correctly), and sd should be 1 (not 0, since that‚Äôs not a valid value for SDs).\n Better versions In this version, I used the same argument names as the rnorm_multi() function from faux, and also set their default values to the same defaults that function uses (simulating a dataset with 100 pairs of observations with means of 0, SDs of 1, and a correlation of 0).\nYou could add more arguments to the function, like vars or varnames, but in this context I know I would never want to vary them, so I can ‚Äúhard-code‚Äù them.\nmy_func2 \u0026lt;- function(n = 100, mu = 0, sd = 1, r = 0) { # simulate data dat \u0026lt;- faux::rnorm_multi( n = n, vars = 2, mu = mu, sd = sd, r = r, varnames = c(\u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;) ) # test high-low difference t.test(dat$high, dat$low, paired = TRUE) } This lets you run the function without any arguments.\nmy_func2() ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 0.94057, df = 99, p-value = 0.3492 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.1338159 0.3750168 ## sample estimates: ## mean of the differences ## 0.1206004 And then I can add in new values or my data-generating parameters from the code above.\nmy_func2(n = 200, mu = my_mu, sd = my_sd, r = my_r) ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 2.2674, df = 199, p-value = 0.02444 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.02327751 0.33404535 ## sample estimates: ## mean of the differences ## 0.1786614 Your function doesn‚Äôt need to use the same variable names as the functions you might be using them in. Some people find using the same variable names to be easier because you can see the connection between the variable in your function and where you‚Äôre using it. But this can be confusing for new coders. You can give your function argument names that are different to clarify where you‚Äôre using them.\nIf this pattern makes sense to you, I recommend using a consistent prefix to the name, like the_, so you can always know if a variable is being defined as an argument to the function or externally.\nmy_func3 \u0026lt;- function(the_n = 100, the_mu = 0, the_sd = 1, the_r = 0) { # simulate data dat \u0026lt;- faux::rnorm_multi( n = the_n, vars = 2, mu = the_mu, sd = the_sd, r = the_r, varnames = c(\u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;) ) # test high-low difference t.test(dat$high, dat$low, paired = TRUE) } If you‚Äôre using argument names in your function call, you will need to make sure they‚Äôre consistent with the function.\nmy_func3(the_n = my_n, the_mu = my_mu, the_sd = my_sd, the_r = my_r) ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 0.80255, df = 49, p-value = 0.4261 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.1585849 0.3694730 ## sample estimates: ## mean of the differences ## 0.105444 Or you can set the arguments by order and omit the names.\nmy_func3(my_n, my_mu, my_sd, my_r) ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 0.29191, df = 49, p-value = 0.7716 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.2255497 0.3022130 ## sample estimates: ## mean of the differences ## 0.03833165  Scope The concept of scope can also be confusing to new coders. In this context it‚Äôs just important to know that if you have argument names that are the same as variables in your environment, the function will use the values set by its arguments, not the ones set in your global environment (what you can see in the Environment tab in RStudio).\nIn other words, a function has access to variables in the global environment, but also has variables created by that function‚Äôs arguments, which can overwrite the values of variables with the same name in the global environment.\nFor that reason, I advise new coders to avoid giving the parameter values in their global environment the same names as the arguments of the functions they are used in. this is fine, but can lead to confusion unless you have a very clear conceptual understanding of scope.\nmy_func4 \u0026lt;- function(my_n = 100, my_mu = 0, my_sd = 1, my_r = 0) { # simulate data dat \u0026lt;- faux::rnorm_multi( n = my_n, vars = 2, mu = my_mu, sd = my_sd, r = my_r, varnames = c(\u0026quot;low\u0026quot;, \u0026quot;high\u0026quot;) ) # test high-low difference t.test(dat$high, dat$low, paired = TRUE) } For example, the function above has arguments called my_n, my_mu, my_sd and my_r. We can also create variables with those same names in the global environment.\n# my data-generating parameters my_n \u0026lt;- 50 my_mu \u0026lt;- c(0, 0.2) my_sd \u0026lt;- c(1, 1) my_r \u0026lt;- 0.5 However, when you run the function without setting the arguments in the function, it uses the default values of the arguments, not the values you set in the global environment.\nmy_func4() ## ## Paired t-test ## ## data: dat$high and dat$low ## t = -0.25649, df = 99, p-value = 0.7981 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.3074508 0.2370637 ## sample estimates: ## mean of the differences ## -0.03519355 If you set the values in the function, then it will work as expected.\nmy_func4(my_n, my_mu, my_sd, my_r) ## ## Paired t-test ## ## data: dat$high and dat$low ## t = 4.0469, df = 49, p-value = 0.0001838 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.2497333 0.7423856 ## sample estimates: ## mean of the differences ## 0.4960594  ","date":1608163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608163200,"objectID":"c732e265bd8f4cf2fabffcbea5936c02","permalink":"https://debruine.github.io/post/function-tips/","publishdate":"2020-12-17T00:00:00Z","relpermalink":"/post/function-tips/","section":"post","summary":"I see a lot of functions from people new to coding that look like this and I want to point out a few common conceptual mistakes with writing functions.","tags":["functions"],"title":"Function Tips","type":"post"},{"authors":null,"categories":["rstats"],"content":" One of my favourite colleagues, Phil McAleer, asked about unequal sample sizes for Mann-Whitney tests on our group chat today. I had no idea, so, as always, I thought ‚ÄúThis is a job for simulations!‚Äù\nI started by loading tidyverse, since I know I‚Äôll need to wrangle data and plot things. I‚Äôm starting to get more comfortable with base R for package development, and it can make things faster, but tidyverse is my favourite for a quick analysis or a pipeline where understandability is more important than speed.\nAnd I set my favourite seed so my simulations will give me a reproducible answer.\nlibrary(tidyverse) set.seed(8675309) Then I wrote a wee function to simulate data with the parameters I‚Äôm interested in varying, run a Mann-Whitney test, and return the p-value (all I need to look at power and false positives).\nFirst, I just wanted to look at false positives for different sample size, so I set n1 and n2 as arguments and set alternative with a default of ‚Äútwo.sided‚Äù. The function wilcox.test runs a Mann-Whitney test for independent samples.\nmw \u0026lt;- function(n1, n2, alternative = \u0026quot;two.sided\u0026quot;) { x1 \u0026lt;- rnorm(n1) x2 \u0026lt;- rnorm(n2) w \u0026lt;- wilcox.test(x1, x2, alternative = alternative) w$p.value } Now I need to set up a table with all of the values I want to run simulations for. I set n1 and n2 to the numbers 10 to 100 in steps of ten. This was crossed with the number of replications I wanted to run (1000). I then removed the values where n2 \u0026gt; n1, since they‚Äôre redundant with the opposite version (e.g., n1 = 10, n2 = 20 is the same as n1 = 20, n2 = 10).\nparams \u0026lt;- expand.grid( n1 = seq(10, 100, 10), n2 = seq(10, 100, 10), reps = 1:1000 ) %\u0026gt;% filter(n1 \u0026lt;= n2)   n1 n2 reps    10 10 1  10 20 1  20 20 1  ‚Ä¶ ‚Ä¶ ‚Ä¶  80 100 1000  90 100 1000  100 100 1000    I then used the pmap_dbl function from purrr to map the values from n1 and n2 onto mw, then grouped the results by n1 and n2 and calculated false_pos as the proportion of p less than alpha.\nalpha \u0026lt;- 0.05 mw1 \u0026lt;- params %\u0026gt;% mutate(p = pmap_dbl(list(n1, n2), mw)) %\u0026gt;% group_by(n1, n2) %\u0026gt;% summarise(false_pos = mean(p \u0026lt; alpha), .groups = \u0026quot;drop\u0026quot;) Then I plotted the false positive rate for each combination against the difference between n1 and n2. You can see that the false positive rate is approximately nominal, or equal to the specified alpha of 0.05.\nggplot(mw1, aes(n2 - n1, false_pos)) + geom_point(aes(color = as.factor(n1))) + geom_smooth(formula = y ~ x, method = lm, color = \u0026quot;black\u0026quot;) + labs(x = \u0026quot;N2 - N1\u0026quot;, y = \u0026quot;False Positive Rate\u0026quot;, color = \u0026quot;N1\u0026quot;) + ylim(0, .1) But what if data aren‚Äôt drawn from a normal distribution? We can change the mw() function to simulate data from a different distribtion, such as uniform, and run the whole process again.\nmw \u0026lt;- function(n1, n2, alternative = \u0026quot;two.sided\u0026quot;) { x1 \u0026lt;- runif(n1) x2 \u0026lt;- runif(n2) w \u0026lt;- wilcox.test(x1, x2, alternative = alternative) w$p.value } The rest of our code is identical to above.\nmw2 \u0026lt;- params %\u0026gt;% mutate(p = pmap_dbl(list(n1, n2), mw)) %\u0026gt;% group_by(n1, n2) %\u0026gt;% summarise(false_pos = mean(p \u0026lt; alpha), .groups = \u0026quot;drop\u0026quot;) This doesn‚Äôt seem to make much difference.\nWhat if the variance between the two samples is different? First, let‚Äôs adjust the mw() function to vary the SD of the two samples. We‚Äôll give sd1 a default value of 1 and sd2 will default to the same as sd1. We might as well add the option to change the means, so default m1 to 0 and m2 to the same as m1.\nmw \u0026lt;- function(n1, m1 = 0, sd1 = 1, n2 = n1, m2 = m1, sd2 = sd1, alternative = \u0026quot;two.sided\u0026quot;) { x1 \u0026lt;- rnorm(n1, m1, sd1) x2 \u0026lt;- rnorm(n2, m2, sd2) w \u0026lt;- wilcox.test(x1, x2, alternative = alternative) w$p.value } Now we need to set up a new list of parameters to change. The Ns didn‚Äôt make much difference last time, so let‚Äôs vary them in steps of 20 this time. We‚Äôll vary sd1 and sd2 from 0.5 to 2 in steps of 0.5, and also only keep combinations where sd1 is less than or equal to sd2 to avoid redundancy.\nparams \u0026lt;- expand.grid( reps = 1:1000, n1 = seq(10, 100, 20), n2 = seq(10, 100, 20), sd1 = seq(0.5, 2, 0.5), sd2 = seq(0.5, 2, 0.5) ) %\u0026gt;% filter(n1 \u0026lt;= n2, sd1 \u0026lt;= sd2) mw3 \u0026lt;- params %\u0026gt;% mutate(p = pmap_dbl(list(n1, 0, sd1, n2, 0, sd2), mw)) %\u0026gt;% group_by(n1, n2, sd1, sd2) %\u0026gt;% summarise(false_pos = mean(p \u0026lt; alpha), .groups = \u0026quot;drop\u0026quot;) It looks like differences in SD make a big difference in the false positive rate, and the effect is bigger as Ns and SDs get more unequal.\nggplot(mw3, aes(sd2 - sd1, false_pos, color = as.factor(n2-n1))) + geom_point() + geom_smooth(formula = y ~ x, method = lm) + labs(x = \u0026quot;SD2 - SD1\u0026quot;, y = \u0026quot;False Positive Rate\u0026quot;, color = \u0026quot;N2-N1\u0026quot;) I‚Äôll leave it to the enterprising reader to simulate power for different effect sizes.\n","date":1599091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599091200,"objectID":"e8da362ba889910e6bfd6d5f56f6cba8","permalink":"https://debruine.github.io/post/mann-whitney/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/post/mann-whitney/","section":"post","summary":"One of my favourite colleagues, Phil McAleer, asked about unequal sample sizes for Mann-Whitney tests on our group chat today. I had no idea, so, as always, I thought ‚ÄúThis is a job for simulations!","tags":["r","mann whitney","non-parametric","power","false positives","simulation"],"title":"Mann-Whitney False Positives","type":"post"},{"authors":null,"categories":["rstats","simulation"],"content":" Today I was trying to figure out how to advise on the number of simulations to run when calculating power by simulation.\nI tackled this question by running a simulation (of course).\nlibrary(ggplot2) library(dplyr) # I love pipes set.seed(8675309) I wanted to figure out how close to the true power was the calculated power from a simulation where the number of replications ranges from 100 to 10K (in steps of 100) and power ranges from 0.5 to 1 in steps of .05 (the result is symmetric around 50%, so the figures below for 80% power also apply to 20% power)..\nFirst, I made all possible combinations of replications and power.\nx \u0026lt;- expand.grid( reps = seq(100, 1e4, 100), power = seq(0.5, 1, .05) ) Then, for each combination, I calculated the proportion of significant analyses in 10K simulations. I assumed this would have a binomial distribution where size is the number of replications in each simulation and probability is the true power. I then calculated the absolute difference from the true value of power and reported the mean (I find it more intuitive than SD or variance).\nx$diff \u0026lt;- mapply(function(size, prob) { sig \u0026lt;- rbinom(1e4, size, prob) / size diff \u0026lt;- abs(sig - prob) mean(diff) }, size = x$reps, prob = x$power) I plotted the results to see if they make sense. As the number of replications per simulation increases, the mean difference from the true power decreases. Accuracy is higher for larger values of power.\nI also calculated the minimum number of replications to get a result that is, on average, less than 1% off from a power of 80%\nfilter(x, power == .8, diff \u0026lt; .01) %\u0026gt;% pull(reps) %\u0026gt;% min() ## [1] 1100 I also calculated the .95 quantile to see how many replications you need to run to get within 1% of the true value.\nx$q95 \u0026lt;- mapply(function(size, prob) { sig \u0026lt;- rbinom(1e4, size, prob) / size diff \u0026lt;- abs(sig - prob) quantile(diff, .95) }, size = x$reps, prob = x$power) Turns out you need a lot more.\nfilter(x, power == .8, q95 \u0026lt; .01) %\u0026gt;% pull(reps) %\u0026gt;% min() ## [1] 6300 ","date":1597622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597622400,"objectID":"609876420c2b36d110ff8751e95d79cf","permalink":"https://debruine.github.io/post/how-many-sims/","publishdate":"2020-08-17T00:00:00Z","relpermalink":"/post/how-many-sims/","section":"post","summary":"Today I was trying to figure out how to advise on the number of simulations to run when calculating power by simulation.\nI tackled this question by running a simulation (of course).","tags":["simulation","r","power"],"title":"How many simulations in my power analysis?","type":"post"},{"authors":null,"categories":["rstats"],"content":" I‚Äôm a huge fan of unit tests, but it‚Äôs tricky to test interactive functions where the user needs to enter input before the function can progress. I used to test them manually, which is incredibly tedious and time-consuming. So I ended up not testing interative functions very thoroughly. I found a post on Stack Overflow with a useful answer by znk. I‚Äôve expanded their answer into a full example of a unit test for an interactive function.\nlibrary(testthat) Set up the function Your function needs to use readLines to get interactive input and take an argument for the connection (con). The default value for the connection should be the same as its default value for readLines, which is stdin() (the terminal). You can‚Äôt use readline, which only supports connection to the terminal.\nThis function displays a prompt and a list of valid options. If your response isn‚Äôt in the list, it will repeat the prompt until it is.\nask_opts \u0026lt;- function(prompt, opts = NULL, con = stdin()) { # display prompt and options optlist \u0026lt;- paste(opts, collapse = \u0026quot;|\u0026quot;) prompt_opt \u0026lt;- paste0(prompt, \u0026quot; [\u0026quot;, optlist, \u0026quot;]\\n\u0026quot;) cat(prompt_opt) input \u0026lt;- readLines(con = con, n = 1) # repeat if input is not in opts if (!is.null(opts) \u0026amp; !input %in% opts) { input \u0026lt;- ask_opts(prompt, opts, con) } input } Set up the Test You need to create a file containing the input you want to send to the function, one input per line. I want to answer the first time with something not in the option list, then the second time with something that is in the option list.\n# set up interactive answers f \u0026lt;- file() lines \u0026lt;- c(\u0026quot;echidna\u0026quot;, \u0026quot;ferret\u0026quot;) ans \u0026lt;- paste(lines, collapse = \u0026quot;\\n\u0026quot;) write(ans, f) Then run your interactive function, setting the connection to your file. Run it inside capture_output_lines if you want to test the prompts and not just the output. Close the file when you are done with it.\nprompt \u0026lt;- \u0026quot;What is your favourite animal?\u0026quot; opts \u0026lt;- c(\u0026quot;cat\u0026quot;, \u0026quot;dog\u0026quot;, \u0026quot;ferret\u0026quot;) output_prompts \u0026lt;- capture_output_lines({ result \u0026lt;- ask_opts(prompt, opts, f) }) close(f) # close the file Now you can run your tests\ntxt \u0026lt;- \u0026quot;What is your favourite animal? [cat|dog|ferret]\u0026quot; expect_equal(result, \u0026quot;ferret\u0026quot;) expect_equal(output_prompts, rep(txt, 2))  Without a new argument What if you don‚Äôt want to change the arguments to your function to add a connection? You can set the connection in the options and test for it in the function, defaulting to stdin(). For example:\nask_opts \u0026lt;- function(prompt, opts = NULL) { # set up connection, default to stdin() if not set con \u0026lt;- getOption(\u0026quot;ask_opts.con\u0026quot;, stdin()) # display prompt and options optlist \u0026lt;- paste(opts, collapse = \u0026quot;|\u0026quot;) prompt_opt \u0026lt;- paste0(prompt, \u0026quot; [\u0026quot;, optlist, \u0026quot;]\\n\u0026quot;) cat(prompt_opt) input \u0026lt;- readLines(con = con, n = 1) # repeat if input is not in opts if (!is.null(opts) \u0026amp; !input %in% opts) { input \u0026lt;- ask_opts(prompt, opts) } input } Then you just need to set this option before you run the interactive function in your testing environment. Make sure to reset it to stdin() when you‚Äôre done.\ntest_that(\u0026quot;interactive\u0026quot;, { # set up interactive answers f \u0026lt;- file() lines \u0026lt;- c(\u0026quot;maybe\u0026quot;, \u0026quot;y\u0026quot;) ans \u0026lt;- paste(lines, collapse = \u0026quot;\\n\u0026quot;) write(ans, f) options(\u0026quot;ask_opts.con\u0026quot; = f) # set connection option # run interactive function prompt \u0026lt;- \u0026quot;Was this helpful?\u0026quot; opts \u0026lt;- c(\u0026quot;y\u0026quot;, \u0026quot;n\u0026quot;) output_prompts \u0026lt;- capture_output_lines({ result \u0026lt;- ask_opts(prompt, opts) }) close(f) # close the file options(\u0026quot;ask_opts.con\u0026quot; = stdin()) # reset connection option # tests txt \u0026lt;- \u0026quot;Was this helpful? [y|n]\u0026quot; expect_equal(result, \u0026quot;y\u0026quot;) expect_equal(output_prompts, rep(txt, 2)) })   ","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596153600,"objectID":"e74e6247ea1a5878cf192854c86548b8","permalink":"https://debruine.github.io/post/interactive-test/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/post/interactive-test/","section":"post","summary":"I‚Äôm a huge fan of unit tests, but it‚Äôs tricky to test interactive functions where the user needs to enter input before the function can progress. I used to test them manually, which is incredibly tedious and time-consuming.","tags":["R","interactive","test","testthat"],"title":"Testing interactive functions","type":"post"},{"authors":null,"categories":["rstats"],"content":" I was working on a simulation project with an undergraduate dissertation student today (I‚Äôm so amazed at what our students can do now!) and wanted to show her how to efficiently run simulations for all combinations of a range of parameters. It took 20 minutes of googling map functions in purrr to figure it out. I find I have to do this every time I want to use this pattern, so I decided to write a quick tutorial on it.\nYou‚Äôll need functions from the purrr library, as well as some dplyr and tidyr functions, so I just load the whole tidyverse.\nlibrary(tidyverse) Fisrt, I need to define the function I want to run for the imulation. I‚Äôll make a relatively simple one, that takes the samples sizes, means and standard deviations for two samples, simulates data, and returns the sample effect size, t-value, p-value, and degrees of freedom from t.test.\nmy_t_sim \u0026lt;- function(n1 = 100, m1 = 0, sd1 = 1, n2 = 100, m2 = 0, sd2 = 1) { # simulate data grp1 \u0026lt;- rnorm(n1, m1, sd1) grp2 \u0026lt;- rnorm(n2, m2, sd2) # analyse tt \u0026lt;- t.test(grp1, grp2) # calculate cohens d for independent samples s_pooled \u0026lt;- sqrt(((n1-1) * sd(grp1)^2 + (n2-1) * sd(grp2)^2)/(n1+n2)) d \u0026lt;- (tt$estimate[[1]] - tt$estimate[[2]]) / s_pooled # return named list of values list(d = d, t = tt$statistic[[1]], df = tt$parameter[[1]], p = tt$p.value) } So we can simulate a study with 20 observations in each group and an effect size of 0.5.\nmy_t_sim(n1 = 20, m1 = 100, sd1 = 10, n2 = 20, m2 = 105, sd2 = 10) ## $d ## [1] -0.7037 ## ## $t ## [1] -2.169 ## ## $df ## [1] 33.89 ## ## $p ## [1] 0.0372 If you want to run it 100 times, you can use the map_df() function to create a data frame of the results for each repeat.\nresults \u0026lt;- map_df(1:100, ~my_t_sim(n1 = 20, m1 = 100, sd1 = 10, n2 = 20, m2 = 105, sd2 = 10))   d t df p    -0.6277 -1.9346 34.22 0.0613  -0.2027 -0.6247 38.00 0.5359  -0.1913 -0.5898 35.22 0.5591  -0.7094 -2.1865 37.58 0.0351  -0.4612 -1.4215 38.00 0.1633  -0.9266 -2.8560 37.52 0.0070    But this only lets you run one set of arguments for n1, n2, m1, m2, sd1, and sd2. What if you want to run the function 100 times for each of a range of parameters?\nFirst, set up a data frame that contains every combination of parameters you want to explore using the crossing() function. The function seq() makes a vector ranging from the first argument to the second, in steps of the third (e.g., seq(30, 60, 5) makes the vector c(30, 35, 40, 45, 50, 55, 60)). If you don‚Äôt want to vary a parameter, set it to a single value.\nparams \u0026lt;- crossing( n1 = seq(30, 120, 5), m1 = seq(0, 0.5, 0.1), sd1 = 1, m2 = 0, sd2 = 1 ) %\u0026gt;% mutate(n2 = n1) You can now use the function pmap_dfr to iterate over the rows of the params data table, using the values as arguments to the function my_t_sim.\nresults \u0026lt;- pmap_dfr(params, my_t_sim)   d t df p    -0.2321 -0.8836 55.35 0.3807  0.3326 1.2663 53.97 0.2108  0.2874 1.0944 56.30 0.2784  0.2734 1.0410 50.49 0.3028  0.5160 1.9647 57.99 0.0542  0.1670 0.6361 57.81 0.5273    You can also wrap this in an anonymous function and do some more processing on the results, like running each combination 100 times and adding the parameters to the data table.\nresults \u0026lt;- pmap_dfr(params, function(...) { args \u0026lt;- list(...) # get list of named arguments # run 500 replications per set of parameters map_df(1:500, ~my_t_sim(n1 = args$n1, m1 = args$m1, sd1 = args$sd1, n2 = args$n2, m2 = args$m2, sd2 = args$sd2)) %\u0026gt;% mutate(!!!args) # add columns to specify arguments }) The three dots in function(...) lets this function takes any named arguments. You need to assign that list of arguments using args \u0026lt;- list(...) and then you can use the arguments in your code (e.g., args$n1).\nThe triple bang (!!!) expands a list in tidyverse functions. For example, mutate(!!!args) is equivalent to mutate(n1 = args$n1, m1 = args$m1, sd1 = args$sd1, n2 = args$n2, m2 = args$m2, sd2 = args$sd2).\nNow you have a data table with 57000 results. You can summarise or graph these results to look at how varying parameters systematically affects things like effect size or power.\nresults %\u0026gt;% group_by(n1, n2, m1, m2) %\u0026gt;% summarise(power = mean(p \u0026lt; .05)) %\u0026gt;% ggplot(aes(n1, power, color = as.factor(m1))) + geom_hline(yintercept = 0.05) + geom_hline(yintercept = 0.80) + geom_point() + geom_line() + scale_color_discrete(name = \u0026quot;Effect Size\u0026quot;) + xlab(\u0026quot;Number of observations per group\u0026quot;) + scale_y_continuous(breaks = seq(0,1,.2)) ","date":1580947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580947200,"objectID":"3f479c87e9cc0604c6ea3e21c119647f","permalink":"https://debruine.github.io/post/pmap_df/","publishdate":"2020-02-06T00:00:00Z","relpermalink":"/post/pmap_df/","section":"post","summary":"I was working on a simulation project with an undergraduate dissertation student today (I‚Äôm so amazed at what our students can do now!) and wanted to show her how to efficiently run simulations for all combinations of a range of parameters.","tags":["r","purrr","pmap_dfr","function","simulation"],"title":"Inputting data table rows as function arguments","type":"post"},{"authors":null,"categories":["methods"],"content":"  I recently responded to a tweet about a preprint about whether people can see Dark Triad traits (narcissism, Machiavellianism, and psychopathy) in facial appearance.\nCan you tell a Dark Triad person from the face? Apparently so (data from USA and Turkey). https://t.co/BxZUcJ9cTY pic.twitter.com/xh1pcmyB5E ‚Äî David Schmitt (@PsychoSchmitt) January 27, 2020   The preprint by Alper, Bayrak, and Yilmaz used faces from the Faceaurus database (Holtzman, 2011). ‚ÄúHoltzman (2011) standardized the assessment scores, computed average scores of self- and peer-reports, and ranked the face images based on the resulting scores. Then, prototypes for each of the personality dimensions were created by digitally combining 10 faces with the highest and 10 faces with the lowest scores on the personality trait in question (Holtzman, 2011).‚Äù This was done separately for male and female faces.\nSince scores on the three dark triad traits are positively correlated, the three pairs of composite faces are not independent. Indeed, Holtzman states that 5 individuals were in all three low composites for the male faces, while the overlap was less extreme in other cases. With 105 observers, Holtzman found that the ability to detect the composite higher in a dark triad trait was greater than chance.\nWhile I commend both Holtzman and Alper, Bayrak, and Yilmaz for their transparency, data sharing, and material sharing, I am arguing that this test has an effective N of 2, and that further replications using these images, such as those done by Alper, Bayrak, and Yilmaz, regardless of number of observers or preregistered status, lend no further weight of evidence to the assertion that dark triad traits are visible in physical appearance.\nWomen‚Äôs height Let‚Äôs go back to my favourite example for demonstrating the problems with aggregating ratings before analysis, Armenian women‚Äôs height. The problem is the same here, but we‚Äôve just averaged the stimuli before rating, rather than averaging the ratings of individual stimuli.\nFirst, we‚Äôre going to simulate a sample of 20 women from a population with a mean height of 158.1 cm and an SD of 5.7. Half are born on odd days and half on even days.\nset.seed(8675309) stim_n \u0026lt;- 10 height_m \u0026lt;- 158.1 height_sd \u0026lt;- 5.7 odd \u0026lt;- rnorm(stim_n, height_m, height_sd) even \u0026lt;- rnorm(stim_n, height_m, height_sd) t.test(odd, even) ## ## Welch Two Sample t-test ## ## data: odd and even ## t = 1.7942, df = 17.409, p-value = 0.09016 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.7673069 9.5977215 ## sample estimates: ## mean of x mean of y ## 161.1587 156.7435 A t-test shows no significant difference, which is unsurprising. We simulated the data from the same distributions, so we know for sure there is no real difference here. Now we‚Äôre going to average the height of the women with odd and even birthdays.\nodd_mean \u0026lt;- mean(odd) even_mean \u0026lt;- mean(even) So if we create a composite of women born on odd days, she would be 161.2 cm tall, and a composite of women born on even days would be 156.7 cm tall.\nIf we ask 100 observers to look at these two composites and judge which one looks taller, what do you imagine would happen? Let‚Äôs say that observers are pretty bad with height estimation, and their estimates for each composite have error with a standard deviation of 10 cm. They then judge whether, by their estimation, the odd-birthday composite looks taller than the even-birthday composite.\nobs_n \u0026lt;-100 error_sd \u0026lt;- 10 odd_estimate \u0026lt;- odd_mean + rnorm(obs_n, 0, error_sd) even_estimate \u0026lt;- even_mean + rnorm(obs_n, 0, error_sd) judgment \u0026lt;- odd_estimate \u0026gt; even_estimate bt \u0026lt;- binom.test(sum(judgment), obs_n, p = 0.5) %\u0026gt;% print() ## ## Exact binomial test ## ## data: sum(judgment) and obs_n ## number of successes = 65, number of trials = 100, p-value = 0.003518 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.5481506 0.7427062 ## sample estimates: ## probability of success ## 0.65 A binomial test shows that they are significantly better than chance at this (p = 0.004). What‚Äôs going on?\nWe can be sure that by chance alone, our two composites will be at least slightly different on any measure, even if they are drawn from identical populations. The mean (unsigned) size of this difference is larger, the smaller the number of stimuli that go into each composite. The graph below shows simulations of the unsigned difference between composites for 1000 samples per number of stimuli per composite.\nx \u0026lt;- replicate(10000, mean(rnorm(10))-mean(rnorm(10))) With only 10 stimuli per composite, the mean unsigned effect size of the difference between composites is 0.36 (in units of SD of the original trait distribution). 65% of random pairs have a difference of greater than 0.2 SD. If our observers are accurate enough at perceiving this difference or we run a very large number of observers, we are virtually guarateed to find significant results every time, and we have a 50% chance that all of these results will be in the predicted direction.\n Personality Traits and Faces So what does this mean for studies of the link between personality traits and facial appearance? The analogy with birth date and height holds. As long as there are facial morphologies that are even slightly consistently associated with the perception of a trait, then composites will not be identical in that morphology, even if it is totally unassociated with the trait as measured by, e.g., personality scales or peer report.\n The smaller the number of stimuli that go into each composite, the greater the chance that they will be visibly different in morphology related to the judgment of interest, just by chance alone. The larger the number of observers or the better observers are at detecting small differences in this morphology, the more likley that ‚Äúdetection‚Äù will be significantly above chance. Repeating this with a new set of observers does not increase the amount of evidence you have for the association between the face morphology and the measured trait. You‚Äôve only measured it once in one population of faces. If observers are your unit of analyses, you are making conclusions about whether the population of observers can detect the difference between your stimuli, you cannot generalise this to new stimulus sets.   References Alper, S., Bayrak, F., \u0026amp; Yilmaz, O. (2020, January 27). All the Dark Triad and Some of the Big Five Traits are Visible in the Face. https://doi.org/10.31234/osf.io/c3ngz\nHoltzman, N. S. (2011). Facing a psychopath: Detecting the dark triad from emotionally-neutral faces, using prototypes from the Personality Faceaurus. Journal of Research in Personality, 45, 648-654. https://doi.org/10.1016/j.jrp.2011.09.002\n ","date":1580428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580428800,"objectID":"056f5a481cb66890ff209c9a70a0c865","permalink":"https://debruine.github.io/post/composite-images/","publishdate":"2020-01-31T00:00:00Z","relpermalink":"/post/composite-images/","section":"post","summary":"I recently responded to a tweet about a preprint about whether people can see Dark Triad traits (narcissism, Machiavellianism, and psychopathy) in facial appearance.\nCan you tell a Dark Triad person from the face?","tags":["methods","simulation"],"title":"Composite Images","type":"post"},{"authors":null,"categories":["rstats"],"content":"  Shiny app for a face-rating example. library(tidyverse) library(lmerTest) set.seed(90210) Imagine you want to find out if Armenian women born on an even-numbered day are taller than women born on an odd-numbered day. (I‚Äôve chosen Armenian women because they‚Äôre the first row in this paper.)\nFirst, let‚Äôs simulate a group of 20 women born on even-numbered days and 20 women born on odd-numbered days.\nstim_n \u0026lt;- 20 # height stats from https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018962 height_m \u0026lt;- 158.1 height_sd \u0026lt;- 5.7 stim \u0026lt;- tibble( stim_id = 1:(stim_n*2), birthday = rep(c(\u0026quot;odd\u0026quot;, \u0026quot;even\u0026quot;), stim_n), height = rnorm(stim_n*2, height_m, height_sd) ) Obviously, the oddness of date of birth is not going to have any effect on women‚Äôs actual height and a two-sample t-test confirms this. However, there is a small difference between the means of the groups just due to chance (2.81 cm).\nt.test(stim$height ~ stim$birthday) ## ## Welch Two Sample t-test ## ## data: stim$height by stim$birthday ## t = -1.5, df = 38, p-value = 0.1 ## alternative hypothesis: true difference in means between group even and group odd is not equal to 0 ## 95 percent confidence interval: ## -6.4997 0.8767 ## sample estimates: ## mean in group even mean in group odd ## 154.9 157.7 Measurement with Error But what if we don‚Äôt measure height from each women once, but have a few different raters estimate it? The raters will each have their own bias, systematically overestimating or underestimating height on average. Let‚Äôs simulate 20 raters who have biases with an SD of 2 cm.\nrater_n \u0026lt;- 20 rater_bias_sd \u0026lt;- 2 rater \u0026lt;- tibble( rater_id = 1:rater_n, rater_bias = rnorm(rater_n, 0, rater_bias_sd) ) New we can get each rater to estimate the height of each woman. Their estimate is the woman‚Äôs actual height, plus the rater‚Äôs bias, plus some error (sampled from a normal distribution with a mean of 0 and an SD of 4 cm, since estimating height is hard).\ndat \u0026lt;- expand.grid( rater_id = rater$rater_id, stim_id = stim$stim_id ) %\u0026gt;% left_join(rater, by = \u0026quot;rater_id\u0026quot;) %\u0026gt;% left_join(stim, by = \u0026quot;stim_id\u0026quot;) %\u0026gt;% mutate( error = rnorm(nrow(.), 0, 4), estimate = height + rater_bias + error )  Aggregating by Stimuli You can aggregate by stimuli, that is, average the 20 raters‚Äô estimate for each stimulus. You now have 40 mean estimates that are fairly well-correlated with the women‚Äôs actual heights.\ndat_agg_by_stim \u0026lt;- dat %\u0026gt;% group_by(stim_id, birthday, height) %\u0026gt;% summarise(mean_estimate = mean(estimate)) ## `summarise()` has grouped output by \u0026#39;stim_id\u0026#39;, \u0026#39;birthday\u0026#39;. You can override using the `.groups` argument. You get pretty much the same result when you compare these mean estimates between the groups of women with odd and even birthdays.\nt.test(dat_agg_by_stim$mean_estimate ~ dat_agg_by_stim$birthday) ## ## Welch Two Sample t-test ## ## data: dat_agg_by_stim$mean_estimate by dat_agg_by_stim$birthday ## t = -1.4, df = 38, p-value = 0.2 ## alternative hypothesis: true difference in means between group even and group odd is not equal to 0 ## 95 percent confidence interval: ## -6.473 1.130 ## sample estimates: ## mean in group even mean in group odd ## 155.2 157.9  Aggregating by Raters Alternatively, you can aggregate by raters, that is, average the 20 odd-group estimates and 20 even-group estimates for each rater. Now raters are your unit of analysis, so you‚Äôve increased your power by having 20 raters and a within-subject design (each rater estimates heights for both odd- and even-birthday groups).\ndat_agg_by_rater \u0026lt;- dat %\u0026gt;% group_by(rater_id, birthday) %\u0026gt;% summarise(mean_estimate = mean(estimate)) %\u0026gt;% spread(birthday, mean_estimate) ## `summarise()` has grouped output by \u0026#39;rater_id\u0026#39;. You can override using the `.groups` argument. t.test(dat_agg_by_rater$odd, dat_agg_by_rater$even, paired = TRUE) ## ## Paired t-test ## ## data: dat_agg_by_rater$odd and dat_agg_by_rater$even ## t = 11, df = 19, p-value = 0.000000002 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 2.145 3.198 ## sample estimates: ## mean of the differences ## 2.672 Now the difference between the odd- and even-birthday groups is highly significant! What‚Äôs going is that you now have a relatively accurate estimate of the chance mean difference between the 20 women in the odd-birthday group and the 20 women in the even-birthday group. Since raters are the unit of analysis, this effect is likely to generalise to the larger population of potential raters, but only when they are rating these exact stimuli. Your conclusions cannot generalise beyond the stimulus set used here.\nWhile this seems like an obvious problem when the question is whether Armenian women with odd birthdays are taller or shorter than Armenian women with even birthdays, the problem is not so obvious for other questions, like whether boxers who won their last match have more masculine faces than boxers who lost their last match. The point of this tutorial isn‚Äôt to call out any particular studies (I‚Äôve certainly done this wrong myself plenty of times in the past), but to illustrate the enormous problem with this method and to explain the solution.\nThe larger the number of raters, the larger this false positive problem becomes because you‚Äôre increasing power to detect the small chance diffference between the two groups. You can play around with how changing parameters changes the power and false positive rates for by-stimulus, by-rater, and mixed effect designs at this shiny app.\n Mixed Effect Model In the particular case above, we‚Äôre only interested in the between-stimulus (and within-rater) main effect of birthday oddness. Therefore, aggregating by stimuli doesn‚Äôt inflate your false positive rate, while aggregating by rater does. However, other designs might have increased false positives for aggregating by stimuli but not by rater, or when aggregating by either.\nA mixed effects model avoids the problems of aggregation completely by modelling random variation for both the stimuli and raters, as well as random variation in the size of within-group effects.\nI effect code the birthday variable to make interpretation of the effects easier). # effect-code birthday dat$birthday.e \u0026lt;- recode(dat$birthday, \u0026quot;odd\u0026quot; = 0.5, \u0026quot;even\u0026quot; = -0.5) mod \u0026lt;- lmer(estimate ~ birthday.e + # random slope for effect of birthday, random intercept for rater bias (1 + birthday.e || rater_id) + # random intercept for variation in stim height (1 | stim_id), data = dat) summary(mod) ## Linear mixed model fit by REML. t-tests use Satterthwaite\u0026#39;s method [ ## lmerModLmerTest] ## Formula: estimate ~ birthday.e + (1 + birthday.e || rater_id) + (1 | stim_id) ## Data: dat ## ## REML criterion at convergence: 4687 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.8414 -0.6590 0.0102 0.6776 2.6231 ## ## Random effects: ## Groups Name Variance Std.Dev. ## stim_id (Intercept) 34.4640965341 5.870613 ## rater_id birthday.e 0.0000000214 0.000146 ## rater_id.1 (Intercept) 10.0890113704 3.176320 ## Residual 15.8201186615 3.977451 ## Number of obs: 800, groups: stim_id, 40; rater_id, 20 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(\u0026gt;|t|) ## (Intercept) 156.55 1.18 55.02 132.98 \u0026lt;2e-16 *** ## birthday.e 2.67 1.88 38.00 1.42 0.16 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## birthday.e 0.000 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular The estimate for (Intercept) is just the mean height estimate (156.55 cm) and the estimate for birthday.e is the mean difference between the odd and even birthday groups (2.67 cm). You can now generalise the conclusions of this mixed effects model to both the population of raters and the population of stimuli.\nThanks to Liam Satchell, Alex Jones, and Ben Jones for the stimulating late-night Twitter discussion that prompted this blog post!  References Plenty of papers have made this point much more thoroughly Wolsiefer, Westfall, and Judd (2017).\nBarr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. ‚ÄúRandom Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.‚Äù Journal of Memory and Language 68 (3): 10.1016/j.jml.2012.11.001.  Coleman, E. B. 1964. ‚ÄúGeneralizing to a Language Population.‚Äù Psychological Reports 14 (1): 219‚Äì26. https://doi.org/10.2466/pr0.1964.14.1.219.  Judd, Charles M., Jacob Westfall, and David A. Kenny. 2012. ‚ÄúTreating Stimuli as a Random Factor in Social Psychology: A New and Comprehensive Solution to a Pervasive but Largely Ignored Problem.‚Äù Journal of Personality and Social Psychology 103 (1): 54‚Äì69. https://doi.org/doi:10.1037/a0028347.  Wolsiefer, Katie, Jacob Westfall, and Charles M. Judd. 2017. ‚ÄúModeling Stimulus Variation in Three Common Implicit Attitude Tasks.‚Äù Behavior Research Methods 49 (4): 1193‚Äì1209. https://doi.org/10.3758/s13428-016-0779-0.    ","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"a12e8e65680c565baae5e358f183e933","permalink":"https://debruine.github.io/post/aggregating/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/aggregating/","section":"post","summary":"Shiny app for a face-rating example. library(tidyverse) library(lmerTest) set.seed(90210) Imagine you want to find out if Armenian women born on an even-numbered day are taller than women born on an odd-numbered day.","tags":["r","lmer","mixed effects","anova","aggregation","simulation"],"title":"What's wrong with aggregating data?","type":"post"},{"authors":null,"categories":["rstats"],"content":" This tutorial has been moved to the tutorials section.\n","date":1546992000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546992000,"objectID":"5fe4617414b0d6bc14a08f4aa6c77935","permalink":"https://debruine.github.io/post/simulating-random-slopes/","publishdate":"2019-01-09T00:00:00Z","relpermalink":"/post/simulating-random-slopes/","section":"post","summary":"This tutorial has been moved to the tutorials section.","tags":["R","simulation","lmer","lme4"],"title":"Simulating Random Slopes","type":"post"},{"authors":null,"categories":["rstats"],"content":" library(faux) library(tidyverse) I added a new function to the package faux to generate a new dataframe from an existing dataframe, simulating all numeric columns from normal distributions with the same mean and SD as the existing data and the same correlation structure as the existing data. (Update: faux is now on CRAN!)\nFor example, here is the relationship between speed and distance in the built-in dataset cars.\ncars %\u0026gt;% ggplot(aes(speed, dist)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Figure 1: Original cars dataset  You can create a new sample with the same parameters and 500 rows with the code sim_df(cars, 500).\nsim_df(cars, 500) %\u0026gt;% ggplot(aes(speed, dist)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Figure 2: Simulated cars dataset  You can also optionally add grouping variables. For example, here is the relationship between sepal length and width in the built-in dataset iris.\niris %\u0026gt;% ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Figure 3: Original iris dataset  And here is a new sample with 50 observations of each species, made with the code sim_df(iris, 100, \"Species\").\nsim_df(iris, 50, between = \u0026quot;Species\u0026quot;) %\u0026gt;% ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Figure 4: Simulated iris dataset  For now, the function only creates new variables sampled from a continuous normal distribution. I hope to add in other sampling distributions in the future. So you‚Äôd need to do any rounding or truncating yourself.\nsim_df(iris, 50, between = \u0026quot;Species\u0026quot;) %\u0026gt;% mutate_if(is.numeric, round, 1) %\u0026gt;% ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) + geom_point() + geom_smooth(method = \u0026quot;lm\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Figure 5: Simulated iris dataset (rounded)  ","date":1546041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546041600,"objectID":"28d7110669966248a067c5d23090ba1d","permalink":"https://debruine.github.io/post/simdf/","publishdate":"2018-12-29T00:00:00Z","relpermalink":"/post/simdf/","section":"post","summary":"library(faux) library(tidyverse) I added a new function to the package faux to generate a new dataframe from an existing dataframe, simulating all numeric columns from normal distributions with the same mean and SD as the existing data and the same correlation structure as the existing data.","tags":["r","simulation","faux"],"title":"Simulate from Existing Data","type":"post"},{"authors":null,"categories":["rstats"],"content":" This tutorial has been moved to the tutorials section.\n","date":1545782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545782400,"objectID":"9762b8ea0df08740f70d8d9bfd7147ae","permalink":"https://debruine.github.io/post/simulating-mixed-effects/","publishdate":"2018-12-26T00:00:00Z","relpermalink":"/post/simulating-mixed-effects/","section":"post","summary":"This tutorial has been moved to the tutorials section.","tags":["R","simulation","lmer","lme4"],"title":"Simulating Mixed Effects","type":"post"},{"authors":null,"categories":["rstats"],"content":" library(tidyverse) Pipes are a way to order your code in a more readable format.\nLet‚Äôs say you have a small data table with 10 participant IDs, two columns with variable type A, and 2 columns with variable type B. You want to calculate the mean of the A variables and the mean of the B variables and return a table with 10 rows (1 for each participant) and 3 columns (id, A_mean and B_mean).\nOne way you could do this is by creating a new object at every step and using that object in the next step. This is pretty clear, but you‚Äôve created 6 unnecessary data objects in your environment. This can get confusing in very long scripts.\n# make a data table with 10 subjects data_original \u0026lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10, 3) ) # gather columns A1 to B2 into \u0026quot;variable\u0026quot; and \u0026quot;value\u0026quot; columns data_gathered \u0026lt;- gather(data_original, variable, value, A1:B2) # separate the variable column at the _ into \u0026quot;var\u0026quot; and \u0026quot;var_n\u0026quot; columns data_separated \u0026lt;- separate(data_gathered, variable, c(\u0026quot;var\u0026quot;, \u0026quot;var_n\u0026quot;), sep = 1) # group the data by id and var data_grouped \u0026lt;- group_by(data_separated, id, var) # calculate the mean value for each id/var data_summarised \u0026lt;- summarise(data_grouped, mean = mean(value)) ## `summarise()` regrouping output by \u0026#39;id\u0026#39; (override with `.groups` argument) # spread the mean column into A and B columns data_spread \u0026lt;- spread(data_summarised, var, mean) # rename A and B to A_mean and B_mean data \u0026lt;- rename(data_spread, A_mean = A, B_mean = B)   id A_mean B_mean    1 0.2304382 3.376790  2 -0.2460394 3.150984  3 0.4908918 2.020612  4 -0.3616511 2.706038  5 -0.5155883 2.599207  6 -0.0474370 1.913186  7 0.1864482 2.065799  8 0.5501416 2.405596  9 0.2093015 1.425043  10 -0.7423514 2.399520    You can name each object data and keep replacing the old data object with the new one at each step. This will keep you environment clean, but I don‚Äôt recommend it because it makes it too easy to accidentally run your code out of order when you are running line-by-line for development or debugging. One way to avoid extra objects is to nest your functions, literally replacing each data object with the code that generated it in the previous step. This can be fine for very short chains.\nmean_petal_width \u0026lt;- round(mean(iris$Petal.Width), 2) But it gets extremely confusing for long chains:\n# do not ever do this!! data \u0026lt;- rename( spread( summarise( group_by( separate( gather( tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10, 3)), variable, value, A1:B2), variable, c(\u0026quot;var\u0026quot;, \u0026quot;var_n\u0026quot;), sep = 1), id, var), mean = mean(value)), var, mean), A_mean = A, B_mean = B) ## `summarise()` regrouping output by \u0026#39;id\u0026#39; (override with `.groups` argument) The pipe lets you ‚Äúpipe‚Äù the result of each function into the next function, allowing you to put your code in a logical order without creating too many extra objects.\n# calculate mean of A and B variables for each participant data \u0026lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10, 3) ) %\u0026gt;% gather(variable, value, A1:B2) %\u0026gt;% separate(variable, c(\u0026quot;var\u0026quot;, \u0026quot;var_n\u0026quot;), sep=1) %\u0026gt;% group_by(id, var) %\u0026gt;% summarise(mean = mean(value)) %\u0026gt;% spread(var, mean) %\u0026gt;% rename(A_mean = A, B_mean = B) ## `summarise()` regrouping output by \u0026#39;id\u0026#39; (override with `.groups` argument) You can read this code from top to bottom as follows:\nMake a tibble called data with  id of 1 to 10, A1 of 10 random numbers from a normal distribution with a mean of 0, A2 of 10 random numbers from a normal distribution with a mean of 1, B1 of 10 random numbers from a normal distribution with a mean of 2, B2 of 10 random numbers from a normal distribution with a mean of 3; and then  Gather to create variable and value column from columns A_1 to B_2; and then Separate the column variable into 2 new columns called varand var_n, separate at character 1; and then Group by columns id and var; and then Summarise and new column called mean as the mean of the value column for each group; and then Spread to make new columns with the key names in var and values in mean; and then Rename to make columns called A_mean (old A) and B_mean (old B)  You can make intermediate objects whenever you need to break up your code because it‚Äôs getting too complicated or you need to debug something.\nYou can debug a pipe by running just the first few functions by highlighting from the beginning to just before the pipe you want to stop at. Try this by highlighting from data \u0026lt;- to the end of the separate function and typing cmd-return. What does data look like now? ","date":1545436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545436800,"objectID":"9e9f37ad815294f2281bff054c5f76eb","permalink":"https://debruine.github.io/post/pipes/","publishdate":"2018-12-22T00:00:00Z","relpermalink":"/post/pipes/","section":"post","summary":"library(tidyverse) Pipes are a way to order your code in a more readable format.\nLet‚Äôs say you have a small data table with 10 participant IDs, two columns with variable type A, and 2 columns with variable type B.","tags":["r","tidyverse","pipes"],"title":"Pipes","type":"post"},{"authors":null,"categories":["rstats"],"content":" library(tidyverse) library(faux) I‚Äôm working on a package for simulations called faux. (Update: faux is now on CRAN!)\nThe first function, rnorm_multi, makes multiple normally distributed vectors with specified relationships and takes the following arguments:\n n = the number of samples required (required) vars = the number of variables to return (default = 3) cors = the correlations among the variables (can be a single number, vars*vars matrix, vars*vars vector, or a vars*(vars-1)/2 vector; default = 0) mu = a vector giving the means of the variables (numeric vector of length 1 or vars; default = 0) sd = the standard deviations of the variables (numeric vector of length 1 or vars; default = 1) varnames = optional names for the variables (string vector of length vars; default = NULL) empirical = logical. If true, mu, sd and cors specify the empirical not population mean, sd and covariance (default = FALSE)  Example 1 The following example creates a 100-row dataframe of 3 columns names A, B, and C, with means = 0, SDs = 1, and where rAB = 0.2, rAC = -0.5, and rBC = 0.5.\nex1 \u0026lt;- rnorm_multi(100, 3, c(0.2, -0.5, 0.5), varnames=c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;)) Correlation Matrix of Sample Data    A B C    A 1.0000000 -0.087499 -0.1202283  B -0.0874990 1.000000 0.0157210  C -0.1202283 0.015721 1.0000000      Example 2 The following example calculates the correlation matrix, means, and SDs from the iris dataset and uses them to simulate a dataset of 100 rows with the same parameters.\ndat \u0026lt;- select_if(iris, is.numeric) iris_sim \u0026lt;- rnorm_multi( n = 100, vars = ncol(dat), r = cor(dat), mu = summarise_all(dat, mean) %\u0026gt;% t(), sd = summarise_all(dat, sd) %\u0026gt;% t(), varnames = names(dat) ) Correlation Matrix of Original Data    Sepal.Length Sepal.Width Petal.Length Petal.Width    Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411  Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259  Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654  Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000     Correlation Matrix of Sample Data    Sepal.Length Sepal.Width Petal.Length Petal.Width    Sepal.Length 1.0000000 -0.1591051 0.8491459 0.7544625  Sepal.Width -0.1591051 1.0000000 -0.4527400 -0.3513351  Petal.Length 0.8491459 -0.4527400 1.0000000 0.9485627  Petal.Width 0.7544625 -0.3513351 0.9485627 1.0000000      ","date":1545436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545436800,"objectID":"51caa26beb634ce7ad7ce29ce3f4b200","permalink":"https://debruine.github.io/post/rnorm_multi/","publishdate":"2018-12-22T00:00:00Z","relpermalink":"/post/rnorm_multi/","section":"post","summary":"library(tidyverse) library(faux) I‚Äôm working on a package for simulations called faux. (Update: faux is now on CRAN!)\nThe first function, rnorm_multi, makes multiple normally distributed vectors with specified relationships and takes the following arguments:","tags":["R","correlated data","simulation","faux"],"title":"Simulating Multiple Vectors","type":"post"},{"authors":null,"categories":["rstats"],"content":" library(tidyverse) I compared bar plots to violin plots in a recent talk to make the point that real data plotted with the full distribution make your effects look less impressive than minimalist bar charts that just show the means and standard errors, but give you a much better idea of what‚Äôs going on with your data.\nI also made a shiny app where you can set the sample size, main effects, and interaction effect, then view six different visualisations of the simulated data.\nI thought I‚Äôd post a quick tutorial for anyone who wants to see some code for creating violin-box plots and split-violin plots.\nFirst, let‚Äôs simulate some data from a 2x2 design with a cross-over interaction with a 0.5 SD effect size.\nn \u0026lt;- 100 data \u0026lt;- tibble( sex = rep(c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;), n), face_sex = rep(c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;), each = n) ) %\u0026gt;% mutate( dv = rnorm(n*2, 0, 1), effect = ifelse(sex==face_sex, .5, 0), dv = dv + effect ) I like to create a theme for all the plots in a talk or paper. This one is my standard white-on-black talk theme.\nbgcolor \u0026lt;- \u0026quot;black\u0026quot; textcolor \u0026lt;- \u0026quot;white\u0026quot; my_theme \u0026lt;- theme( plot.background = element_rect(fill = bgcolor, colour = bgcolor), panel.background = element_rect(fill = NA), legend.background = element_rect(fill = NA), legend.position=\u0026quot;none\u0026quot;, panel.grid.major = element_blank(), panel.grid.minor = element_blank(), text = element_text(family=\u0026#39;Fira Code\u0026#39;, colour = textcolor, size=20), axis.text = element_text(family=\u0026#39;Fira Code\u0026#39;, colour = textcolor, size=15) ) Bar Plot I‚Äôve commented it out below, but I recommend alsways using ggsave to save your plots for papers or talks. They are much better resolution than the plots you copy out of an Rmarkdown notebook.\ndata %\u0026gt;% group_by(sex, face_sex) %\u0026gt;% summarise( mean = mean(dv), se = sd(dv)/sqrt(n()) ) %\u0026gt;% ggplot(aes(sex, mean, fill=face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_col(color = \u0026quot;white\u0026quot;, position=\u0026quot;dodge\u0026quot;, alpha = 0.5) + geom_errorbar(aes(ymin = mean-se, ymax=mean+se), width=0.1, position=position_dodge(0.9), color=textcolor) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme ## `summarise()` regrouping output by \u0026#39;sex\u0026#39; (override with `.groups` argument) #ggsave(\u0026quot;bar.png\u0026quot;, width=10, height = 6) Notice how the bar plot hides the real range of the data. This is what it would look like plotted with the y-axis ranges shown below.\ndata %\u0026gt;% group_by(sex, face_sex) %\u0026gt;% summarise( mean = mean(dv), se = sd(dv)/sqrt(n()) ) %\u0026gt;% ggplot(aes(sex, mean, fill=face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_col(color = \u0026quot;white\u0026quot;, position=\u0026quot;dodge\u0026quot;, alpha = 0.5) + geom_errorbar(aes(ymin = mean-se, ymax=mean+se), width=0.1, position=position_dodge(0.9), color=textcolor) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + ylim(-5, 5) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme ## `summarise()` regrouping output by \u0026#39;sex\u0026#39; (override with `.groups` argument)  ViolinBox Plot data %\u0026gt;% ggplot(aes(sex, dv, fill = face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_violin(color=textcolor, trim=FALSE, alpha = 0.5) + geom_boxplot(color = textcolor, width = 0.25, position = position_dodge(width=0.9)) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + ylim(-5, 5) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme #ggsave(\u0026quot;violinbox.png\u0026quot;, width=10, height = 6)  Violin-Point Plot The boxplot above showss the median and quartiles, which sometimes isn‚Äôt the summary statistic you want to emphasise (HT https://twitter.com/PaulMinda1). You can alternatively plot the mean and 95% CI using geom_pointrange. This requires a bit of data wrangling first.\nsummary_data \u0026lt;- data %\u0026gt;% group_by(sex, face_sex) %\u0026gt;% summarise( mean = mean(dv), min = mean(dv) - qnorm(0.975)*sd(dv)/sqrt(n()), max = mean(dv) + qnorm(0.975)*sd(dv)/sqrt(n()) ) ## `summarise()` regrouping output by \u0026#39;sex\u0026#39; (override with `.groups` argument) data %\u0026gt;% ggplot(aes(sex, dv, fill = face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_violin(color=textcolor, trim=FALSE, alpha = 0.5) + geom_pointrange( data = summary_data, aes(sex, mean, ymin=min, ymax=max), shape = 20, color = textcolor, position = position_dodge(width = 0.9) ) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + ylim(-5, 5) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + scale_color_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme #ggsave(\u0026quot;violin_pointrange.png\u0026quot;, width=10, height = 6)  Split-Violin Plots To make a split violin plot, first you have to define geom_split_violin(). I derived the code from https://stackoverflow.com/questions/35717353/split-violin-plot-with-ggplot2.\nGeomSplitViolin \u0026lt;- ggproto( \u0026quot;GeomSplitViolin\u0026quot;, GeomViolin, draw_group = function(self, data, ..., draw_quantiles = NULL) { data \u0026lt;- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x)) grp \u0026lt;- data[1,\u0026#39;group\u0026#39;] newdata \u0026lt;- plyr::arrange( transform(data, x = if(grp%%2==1) xminv else xmaxv), if(grp%%2==1) y else -y ) newdata \u0026lt;- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ]) newdata[c(1,nrow(newdata)-1,nrow(newdata)), \u0026#39;x\u0026#39;] \u0026lt;- round(newdata[1, \u0026#39;x\u0026#39;]) if (length(draw_quantiles) \u0026gt; 0 \u0026amp; !scales::zero_range(range(data$y))) { stopifnot(all(draw_quantiles \u0026gt;= 0), all(draw_quantiles \u0026lt;= 1)) quantiles \u0026lt;- ggplot2:::create_quantile_segment_frame(data, draw_quantiles) aesthetics \u0026lt;- data[rep(1, nrow(quantiles)), setdiff(names(data), c(\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;)), drop = FALSE] aesthetics$alpha \u0026lt;- rep(1, nrow(quantiles)) both \u0026lt;- cbind(quantiles, aesthetics) quantile_grob \u0026lt;- GeomPath$draw_panel(both, ...) ggplot2:::ggname(\u0026quot;geom_split_violin\u0026quot;, grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob)) } else { ggplot2:::ggname(\u0026quot;geom_split_violin\u0026quot;, GeomPolygon$draw_panel(newdata, ...)) } } ) geom_split_violin \u0026lt;- function (mapping = NULL, data = NULL, stat = \u0026quot;ydensity\u0026quot;, position = \u0026quot;identity\u0026quot;, ..., draw_quantiles = NULL, trim = TRUE, scale = \u0026quot;area\u0026quot;, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE) { layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...) ) } Once you‚Äôve defined the new geom, you can use geom_split_violin pretty much like geom_violin. Note how the position of the geom_boxplot changes to put the boxplots side-by-side.\ndata %\u0026gt;% ggplot(aes(sex, dv, fill = face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_split_violin(color=textcolor, trim=FALSE, alpha = 0.5) + geom_boxplot(color = textcolor, width = 0.25, position = position_dodge(width=0.25)) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + ylim(-5, 5) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme #ggsave(\u0026quot;split_violin.png\u0026quot;, width=10, height = 6) This is a split violin with means and 95% CIs defined.\nsummary_data \u0026lt;- data %\u0026gt;% group_by(sex, face_sex) %\u0026gt;% summarise( mean = mean(dv), min = mean(dv) - qnorm(0.975)*sd(dv)/sqrt(n()), max = mean(dv) + qnorm(0.975)*sd(dv)/sqrt(n()) ) ## `summarise()` regrouping output by \u0026#39;sex\u0026#39; (override with `.groups` argument) data %\u0026gt;% ggplot(aes(sex, dv, fill = face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_split_violin(color=textcolor, trim=FALSE, alpha = 0.5) + geom_pointrange( data = summary_data, aes(sex, mean, ymin=min, ymax=max), color = textcolor, shape = 20, # 95, position = position_dodge(width = 0.25) ) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + ylim(-5, 5) + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + scale_color_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme #ggsave(\u0026quot;split_violin_pointrange.png\u0026quot;, width=10, height = 6)  Raincloud Plots The code for raincloud plots is from Micah Allen and Ben Marwick.\n\u0026quot;%||%\u0026quot; \u0026lt;- function(a, b) { if (!is.null(a)) a else b } geom_flat_violin \u0026lt;- function(mapping = NULL, data = NULL, stat = \u0026quot;ydensity\u0026quot;, position = \u0026quot;dodge\u0026quot;, trim = TRUE, scale = \u0026quot;area\u0026quot;, show.legend = NA, inherit.aes = TRUE, ...) { layer( data = data, mapping = mapping, stat = stat, geom = GeomFlatViolin, position = position, show.legend = show.legend, inherit.aes = inherit.aes, params = list( trim = trim, scale = scale, ... ) ) } GeomFlatViolin \u0026lt;- ggproto(\u0026quot;GeomFlatViolin\u0026quot;, Geom, setup_data = function(data, params) { data$width \u0026lt;- data$width %||% params$width %||% (resolution(data$x, FALSE) * 0.9) # ymin, ymax, xmin, and xmax define the bounding rectangle for each group data %\u0026gt;% group_by(group) %\u0026gt;% mutate(ymin = min(y), ymax = max(y), xmin = x, xmax = x + width / 2) }, draw_group = function(data, panel_scales, coord) { # Find the points for the line to go all the way around data \u0026lt;- transform(data, xminv = x, xmaxv = x + violinwidth * (xmax - x)) # Make sure it\u0026#39;s sorted properly to draw the outline newdata \u0026lt;- rbind(plyr::arrange(transform(data, x = xminv), y), plyr::arrange(transform(data, x = xmaxv), -y)) # Close the polygon: set first and last point the same # Needed for coord_polar and such newdata \u0026lt;- rbind(newdata, newdata[1,]) ggplot2:::ggname(\u0026quot;geom_flat_violin\u0026quot;, GeomPolygon$draw_panel(newdata, panel_scales, coord)) }, draw_key = draw_key_polygon, default_aes = aes(weight = 1, colour = \u0026quot;grey20\u0026quot;, fill = \u0026quot;white\u0026quot;, size = 0.5, alpha = NA, linetype = \u0026quot;solid\u0026quot;), required_aes = c(\u0026quot;x\u0026quot;, \u0026quot;y\u0026quot;) )  data %\u0026gt;% ggplot(aes(sex, dv, fill = face_sex)) + geom_hline(yintercept=0, color=textcolor, size=1) + geom_flat_violin(position = position_nudge(x = .25, y = 0), color=textcolor, trim=FALSE, alpha = 0.75) + geom_point(aes(color = face_sex), position = position_jitter(width = .2, height = 0), size = .5, alpha = .75) + ylab(\u0026quot;DV\u0026quot;) + xlab(\u0026quot;Participant Sex\u0026quot;) + coord_flip() + scale_fill_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + scale_color_manual(values = c(\u0026quot;#3D66CC\u0026quot;, \u0026quot;#892110\u0026quot;)) + my_theme  ","date":1522195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522195200,"objectID":"18f700b2a4f82f671c509ed576dc98cf","permalink":"https://debruine.github.io/post/plot-comparison/","publishdate":"2018-03-28T00:00:00Z","relpermalink":"/post/plot-comparison/","section":"post","summary":"library(tidyverse) I compared bar plots to violin plots in a recent talk to make the point that real data plotted with the full distribution make your effects look less impressive than minimalist bar charts that just show the means and standard errors, but give you a much better idea of what‚Äôs going on with your data.","tags":["R","ggplot","tidyverse","dataviz"],"title":"Plot Comparison","type":"post"},{"authors":null,"categories":["rstats"],"content":"  A student on our help forum recently asked for help making a wide-format dataset long. When I tried to load the data, I realised the first three rows were all header rows. Here‚Äôs the code I wrote to deal with it.\nFirst, I‚Äôll make a small CSV ‚Äúfile‚Äù below. In a typical case, you‚Äôd read the data in from a file.\ndemo_csv \u0026lt;- \u0026quot;SUB1, SUB1, SUB1, SUB1, SUB2, SUB2, SUB2, SUB2 COND1, COND1, COND2, COND2, COND1, COND1, COND2, COND2 X, Y, X, Y, X, Y, X, Y 10, 15, 6, 2, 42, 4, 32, 5 4, 43, 7, 34, 56, 43, 2, 33 77, 12, 14, 75, 36, 85, 3, 2\u0026quot; If you try to read in this data, you‚Äôll get an error message about the duplicate column names.\ndata \u0026lt;- read_csv(demo_csv) ## Warning: Duplicated column names deduplicated: \u0026#39;SUB1\u0026#39; =\u0026gt; \u0026#39;SUB1_1\u0026#39; [2], \u0026#39;SUB1\u0026#39; ## =\u0026gt; \u0026#39;SUB1_2\u0026#39; [3], \u0026#39;SUB1\u0026#39; =\u0026gt; \u0026#39;SUB1_3\u0026#39; [4], \u0026#39;SUB2\u0026#39; =\u0026gt; \u0026#39;SUB2_1\u0026#39; [6], \u0026#39;SUB2\u0026#39; =\u0026gt; ## \u0026#39;SUB2_2\u0026#39; [7], \u0026#39;SUB2\u0026#39; =\u0026gt; \u0026#39;SUB2_3\u0026#39; [8] Instead, you should read in just the header rows by setting n_max equal to the number of header rows and col_names to FALSE.\ndata_head \u0026lt;- read_csv(demo_csv, n_max = 3, col_names = FALSE) You will get a table that looks like this:\n  X1  X2  X3  X4  X5  X6  X7  X8      SUB1  SUB1  SUB1  SUB1  SUB2  SUB2  SUB2  SUB2    COND1  COND1  COND2  COND2  COND1  COND1  COND2  COND2    X  Y  X  Y  X  Y  X  Y     You can then transpose the table (rotate it) and make new header names by pasting together the names of the three headers.\nnew_names \u0026lt;- data_head %\u0026gt;% t() %\u0026gt;% # transposes the data and turns it into a matrix as_tibble() %\u0026gt;% # turn it back to a tibble mutate(name = paste(V1, V2, V3, sep = \u0026quot;_\u0026quot;)) %\u0026gt;% pull(name) ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. ## Using compatibility `.name_repair`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. Now you can read in the data without the three header rows. Use skip to skip the headers and set col_names to the new names.\ndata \u0026lt;- read_csv(demo_csv, skip = 3, col_names = new_names) If you have an excel file that merges the duplicate headers across rows, it‚Äôs a little trickier, but still do-able.\nThe first steps is the same: read in the first three rows.\ndata_head \u0026lt;- readxl::read_excel(\u0026quot;3headers_demo.xlsx\u0026quot;, n_max = 3, col_names = FALSE) ## New names: ## * `` -\u0026gt; ...1 ## * `` -\u0026gt; ...2 ## * `` -\u0026gt; ...3 ## * `` -\u0026gt; ...4 ## * `` -\u0026gt; ...5 ## * ...   ‚Ä¶1  ‚Ä¶2  ‚Ä¶3  ‚Ä¶4  ‚Ä¶5  ‚Ä¶6  ‚Ä¶7  ‚Ä¶8      SUB1  NA  NA  NA  SUB2  NA  NA  NA    COND1  NA  COND2  NA  COND1  NA  COND2  NA    X  Y  X  Y  X  Y  X  Y     The function below starts at the top and fills in any missing data with the value in the previous row. You‚Äôll have to define this function in your script before you run the next part.\nfillHeaders \u0026lt;- function(header_table) { for (row in 2:nrow(header_table)) { this_row \u0026lt;- header_table[row, ] last_row \u0026lt;- header_table[row-1, ] new_row \u0026lt;- ifelse(is.na(this_row), last_row, this_row) header_table[row, ] \u0026lt;- new_row } header_table } Just run the fillHeaders() function after you transpose as re-tibble the header data, then continue generating the pasted name the same as above.\nnew_names \u0026lt;- data_head %\u0026gt;% t() %\u0026gt;% # transposes the data and turns it into a matrix as_tibble() %\u0026gt;% # turn it back to a tibble fillHeaders() %\u0026gt;% # fill in missing headers mutate(name = paste(V1, V2, V3, sep = \u0026quot;_\u0026quot;)) %\u0026gt;% pull(name) If your data are set up with multiple headers, you‚Äôll probably want to change them from wide to long format. Here‚Äôs a quick example how to use gather, separate, and spread to do this with variable names like above.\ndata \u0026lt;- readxl::read_excel(\u0026quot;3headers_demo.xlsx\u0026quot;, skip = 3, col_names = new_names) data_long \u0026lt;- data %\u0026gt;% # add row IDs if each row doesn\u0026#39;t already have uniquely identifying column(s) mutate(trial = row_number()) %\u0026gt;% # gather creates a column of variable names and a column of values gather(\u0026quot;var\u0026quot;, \u0026quot;val\u0026quot;, new_names) %\u0026gt;% # split the variable names into their three component parts separate(var, c(\u0026quot;subID\u0026quot;, \u0026quot;condition\u0026quot;, \u0026quot;coord\u0026quot;), sep = \u0026quot;_\u0026quot;) %\u0026gt;% # put X and Y in separate columns spread(coord, val) ## Note: Using an external vector in selections is ambiguous. ## ‚Ñπ Use `all_of(new_names)` instead of `new_names` to silence this message. ## ‚Ñπ See \u0026lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html\u0026gt;. ## This message is displayed once per session.   trial  subID  condition  X  Y      1  SUB1  COND1  0.8316380  0.7881552    1  SUB1  COND2  0.3941482  0.2056488    1  SUB2  COND1  0.9332829  0.1530898    1  SUB2  COND2  0.6189847  0.9400281    2  SUB1  COND1  0.4147148  0.1366791    2  SUB1  COND2  0.9805130  0.7493469    2  SUB2  COND1  0.1048907  0.6573472    2  SUB2  COND2  0.9579583  0.3430333    3  SUB1  COND1  0.5577673  0.0956297    3  SUB1  COND2  0.3045316  0.3540656    3  SUB2  COND1  0.3621907  0.8460132    3  SUB2  COND2  0.0167339  0.1886913    4  SUB1  COND1  0.4326746  0.8276863    4  SUB1  COND2  0.2845026  0.6236266    4  SUB2  COND1  0.0439374  0.5379287    4  SUB2  COND2  0.0712748  0.3511542    5  SUB1  COND1  0.6545546  0.6501679    5  SUB1  COND2  0.9202481  0.2525272    5  SUB2  COND1  0.8117072  0.3455603    5  SUB2  COND2  0.7073851  0.4249118    6  SUB1  COND1  0.0679236  0.6978207    6  SUB1  COND2  0.3979061  0.6922928    6  SUB2  COND1  0.5282960  0.1093352    6  SUB2  COND2  0.6622162  0.5567239     ","date":1519257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519257600,"objectID":"7956116c7dc971d26561688fc9bb4e4c","permalink":"https://debruine.github.io/post/multi-row-headers/","publishdate":"2018-02-22T00:00:00Z","relpermalink":"/post/multi-row-headers/","section":"post","summary":"A student on our help forum recently asked for help making a wide-format dataset long. When I tried to load the data, I realised the first three rows were all header rows.","tags":["R","data import","headers"],"title":"Multi-Row Headers","type":"post"},{"authors":null,"categories":["rstats"],"content":"  I‚Äôve often wondered how many raters I need to sample to get reliable stimulus ratings.\nThis will obviously depend on the stimuli and what they‚Äôre being rated for. If there is a lot of inter-rater variation or very little inter-stimulus variation, you will need more raters to generate mean ratings with any reliability.\nIf you have a large set of ratings of a type of stimulus, population of rater, and type of rating you‚Äôre interested in, you can use the script below to figure out how many raters you need to sample to get mean stimulus ratings that are well-correlated with mean ratings from very large samples.\nThe example below is for attractiveness ratings using an open-access image set from my lab.\nYou can cite this method as: DeBruine, Lisa \u0026amp; Jones, Benedict C. (2018) Determining the number of raters for reliable mean ratings. OSF. doi: 10.17605/OSF.IO/X7FUS\nlibrary(tidyverse) library(psych) Read data from DeBruine, Lisa; Jones, Benedict (2017): Face Research Lab London Set. figshare. doi: 10.6084/m9.figshare.5047666\ndata \u0026lt;- read_csv(\u0026quot;https://ndownloader.figshare.com/files/8542045\u0026quot;) Calculate canonical mean ratings (average of all available ratings)\ncanon \u0026lt;- data %\u0026gt;% select(X001:X173) %\u0026gt;% group_by() %\u0026gt;% summarise_all(mean) %\u0026gt;% t() Below is a function to sample n raters from the set and calculate Cronbach‚Äôs alpha and r from the Pearson‚Äôs correlation with the canonical ratings.\nget_alpha \u0026lt;- function(data, n) { # sample your full dataset data_sample \u0026lt;- data %\u0026gt;% sample_n(n) %\u0026gt;% select(X001:X173) # select only columns with your stimuli # calculate cronbach\u0026#39;s alpha capture.output(suppressWarnings(a \u0026lt;- alpha(t(data_sample)))) alpha \u0026lt;- a$total[\u0026quot;std.alpha\u0026quot;] %\u0026gt;% pluck(1) # calculate mean sample ratings sample_means \u0026lt;- data_sample %\u0026gt;% group_by() %\u0026gt;% summarise_all(mean) %\u0026gt;% t() # calculate correlation between sample mean ratings and canon r \u0026lt;- cor(sample_means, canon)[[1,1]] # return relevant data tibble( n = n, alpha = alpha, r = r ) } Generate 100 samples for 5 to 50 raters.\nn_samples \u0026lt;- 100 n_raters \u0026lt;- seq(5, 50, by = 5) sim \u0026lt;- rep(n_raters, each = n_samples) %\u0026gt;% purrr::map_df( function(n) { get_alpha(data, n) }) This graph of the distribution of Cronbach‚Äôs alphas shows that alphas tend to be fairly ‚Äúhigh‚Äù (\u0026gt;.8) after about 15 raters for this stimulus set and rating.\nHere is a graph of the distribution of correlations between sample means and canonical mean ratings. Again, the sample mean ratings are very highly correlated with the canonical ratings from the full set of 2513 raters after about 15 raters.\nThis table gives the median and 10th percentiles for alpha and r, as well as the proportion of alphas over 0.8 (typically considered high).\n## `summarise()` ungrouping output (override with `.groups` argument)   n  median alpha  90% alpha \u0026gt;  alpha \u0026gt;= 0.8  median r  90% r \u0026gt;      5  0.73  0.58  0.13  0.87  0.79    10  0.85  0.78  0.82  0.92  0.89    15  0.89  0.85  0.99  0.95  0.93    20  0.91  0.89  1.00  0.96  0.94    25  0.93  0.91  1.00  0.97  0.96    30  0.94  0.93  1.00  0.97  0.96    35  0.95  0.94  1.00  0.98  0.97    40  0.96  0.95  1.00  0.98  0.97    45  0.96  0.95  1.00  0.98  0.97    50  0.96  0.96  1.00  0.98  0.98     ","date":1518825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518825600,"objectID":"ade0f179715709c990fa97f78ae9e1f5","permalink":"https://debruine.github.io/post/how-many-raters/","publishdate":"2018-02-17T00:00:00Z","relpermalink":"/post/how-many-raters/","section":"post","summary":"I‚Äôve often wondered how many raters I need to sample to get reliable stimulus ratings.\nThis will obviously depend on the stimuli and what they‚Äôre being rated for. If there is a lot of inter-rater variation or very little inter-stimulus variation, you will need more raters to generate mean ratings with any reliability.","tags":["alpha","cronbach"],"title":"How many raters do I need?","type":"post"},{"authors":null,"categories":["rstats"],"content":" Download a simple demo .rmd/.html.\nI‚Äôd noticed that students were tending to just look at the hidden solutions and not try very hard to understand the exercises, so I wanted a way for them to check if they‚Äôre right, but not give them the answer immediately. I made a quick way to set up an input box that turns blue when you type in the right answer.\nWhat is 2 + 2? Setting this up requires a few lines at the beginning and end of each file, plus surrounding your solutions with a line of html.\nPut this at the beginning of your file If you‚Äôre making your website in RMarkdown, put it after the second --- in the yml header. If you‚Äôre writing html directly, put it inside the \u0026lt;head\u0026gt; element.\nYou can use different colours or line types by changing the border styles.\n\u0026lt;style\u0026gt; /* styles for solveme */ .solveme { border: 2px dotted red; } .solveme.correct { border: 2px solid blue; } \u0026lt;/style\u0026gt; If you‚Äôre using RMarkdown Websites, you can just put these lines of css into an external stylesheet linked in your _site.yml file (e.g., rguppies.css).\n Put this at the end of your file \u0026lt;script\u0026gt; tc = function() { if (t = document.getElementById(\u0026quot;total_correct\u0026quot;)) { t.innerHTML = document.getElementsByClassName(\u0026quot;correct\u0026quot;).length + \u0026quot; of \u0026quot; + document.getElementsByClassName(\u0026quot;solveme\u0026quot;).length + \u0026quot; correct\u0026quot;; } } window.onload = function() { tc(); var solveme = document.getElementsByClassName(\u0026quot;solveme\u0026quot;); for (var i = 0; i \u0026lt; solveme.length; i++) { solveme[i].setAttribute(\u0026quot;autocomplete\u0026quot;,\u0026quot;off\u0026quot;); solveme[i].value = \u0026quot;\u0026quot;; solveme[i].onkeyup = function(e) { var real_answer = this.getAttribute(\u0026quot;answer\u0026quot;).trim(); var my_answer = this.value; var cl = this.classList; if (cl.contains(\u0026quot;nospaces\u0026quot;)) { real_answer = real_answer.replace(/ /g, \u0026quot;\u0026quot;); my_answer = my_answer.replace(/ /g, \u0026quot;\u0026quot;); } if (cl.contains(\u0026quot;ignorecase\u0026quot;)) { real_answer = real_answer.toLowerCase(); my_answer = my_answer.toLowerCase(); } var linend = new RegExp(/\\s*(:or:)\\s*/, \u0026#39;g\u0026#39;) real_answer = real_answer.split(linend); if (my_answer !== \u0026quot;\u0026quot; \u0026amp; real_answer.includes(my_answer)) { cl.add(\u0026quot;correct\u0026quot;); } else { cl.remove(\u0026quot;correct\u0026quot;); } tc(); } solveme[i].onchange = function() { this.onkeyup(); } } } \u0026lt;/script\u0026gt; If you‚Äôre using RMarkdown Websites, you can just put this script into an external footer or script file linked in your _site.yml file (e.g., rguppies.js).\n Set up the input boxes  Set up a basic input box like below. It needs to have solveme as the class and the correct answer in answer.\nWhat is \\(5 + 5\\)? \u0026lt;input class=\u0026quot;solveme\u0026quot; answer=\u0026quot;10\u0026quot; \u0026gt; If you don‚Äôt care about uppercase vs lowercase letters, add ignorecase to the input style. You can also change the width of theinput box with size.\nWhat is the letter after B? \u0026lt;input class=\u0026quot;solveme ignorecase\u0026quot; size=\u0026quot;1\u0026quot; answer=\u0026quot;c\u0026quot; \u0026gt; You can also put multiple correct answer possibilities separated by :or:.\nType a vowel \u0026lt;input class=\u0026quot;solveme ignorecase\u0026quot; size=\u0026quot;1\u0026quot; answer=\u0026quot;a :or: e :or: i :or: o :or: u\u0026quot; \u0026gt; If you‚Äôre asking for simple code where the spaces don‚Äôt matter, add the class nospaces.\nDraw 10 random numbers from a normal distribution with a mean of 3 and SD of 2:\n\u0026lt;input class=\u0026quot;solveme nospaces\u0026quot; size=\u0026quot;30\u0026quot; answer=\u0026quot;rnorm(10, 3, 2) :or: rnorm(10, mean = 3, sd = 2) :or: rnorm(10, 3, sd = 2) :or: rnorm(10, sd = 2, mean = 3) :or: rnorm(x = 10, mean = 3, sd = 2)\u0026quot; \u0026gt; You can also skip a line after :or:. Whitespace before and after your answer is trimmed off, so your coprrect answer can‚Äôt require that the student start or end with spaces.  This can‚Äôt handle multiple-line answers, but you can embed several input boxes in a paragraph. The formatting can get tricky, though:\nComplete the following function for returning the scaled values of a vector, v.\n scale_function () the_sd ) (v the_mean ) the_sd }  \u0026lt;pre\u0026gt; scale_function \u0026lt;- function(v) { the_mean \u0026lt;- \u0026lt;input class=\u0026quot;solveme\u0026quot; size=\u0026quot;6\u0026quot; answer=\u0026quot;mean\u0026quot;\u0026gt;(\u0026lt;input class=\u0026quot;solveme\u0026quot; size = \u0026quot;2\u0026quot; answer=\u0026quot;v\u0026quot;\u0026gt;) the_sd \u0026lt;- sd(\u0026lt;input class=\u0026quot;solveme\u0026quot; size=\u0026quot;1\u0026quot; answer=\u0026quot;v\u0026quot;\u0026gt;) (v \u0026lt;input class=\u0026quot;solveme\u0026quot; size = \u0026quot;1\u0026quot; answer=\u0026quot;-\u0026quot;\u0026gt; the_mean ) \u0026lt;input class=\u0026quot;solveme\u0026quot; size = \u0026quot;1\u0026quot; answer=\u0026quot;/\u0026quot;\u0026gt; the_sd } \u0026lt;/pre\u0026gt; I wrapped the text in \u0026lt;pre\u0026gt; tags to format it like code, while still rendering the input boxes. If you surround it with three backticks, it will just display the code for the input boxes, not the actual boxes.  You can also use this for a multiple choice drop-down menu.\nHow would you model a distribution of coin flips?\n rnorm runif rpois rbinom \n\u0026lt;select class=\u0026quot;solveme\u0026quot; answer=\u0026quot;rbinom\u0026quot;\u0026gt; \u0026lt;option\u0026gt;\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;rnorm\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;runif\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;rpois\u0026lt;/option\u0026gt; \u0026lt;option\u0026gt;rbinom\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; You can include a line with automatically updating total correct using the following code:\n\n\u0026lt;span id=\u0026quot;total_correct\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;   ","date":1510704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510704000,"objectID":"0f161682ecfe32497422093042f80396","permalink":"https://debruine.github.io/post/solution-feedback/","publishdate":"2017-11-15T00:00:00Z","relpermalink":"/post/solution-feedback/","section":"post","summary":"Download a simple demo .rmd/.html.\nI‚Äôd noticed that students were tending to just look at the hidden solutions and not try very hard to understand the exercises, so I wanted a way for them to check if they‚Äôre right, but not give them the answer immediately.","tags":["R","pedagogy"],"title":"Solution Feedback","type":"post"},{"authors":null,"categories":["prereg"],"content":"  input[type=text] { width: 100%; } textarea { width: 100%; height: 6em; } .example { background-color: #DDEEFF; border: 1px solid #BBCCDD; border-radius: 0.5em; padding: 0.5em 0.5em 0.5em 0.5em;} .eval { font-size: smaller; color: #666666; }  Here is my internal lab pre-registration form (including an example). It is based on the OSF Preregistration Challenge forms. We use this for student projects to train them about open science practices and to prepare formal preregistrations on the OSF for postgraduate students and other lab members.\nDownload the Rmd notebook for this example\nStudy Information Title Provide the working title of your study.\nThe effect of facial expression on third party kin recognition\n The title should be a specific and informative description of a project. Vague titles such as ‚ÄòFaces preregistration plan‚Äô are not appropriate.   Research Questions Please list each research question included in this study.\nDoes facial expression influence the accuracy of third party kin recognition?\n The type of submissions for this question will vary widely by discipline, and we cannot determine if the question is worth asking. However, questions that are excessively vague so as to make understanding later sections difficult are not appropriate. For some studies, the research questions and hypotheses are extremely similar, so overlap between this and the subsequent question is expected.\n  Hypotheses For each of the research questions listed in the previous section, provide one or multiple specific and testable hypotheses. Please state if the hypotheses are directional or non-directional. If directional, state the direction. A predicted effect is also appropriate here.\nThird party kinship recognition accuracy will be higher for stimuli displaying a smiling facial expression than a neutral facial expression.\n In this section, the submission should provide a prediction as to the outcome of the study or a statement that no specific prediction is expected.\n   Sampling Plan In this section we‚Äôll ask you to describe how you plan to collect samples, as well as the number of samples you plan to collect and your rationale for this decision. Please keep in mind that the data described in this section should be the actual data used for analysis, so if you are using a subset of a larger dataset, please describe the subset that will actually be used in your study.\nData collection procedures Please describe the process by which you will collect your data. If you are using human subjects, this should include the population from which you obtain subjects, recruitment efforts, payment for participation, how subjects will be selected for eligibility from the initial pool (e.g.¬†inclusion and exclusion rules), and your study timeline. For studies that don‚Äôt include human subjects, include information about how you will collect samples, duration of data gathering efforts, source or location of samples, or batch numbers you will use.\nRaters will take part in this study online at faceresearch.org. Raters need to be at least 16 years old and give consent to participate in the study. Data collection will start in January 2017 and continue until we obtain complete data from 50 people, with no further restrictions for sex, nationality, language, or other characteristics.\n The answer to this question requires a specific set of instructions so that another person could repeat the data collection procedures and recreate the study population. Alternatively, if the study population would be unable to be reproduced because it relies on a specific set of circumstances unlikely to be recreated (e.g., a community of people from a specific time and location), the criteria and methods for creating the group and the rationale for this unique set of subjects should be clear.\n  Sample size Describe the sample size of your study. How many units will be analyzed in the study? This could be the number of people, birds, classrooms, plots, interactions, or countries included. If the units are not individuals, then describe the size requirements for each unit. If you are using a clustered or multilevel design, how many units are you collecting at each level of the analysis?\nOur target sample size is 50 raters. Due to constraints of online data collection, we may collect more than 50 raters if many people participate in a short period of time. Data will not be excluded if more than 50 people complete the study.\n For some studies, this will simply be the number of samples or the number of clusters. For others, this could be an expected range, minimum, or maximum number.\n  Sample size rationale This could include a power analysis or an arbitrary constraint such as time, money, or personnel.\nWe performed a power calculation using simulated data (R script attached) to ascertain that our design has \u0026gt;90% power to detect a third party kin recognition ability difference of at least 5% between neutral and smiling faces.\n This gives you an opportunity to specifically state how the sample size will be determined. A wide range of possible answers is acceptable; remember that transparency is more important than principled justifications. If you state any reason for a sample size upfront, it is better than stating no reason and leaving the reader to ‚Äúfill in the blanks.‚Äù Acceptable rationales include: a power analysis, an arbitrary number of subjects, or a number based on time or monetary constraints.\n   Variables In this section you can describe all variables (both manipulated and measured variables) that will later be used in your confirmatory analysis plan. In your analysis plan, you will have the opportunity to describe how each variable will be used. If you have variables which you are measuring for exploratory analyses, you are not required to list them, though you are permitted to do so.\nManipulated variables Describe all variables you plan to manipulate and the levels or treatment arms of each variable. For observational studies and meta-analyses, simply state that this is not applicable.\nRelatedness (related/unrelated): Half of the stimulus pairs are related; half are unrelated age- and sex-matched pairs.\nFacial expression (smiling/neutral): Each rater will see half of the stimulus pairs with a smiling facial expression and the other half with a neutral facial expression.\n For any experimental manipulation, you should give a precise definition of each manipulated variable. This must include a precise description of the levels at which each variable will be set, or a specific definition for each categorical treatment. For example, ‚Äúloud or quiet,‚Äù should instead give either a precise decibel level or a means of recreating each level. ‚ÄòPresence/absence‚Äô or ‚Äòpositive/negative‚Äô is an acceptable description if the variable is precisely described.\n  Measured variables Describe each variable that you will measure. This will include outcome measures, as well as any predictors or covariates that you will measure. You do not need to include any variables that you plan on collecting if they are not going to be included in the confirmatory analyses of this study.\nThe outcome variable will be the perceived kinship status of each presented stimulus pair (related/unrelated).\n Observational studies and meta-analyses will include only measured variables. As with the previous questions, the answers here must be precise. For example, ‚Äòintelligence,‚Äô ‚Äòaccuracy,‚Äô ‚Äòaggression,‚Äô and ‚Äòcolor‚Äô are too vague. Acceptable alternatives could be ‚ÄòIQ as measured by Wechsler Adult Intelligence Scale‚Äô ‚Äòpercent correct,‚Äô ‚Äònumber of threat displays,‚Äô and ‚Äòpercent reflectance at 400 nm.‚Äô\n  Indices If any measurements are going to be combined into an index (or even a mean), what measures will you use and how will they be combined? Include either a formula or a precise description of your method. If your are using a more complicated statistical method to combine measures (e.g.¬†a factor analysis), you can note that here but describe the exact method in the analysis plan section.\nOur analyses do not require transformation beyond assigning 0/1 to the response labels (related = 1, unrelated = 0).\n If you are using multiple pieces of data to construct a single variable, how will this occur? Both the data that are included and the formula or weights for each measure must be specified. Standard summary statistics, such as ‚Äúmeans‚Äù do not require a formula, though more complicated indices require either the exact formula or, if it is an established index in the field, the index must be unambiguously defined. For example, ‚Äúbiodiversity index‚Äù is too broad, whereas ‚ÄúShannon‚Äôs biodiversity index‚Äù is appropriate.\n   Design Plan In this section, you will be asked to describe the overall design of your study. Remember that this research plan is designed to register a single study, so if you have multiple experimental designs, please complete a separate preregistration.\nStudy design Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies.\nEach rater will be presented with 100 stimulus pairs, presented in a random order. Half of the stimulus pairs are related (full siblings) and half are unrelated age- and sex-matched pairs. Half of each group will be shown with smiling expressions, the other half with neutral expressions, ensuring that the same stimuli are never presented as both smiling and neutral to the same rater. Raters will be randomly assigned to one of two versions containing the same stimuli, but the opposite facial expression (e.g., the stimuli with a smiling expression in version A are neutral in version B).\nRaters will receive the following instructions before the study:\n In this experiment you will be shown 100 pairs of faces. Some are siblings, some are an unrelated pair. You will be asked to determine whether each pair is ‚Äúunrelated‚Äù or ‚Äúrelated‚Äù. After the experiment, you will be told how many of the 100 pairs you correctly determined and what the average performance on this task was.  After this, they will see 100 trials in a randomised order. Each trial has the questions, ‚ÄúPlease indicate if this pair of faces shows siblings or an unrelated pair‚Äù, two respinse buttons (‚Äúunrelated‚Äù, ‚Äúrelated‚Äù) and the faces of the stimulus pair shown side-by-side below at a maximum of 600x800 pixels (or sized to fit screen width if the device screen is smaller than 1200px). Face images have hair and clothing masked in black.\nAn example trial\n  This question has a variety of possible answers. The key is for a researcher to be as detailed as is necessary given the specifics of their design. Be careful to determine if every parameter has been specified in the description of the study design. There may be some overlap between this question and the following questions. That is OK, as long as sufficient detail is given in one of the areas to provide all of the requested information. For example, if the study design describes a complete factorial, 2 X 3 design and the treatments and levels are specified previously, you do not have to repeat that information.\n  Randomization If you are doing a randomized study, how will you randomize, and at what level?\nEach rater will be assigned to one of the 2 counterbalanced versions. Raters will be assigned to whichever version currently has fewer completions by their sex, or randomly when both versions have the same number (this is done by the online platform). The order of stimuli is randomized for each rater.\n Typical randomization techniques include: simple, block, stratified, and adaptive covariate randomization. If randomization is required for the study, the method should be specified here, not simply the source of random numbers.\n   Analysis Plan You may describe one or more confirmatory analysis in this preregistration. Please remember that all analyses specified below must be reported in the final article, and any additional analyses must be noted as exploratory or hypothesis-generating.\nA confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis. You are allowed to describe any exploratory work here, but a clear confirmatory analysis is required.\nStatistical models What statistical model will you use to test each hypothesis? Please include the type of model (e.g.¬†ANOVA, multiple regression, SEM, etc) and the specification of the model (this includes each variable that will be included as predictors, outcomes, or covariates). Please specify any interactions that will be tested and remember that any test not included here must be noted as an exploratory test in your final article.\nBinary relatedness judgments will be analyzed using binomial logistic mixed regression in R using lme4.\nlibrary(lmerTest) model \u0026lt;- glmer(judgement ~ related * expression + (1 + related | rater) + (1 + expression | stimulus), data = my_data, family = binomial) Relatedness judgment (0 = unrelated, 1 = related) is the dependent variable, relatedness (0.5 = related, -0.5 = unrelated) and expression (0.5 = smiling, -0.5 = neutral) are the independent variables. We include the rater and stimulus id as random effects and use maximally specified slopes.\nSee the attached RMarkdown file with the proposed analysis script.\n This is perhaps the most important and most complicated question within the preregistration. As with all of the other questions, the key is to provide a specific recipe for analyzing the collected data. Ask yourself: is enough detail provided to run the same analysis again with the information provided by the user? Be aware for instances where the statistical models appear specific, but actually leave openings for the precise test. See the following examples:\nIf someone specifies a 2x3 ANOVA with both factors within subjects, there is still flexibility with the various types of ANOVAs that could be run. Either a repeated measures ANOVA (RMANOVA) or a multivariate ANOVA (MANOVA) could be used for that design, which are two different tests.\nIf you are going to perform a sequential analysis and check after 50, 100, and 150 samples, you must also specify the p-values you‚Äôll test against at those three points.\n  Transformations If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process.\nRelatedness judgments are coded as 1 for related and 0 for unrelated. Actual relatedness will be effect-coded as -0.5 for unrelated and 0.5 for related, and facial expression will be effect-coded as -0.5 for neutral and 0.5 for smiling.\n If any categorical predictors are included in a regression, indicate how those variables will be coded (e.g.¬†dummy coding, summation coding, etc.) and what the reference category will be.\n  Follow-up analyses If not specified previously, will you be conducting any confirmatory analyses to follow up on effects in your statistical model, such as subgroup analyses, pairwise or complex contrasts, or follow-up tests from interactions? Remember that any analyses not specified in this research plan must be noted as exploratory.\nIf there is an interaction between expression and relatedness, separate models will be run for smiling and neutral expressions to determine whether kin recognition is apparent for both expressions.\nmodel_s \u0026lt;- glmer(judgement ~ related + (1 + related | rater) + (1 | stimulus), data = filter(my_data, expression == \u0026quot;smiling\u0026quot;), family = binomial) model_n \u0026lt;- glmer(judgement ~ related + (1 + related | rater) + (1 | stimulus), data = filter(my_data, expression == \u0026quot;neutral\u0026quot;), family = binomial)  This is simply a place to allow entering in any additional analyses. The criteria for these follow up analyses are identical to any analyses listed in other sections. It is also fine to enter these follow up analyses in a separate analysis section. The purpose of this question is to allow entering of any follow up tests that naturally follow from a primary analysis.\n  Inference criteria What criteria will you use to make inferences? Please describe the information you‚Äôll use (e.g.¬†specify the p-values, Bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this?\nWe will use an alpha criterion of .05, given that our specific predictions are pre-registered and our power analyses were calculated using this alpha.  P-values, confidence intervals, and effect sizes are standard means for making an inference, and any level is acceptable, though some criteria must be specified in this or previous fields. Bayesian analyses should specify a Bayes factor or a credible interval. If you are selecting models, then how will you determine the relative quality of each? In regards to multiple comparisons, this is a question with few ‚Äúwrong‚Äù answers. In other words, transparency is more important than any specific method of controlling the false discovery rate or false error rate. One may state an intention to report all tests conducted or one may conduct a specific correction procedure; either strategy is acceptable.   Data exclusion How will you determine which data points or samples (if any) to exclude from your analyses? How will outliers be handled?\nOnly responses of raters who have completed all 100 trials will be included in the analysis.\n Any rule for excluding a particular set of data is acceptable. One may describe rules for excluding a rater or for identifying outlier data.\n  Missing data How will you deal with incomplete or missing data?\nIf a rater does not complete all 100 trials they will be excluded from the analysis.\n Any relevant explanation is acceptable. As a final reminder, remember that the final analysis must follow the specified plan, and deviations must be either strongly justified or included as a separate, exploratory analysis.\n  Exploratory analysis (optional) If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.\nWe will explore whether demographic traits of the raters are related to kin recognition. Therefore, we will look for relationships between demographic variables (age, sex, parental status) and third party kinship detection accuracy.\n  /* document.body.onclick= function(e){ e = window.event ? event.srcElement : e.target; if (e.className \u0026\u0026 e.className.indexOf('example')!=-1) { var tbox = document.createElement(\"textarea\"); tbox.value = e.innerText.trim(); e.parentNode.replaceChild(tbox, e); } else if (e.tagName != \"TEXTAREA\") { var tboxes = document.getElementsByTagName(\"textarea\")[0]; var divbox = document.createElement(\"div\"); divbox.innerHTML = tboxes.value; divbox.className = \"example\"; e.parentNode.replaceChild(divbox, tboxes); } } */    ","date":1508716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508716800,"objectID":"607af80bbbf444c38a3864238690910b","permalink":"https://debruine.github.io/post/frl-prereg/","publishdate":"2017-10-23T00:00:00Z","relpermalink":"/post/frl-prereg/","section":"post","summary":"input[type=text] { width: 100%; } textarea { width: 100%; height: 6em; } .example { background-color: #DDEEFF; border: 1px solid #BBCCDD; border-radius: 0.5em; padding: 0.5em 0.5em 0.5em 0.5em;} .eval { font-size: smaller; color: #666666; }  Here is my internal lab pre-registration form (including an example).","tags":["preregistration"],"title":"Face Research Lab PreReg Example","type":"post"},{"authors":null,"categories":["rstats"],"content":" library(tidyverse) The R for Reproducible Scientific Analysis pages at software carpentry have a really nice interface for hiding and showing solutions to exercises. I‚Äôve created my own lightweight solution that you can use in any html file, including those made by RMarkdown (e.g., R notebooks).\nExample Graph the relationship between speed and distance for the cars dataset.\n Solution  You can put some text inside the solution, as well as code cunks.\nggplot(cars, aes(speed, dist)) + geom_point(color = \u0026quot;purple\u0026quot;) + geom_smooth(method = \u0026quot;lm\u0026quot;, color = \u0026quot;purple\u0026quot;) ## `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  Setting this up requires a few lines at the beginning and end of each file, plus surrounding your solutions with a line of html.\n Put this at the beginning of your file \u0026lt;style\u0026gt; /* styles for hidden solutions */ .solution { height: 2em; overflow-y: hidden; padding: 0.5em; } .solution.open { height: auto; background-color: rgba(0, 0, 0, 0.1); border-radius: 5px; } .solution button { height: 1.5em; margin-bottom: 0.5em; } .solution pre.sourceCode { border-color: green; } \u0026lt;/style\u0026gt; If you‚Äôre using RMarkdown Websites, you can just put these lines of css into an external stylesheet linked in your _site.yml file (e.g., rguppies.css).\n Put this at the end of your file \u0026lt;script\u0026gt; window.onload = function(){ var buttons = document.getElementsByTagName(\u0026quot;button\u0026quot;); for (var i = 0; i \u0026lt; buttons.length; i++) { buttons[i].onclick = function() { var cl = this.parentElement.classList; if (cl.contains(\u0026#39;open\u0026#39;)) { cl.remove(\u0026quot;open\u0026quot;); } else { cl.add(\u0026quot;open\u0026quot;); } } } } \u0026lt;/script\u0026gt; If you‚Äôre using RMarkdown Websites, you can just put this script into an external footer or script file linked in your _site.yml file (e.g., rguppies.js).\n Surround your hidden solutions like this \u0026lt;div class=\u0026quot;solution\u0026quot;\u0026gt;\u0026lt;button\u0026gt;Solution\u0026lt;/button\u0026gt; PUT YOUR SOLUTION HERE (including r chunks) \u0026lt;/div\u0026gt; You can change the text on the button to something else (e.g., \u0026lt;button\u0026gt;View the Answer\u0026lt;/button\u0026gt;).\nLet me know if you have any suggestions or find this useful.\n ","date":1508544000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508544000,"objectID":"d30b0f623dfb86e393fe8d3f1b8b2053","permalink":"https://debruine.github.io/post/hidden-solutions/","publishdate":"2017-10-21T00:00:00Z","relpermalink":"/post/hidden-solutions/","section":"post","summary":"library(tidyverse) The R for Reproducible Scientific Analysis pages at software carpentry have a really nice interface for hiding and showing solutions to exercises. I‚Äôve created my own lightweight solution that you can use in any html file, including those made by RMarkdown (e.","tags":["r","pedagogy","web"],"title":"Hidden Solutions","type":"post"},{"authors":null,"categories":["rstats"],"content":" This is a tutorial in progress on how to calculate Cronbach‚Äôs alphas using the psych package in R.\nlibrary(tidyverse) library(psych) disgust \u0026lt;- read_csv(\u0026quot;https://psyteachr.github.io/msc-data-skills/data/disgust.csv\u0026quot;) SPSS  Under the Analyze menu, choose Scale and Reliability Analysis... Choose the 7 moral disgust items Make sure the Model is ‚ÄúAlpha‚Äù Under Statistics, add descriptives for Item, Scale, and Scale if Item Deleted   psych::alpha() alpha(x, keys=NULL, cumulative=FALSE, title=NULL, max=10, na.rm=TRUE,\ncheck.keys=FALSE, n.iter=1, delete=TRUE, use=\"pairwise\", warnings=TRUE, n.obs=NULL)\nArguments  x A data.frame or matrix of data, or a covariance or correlation matrix keys If some items are to be reversed keyed, then either specify the direction of all items or just a vector of which items to reverse title Any text string to identify this run cumulative should means reflect the sum of items or the mean of the items. The default value is means. max the number of categories/item to consider if reporting category frequencies. Defaults to 10, passed to link{response.frequencies} na.rm The default is to remove missing values and find pairwise correlations check.keys if TRUE, then find the first principal component and reverse key items with negative loadings. Give a warning if this happens. n.iter Number of iterations if bootstrapped confidence intervals are desired delete Delete items with no variance and issue a warning use Options to pass to the cor function: ‚Äúeverything‚Äù, ‚Äúall.obs‚Äù, ‚Äúcomplete.obs‚Äù, ‚Äúna.or.complete‚Äù, or ‚Äúpairwise.complete.obs‚Äù. The default is ‚Äúpairwise‚Äù warnings By default print a warning and a message that items were reversed. Suppress the message if warnings = FALSE n.obs If using correlation matrices as input, by specify the number of observations, we can find confidence intervals  disgust %\u0026gt;% select(moral1:moral7) %\u0026gt;% psych::alpha(title = \u0026quot;moral\u0026quot;) ## ## Reliability analysis moral ## Call: psych::alpha(x = ., title = \u0026quot;moral\u0026quot;) ## ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd median_r ## 0.85 0.85 0.84 0.45 5.8 0.0016 3.8 1.3 0.46 ## ## lower alpha upper 95% confidence boundaries ## 0.85 0.85 0.85 ## ## Reliability if an item is dropped: ## raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r ## moral1 0.83 0.83 0.81 0.45 4.9 0.0019 0.0035 0.45 ## moral2 0.82 0.82 0.80 0.43 4.6 0.0019 0.0033 0.42 ## moral3 0.83 0.83 0.81 0.45 5.0 0.0019 0.0040 0.45 ## moral4 0.84 0.84 0.82 0.47 5.3 0.0017 0.0023 0.48 ## moral5 0.83 0.83 0.81 0.44 4.8 0.0019 0.0038 0.45 ## moral6 0.84 0.84 0.82 0.47 5.4 0.0017 0.0033 0.49 ## moral7 0.82 0.83 0.81 0.44 4.8 0.0019 0.0043 0.44 ## ## Item statistics ## n raw.r std.r r.cor r.drop mean sd ## moral1 19668 0.74 0.73 0.67 0.62 3.1 1.9 ## moral2 19662 0.77 0.78 0.75 0.68 4.6 1.5 ## moral3 19681 0.74 0.73 0.67 0.62 3.2 1.8 ## moral4 19656 0.66 0.68 0.60 0.54 4.5 1.5 ## moral5 19668 0.76 0.75 0.70 0.64 3.8 1.9 ## moral6 19679 0.68 0.67 0.58 0.54 3.8 1.8 ## moral7 19665 0.76 0.76 0.70 0.65 3.7 1.7 ## ## Non missing response frequency for each item ## 0 1 2 3 4 5 6 miss ## moral1 0.11 0.13 0.14 0.18 0.18 0.15 0.12 0.02 ## moral2 0.03 0.03 0.05 0.09 0.18 0.28 0.34 0.02 ## moral3 0.10 0.11 0.13 0.17 0.20 0.17 0.12 0.02 ## moral4 0.03 0.03 0.06 0.11 0.19 0.29 0.30 0.02 ## moral5 0.07 0.08 0.10 0.15 0.17 0.21 0.23 0.02 ## moral6 0.07 0.07 0.10 0.14 0.20 0.22 0.20 0.02 ## moral7 0.06 0.08 0.10 0.17 0.21 0.22 0.16 0.02 disgust %\u0026gt;% select(sexual1:sexual7) %\u0026gt;% psych::alpha(title = \u0026quot;sexual disgust\u0026quot;) ## ## Reliability analysis sexual disgust ## Call: psych::alpha(x = ., title = \u0026quot;sexual disgust\u0026quot;) ## ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd median_r ## 0.81 0.81 0.8 0.38 4.3 0.0021 2.6 1.4 0.4 ## ## lower alpha upper 95% confidence boundaries ## 0.8 0.81 0.81 ## ## Reliability if an item is dropped: ## raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r ## sexual1 0.77 0.78 0.76 0.37 3.5 0.0025 0.0073 0.38 ## sexual2 0.79 0.79 0.77 0.38 3.7 0.0023 0.0043 0.40 ## sexual3 0.77 0.77 0.74 0.36 3.3 0.0025 0.0045 0.38 ## sexual4 0.79 0.80 0.77 0.39 3.9 0.0023 0.0073 0.40 ## sexual5 0.77 0.78 0.76 0.37 3.5 0.0025 0.0077 0.37 ## sexual6 0.80 0.80 0.78 0.40 4.0 0.0022 0.0052 0.40 ## sexual7 0.79 0.79 0.77 0.38 3.7 0.0024 0.0078 0.40 ## ## Item statistics ## n raw.r std.r r.cor r.drop mean sd ## sexual1 19693 0.71 0.72 0.66 0.59 2.4 1.9 ## sexual2 19664 0.65 0.67 0.59 0.52 1.4 1.8 ## sexual3 19690 0.74 0.75 0.71 0.63 1.6 1.9 ## sexual4 19703 0.64 0.64 0.54 0.49 3.0 2.0 ## sexual5 19695 0.73 0.72 0.66 0.59 2.7 2.1 ## sexual6 19670 0.62 0.62 0.52 0.46 3.9 2.1 ## sexual7 19684 0.69 0.67 0.59 0.53 2.9 2.2 ## ## Non missing response frequency for each item ## 0 1 2 3 4 5 6 miss ## sexual1 0.20 0.19 0.16 0.16 0.13 0.09 0.07 0.02 ## sexual2 0.47 0.19 0.10 0.09 0.05 0.04 0.05 0.02 ## sexual3 0.41 0.20 0.11 0.10 0.07 0.05 0.06 0.02 ## sexual4 0.14 0.13 0.14 0.15 0.16 0.14 0.13 0.01 ## sexual5 0.20 0.16 0.13 0.14 0.11 0.11 0.14 0.02 ## sexual6 0.10 0.08 0.08 0.11 0.12 0.19 0.33 0.02 ## sexual7 0.21 0.15 0.11 0.11 0.10 0.12 0.20 0.02 disgust %\u0026gt;% select(pathogen1:pathogen7) %\u0026gt;% psych::alpha(title = \u0026quot;pathogen disgust\u0026quot;) ## ## Reliability analysis pathogen disgust ## Call: psych::alpha(x = ., title = \u0026quot;pathogen disgust\u0026quot;) ## ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd median_r ## 0.74 0.74 0.72 0.29 2.9 0.0028 3.7 1.1 0.3 ## ## lower alpha upper 95% confidence boundaries ## 0.73 0.74 0.74 ## ## Reliability if an item is dropped: ## raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r ## pathogen1 0.71 0.71 0.69 0.29 2.5 0.0032 0.0042 0.26 ## pathogen2 0.70 0.71 0.68 0.29 2.5 0.0032 0.0033 0.30 ## pathogen3 0.70 0.70 0.67 0.28 2.4 0.0033 0.0028 0.26 ## pathogen4 0.71 0.72 0.69 0.30 2.5 0.0032 0.0042 0.30 ## pathogen5 0.70 0.70 0.67 0.28 2.4 0.0033 0.0030 0.26 ## pathogen6 0.72 0.72 0.70 0.30 2.6 0.0031 0.0042 0.31 ## pathogen7 0.71 0.72 0.69 0.30 2.6 0.0031 0.0037 0.30 ## ## Item statistics ## n raw.r std.r r.cor r.drop mean sd ## pathogen1 19668 0.60 0.63 0.53 0.45 4.4 1.5 ## pathogen2 19683 0.64 0.63 0.54 0.46 3.3 1.7 ## pathogen3 19687 0.65 0.66 0.58 0.49 3.2 1.6 ## pathogen4 19683 0.62 0.62 0.52 0.44 3.7 1.8 ## pathogen5 19678 0.64 0.67 0.59 0.50 4.3 1.4 ## pathogen6 19655 0.61 0.59 0.48 0.41 3.8 1.9 ## pathogen7 19692 0.63 0.61 0.50 0.43 3.5 1.9 ## ## Non missing response frequency for each item ## 0 1 2 3 4 5 6 miss ## pathogen1 0.01 0.04 0.07 0.11 0.22 0.26 0.29 0.02 ## pathogen2 0.07 0.12 0.14 0.18 0.22 0.16 0.11 0.02 ## pathogen3 0.05 0.14 0.17 0.19 0.24 0.14 0.08 0.02 ## pathogen4 0.04 0.11 0.12 0.15 0.21 0.19 0.18 0.02 ## pathogen5 0.01 0.04 0.08 0.13 0.24 0.27 0.23 0.02 ## pathogen6 0.06 0.10 0.10 0.13 0.18 0.19 0.25 0.02 ## pathogen7 0.08 0.12 0.12 0.13 0.17 0.17 0.20 0.02   ","date":1505174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505174400,"objectID":"592c725536b97cf2ef893c4bb6567305","permalink":"https://debruine.github.io/post/psych-alpha/","publishdate":"2017-09-12T00:00:00Z","relpermalink":"/post/psych-alpha/","section":"post","summary":"This is a tutorial in progress on how to calculate Cronbach‚Äôs alphas using the psych package in R.\nlibrary(tidyverse) library(psych) disgust \u0026lt;- read_csv(\u0026quot;https://psyteachr.github.io/msc-data-skills/data/disgust.csv\u0026quot;) SPSS  Under the Analyze menu, choose Scale and Reliability Analysis.","tags":["R","alpha","psych-r-package","cronbach","SPSS"],"title":"psych::alpha()","type":"post"},{"authors":null,"categories":["rstats"],"content":" I‚Äôm going to use intra-class correlations to demonstrate how to run an analysis on subgroups of data (because I‚Äôm constantly forgetting exactly how to do it).\nlibrary(tidyverse) library(irr) Load the rating data for the open-source Face Research Lab London Set. The data set contains 1-7 attractiveness ratings from 2513 raters for the 102 faces in the set (X001:X173).\nlondon \u0026lt;- read_csv(\u0026quot;https://ndownloader.figshare.com/files/8542045\u0026quot;) head(london) ## # A tibble: 6 x 105 ## rater_sex rater_sexpref rater_age X001 X002 X003 X004 X005 X006 X007 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 female either 17 3 3 3 3 2 3 5 ## 2 female either 17 5 2 3 2 1 5 6 ## 3 female either 17.1 5 3 4 3 3 4 4 ## 4 female either 17.1 4 6 5 5 3 4 5 ## 5 female either 17.2 3 4 3 1 1 1 3 ## 6 female either 17.3 6 5 5 3 7 5 6 ## # ‚Ä¶ with 95 more variables: X008 \u0026lt;dbl\u0026gt;, X009 \u0026lt;dbl\u0026gt;, X010 \u0026lt;dbl\u0026gt;, X011 \u0026lt;dbl\u0026gt;, ## # X012 \u0026lt;dbl\u0026gt;, X013 \u0026lt;dbl\u0026gt;, X014 \u0026lt;dbl\u0026gt;, X016 \u0026lt;dbl\u0026gt;, X017 \u0026lt;dbl\u0026gt;, X018 \u0026lt;dbl\u0026gt;, ## # X019 \u0026lt;dbl\u0026gt;, X020 \u0026lt;dbl\u0026gt;, X021 \u0026lt;dbl\u0026gt;, X022 \u0026lt;dbl\u0026gt;, X024 \u0026lt;dbl\u0026gt;, X025 \u0026lt;dbl\u0026gt;, ## # X026 \u0026lt;dbl\u0026gt;, X027 \u0026lt;dbl\u0026gt;, X029 \u0026lt;dbl\u0026gt;, X030 \u0026lt;dbl\u0026gt;, X031 \u0026lt;dbl\u0026gt;, X032 \u0026lt;dbl\u0026gt;, ## # X033 \u0026lt;dbl\u0026gt;, X034 \u0026lt;dbl\u0026gt;, X036 \u0026lt;dbl\u0026gt;, X037 \u0026lt;dbl\u0026gt;, X038 \u0026lt;dbl\u0026gt;, X039 \u0026lt;dbl\u0026gt;, ## # X041 \u0026lt;dbl\u0026gt;, X042 \u0026lt;dbl\u0026gt;, X043 \u0026lt;dbl\u0026gt;, X044 \u0026lt;dbl\u0026gt;, X045 \u0026lt;dbl\u0026gt;, X061 \u0026lt;dbl\u0026gt;, ## # X062 \u0026lt;dbl\u0026gt;, X063 \u0026lt;dbl\u0026gt;, X064 \u0026lt;dbl\u0026gt;, X066 \u0026lt;dbl\u0026gt;, X067 \u0026lt;dbl\u0026gt;, X068 \u0026lt;dbl\u0026gt;, ## # X069 \u0026lt;dbl\u0026gt;, X070 \u0026lt;dbl\u0026gt;, X081 \u0026lt;dbl\u0026gt;, X082 \u0026lt;dbl\u0026gt;, X083 \u0026lt;dbl\u0026gt;, X086 \u0026lt;dbl\u0026gt;, ## # X087 \u0026lt;dbl\u0026gt;, X090 \u0026lt;dbl\u0026gt;, X091 \u0026lt;dbl\u0026gt;, X092 \u0026lt;dbl\u0026gt;, X094 \u0026lt;dbl\u0026gt;, X096 \u0026lt;dbl\u0026gt;, ## # X097 \u0026lt;dbl\u0026gt;, X099 \u0026lt;dbl\u0026gt;, X100 \u0026lt;dbl\u0026gt;, X101 \u0026lt;dbl\u0026gt;, X102 \u0026lt;dbl\u0026gt;, X103 \u0026lt;dbl\u0026gt;, ## # X104 \u0026lt;dbl\u0026gt;, X105 \u0026lt;dbl\u0026gt;, X107 \u0026lt;dbl\u0026gt;, X108 \u0026lt;dbl\u0026gt;, X112 \u0026lt;dbl\u0026gt;, X113 \u0026lt;dbl\u0026gt;, ## # X114 \u0026lt;dbl\u0026gt;, X115 \u0026lt;dbl\u0026gt;, X117 \u0026lt;dbl\u0026gt;, X118 \u0026lt;dbl\u0026gt;, X119 \u0026lt;dbl\u0026gt;, X120 \u0026lt;dbl\u0026gt;, ## # X121 \u0026lt;dbl\u0026gt;, X122 \u0026lt;dbl\u0026gt;, X123 \u0026lt;dbl\u0026gt;, X124 \u0026lt;dbl\u0026gt;, X125 \u0026lt;dbl\u0026gt;, X126 \u0026lt;dbl\u0026gt;, ## # X127 \u0026lt;dbl\u0026gt;, X128 \u0026lt;dbl\u0026gt;, X129 \u0026lt;dbl\u0026gt;, X130 \u0026lt;dbl\u0026gt;, X131 \u0026lt;dbl\u0026gt;, X132 \u0026lt;dbl\u0026gt;, ## # X134 \u0026lt;dbl\u0026gt;, X135 \u0026lt;dbl\u0026gt;, X136 \u0026lt;dbl\u0026gt;, X137 \u0026lt;dbl\u0026gt;, X138 \u0026lt;dbl\u0026gt;, X139 \u0026lt;dbl\u0026gt;, ## # X140 \u0026lt;dbl\u0026gt;, X141 \u0026lt;dbl\u0026gt;, X142 \u0026lt;dbl\u0026gt;, X143 \u0026lt;dbl\u0026gt;, X144 \u0026lt;dbl\u0026gt;, X172 \u0026lt;dbl\u0026gt;, ## # X173 \u0026lt;dbl\u0026gt; To calculate the ICC for ratings, first we need to get the data into a format where each column represents a rater and each row represents a stimulus. Select just the columns with ratings, then transpose (t()) the data.\nlondon %\u0026gt;% select(X001:X173) %\u0026gt;% t() %\u0026gt;% irr::icc() ## Single Score Intraclass Correlation ## ## Model: oneway ## Type : consistency ## ## Subjects = 102 ## Raters = 2513 ## ICC(1) = 0.24 ## ## F-Test, H0: r0 = 0 ; H1: r0 \u0026gt; 0 ## F(101,256224) = 793 , p = 0 ## ## 95%-Confidence Interval for ICC Population Values: ## 0.196 \u0026lt; ICC \u0026lt; 0.298 But what if you want to do this for several subsets of the raters or stimuli? One solution is to run the code above several times, once for each subset, adding code to select and filter.\nlondon %\u0026gt;% filter(rater_sex == \u0026quot;male\u0026quot;) %\u0026gt;% select(X001:X173) %\u0026gt;% t() %\u0026gt;% irr::icc() ## Single Score Intraclass Correlation ## ## Model: oneway ## Type : consistency ## ## Subjects = 102 ## Raters = 955 ## ICC(1) = 0.225 ## ## F-Test, H0: r0 = 0 ; H1: r0 \u0026gt; 0 ## F(101,97308) = 279 , p = 0 ## ## 95%-Confidence Interval for ICC Population Values: ## 0.183 \u0026lt; ICC \u0026lt; 0.281 london %\u0026gt;% filter(rater_sex == \u0026quot;female\u0026quot;) %\u0026gt;% select(X001:X173) %\u0026gt;% t() %\u0026gt;% irr::icc() ## Single Score Intraclass Correlation ## ## Model: oneway ## Type : consistency ## ## Subjects = 102 ## Raters = 1552 ## ICC(1) = 0.253 ## ## F-Test, H0: r0 = 0 ; H1: r0 \u0026gt; 0 ## F(101,158202) = 526 , p = 0 ## ## 95%-Confidence Interval for ICC Population Values: ## 0.207 \u0026lt; ICC \u0026lt; 0.313 But what if you want to calculate ICCs for lots of subdivisions? It‚Äôs tedious and error-prone to do each one by hand, but you can group your data into the subdivisions, nest the ratings, and map them onto a function.\nFirst, we have to write a function that takes the data and returns a table of the stats you‚Äôre interested in. The irr::icc() function returns a list, which won‚Äôt play well with nesting later, so we unlist() it, transpose it so it‚Äôs a row of values, not a column, turn it back into a tibble (transposing turns it into a matrix), and select just the columns you want.\nmy_icc \u0026lt;- function(data) { data %\u0026gt;% select(X001:X173) %\u0026gt;% # select just the rating columns t() %\u0026gt;% # transpose so columns are raters and rows are stimuli irr::icc() %\u0026gt;% # calculate the ICC unlist() %\u0026gt;% # turn the output list into a vector t() %\u0026gt;% # transpose this vector as_tibble() %\u0026gt;% # turn the vector into a table select( # select just the columns you want stimuli = subjects, # rename subjects to stimuli raters, icc = value, # rename value to icc lbound, ubound ) %\u0026gt;% # fix column modes (unlisting turned them all into characters) mutate_at(vars(stimuli, raters), as.integer) %\u0026gt;% mutate_at(vars(icc:ubound), as.numeric) } Test the function on the whole dataset to check it gives you the right data.\nmy_icc(london) ## # A tibble: 1 x 5 ## stimuli raters icc lbound ubound ## \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 102 2513 0.240 0.196 0.298 Then we can group our full dataframe. Here I‚Äôve created a new column of age group and filtered out age/sex groups with fewer than 10 raters. After you group your data, use the nest() function to turn all the rest of the columns into a separate table for each group (stored in the column data). Then you can map these tables onto your my_icc function. Finally, unnest this new icc column to re-expand your table.\nlondon_icc_grouped \u0026lt;- london %\u0026gt;% mutate(age_group = round(rater_age / 10)*10) %\u0026gt;% # create age group by decade group_by(rater_sex, age_group) %\u0026gt;% # group by rater age and sex filter(n() \u0026gt;= 10) %\u0026gt;% # remove groups smaller than 10 nest() %\u0026gt;% # nest the rest of the columns mutate(icc = map(data, my_icc)) %\u0026gt;% # calculate ICC for each group unnest(icc) %\u0026gt;% # expand the tables returned to icc select(-data) # get rid of the data column london_icc_grouped ## # A tibble: 10 x 7 ## # Groups: rater_sex, age_group [10] ## rater_sex age_group stimuli raters icc lbound ubound ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 female 20 102 1035 0.253 0.207 0.313 ## 2 female 30 102 317 0.257 0.211 0.319 ## 3 female 40 102 123 0.264 0.216 0.327 ## 4 female 50 102 54 0.255 0.206 0.319 ## 5 female 60 102 20 0.271 0.215 0.342 ## 6 male 20 102 478 0.211 0.171 0.265 ## 7 male 30 102 253 0.252 0.206 0.312 ## 8 male 40 102 119 0.217 0.175 0.274 ## 9 male 50 102 74 0.267 0.218 0.332 ## 10 male 60 102 27 0.245 0.194 0.311 ","date":1503273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1503273600,"objectID":"c819c21add164de67a47adb52235cc6c","permalink":"https://debruine.github.io/post/nest/","publishdate":"2017-08-21T00:00:00Z","relpermalink":"/post/nest/","section":"post","summary":"I‚Äôm going to use intra-class correlations to demonstrate how to run an analysis on subgroups of data (because I‚Äôm constantly forgetting exactly how to do it).\nlibrary(tidyverse) library(irr) Load the rating data for the open-source Face Research Lab London Set.","tags":["R","tidyverse","nest","icc"],"title":"nest() and irr::icc()","type":"post"},{"authors":null,"categories":["stats"],"content":"  EJ Wagenmakers started an interesting debate last night with a twitter poll on p-values. Some responses suggested you can multiply p-values from several tests to create a sort of cumulative p-value that is the joint probability of the null hypothesis.\nI also used to believe that you could multiply p-values, but am now a bit embarassed at my misunderstanding, common as it is. The p-value is not the probability that the null hypothesis is true, it is the probability of obtaining the current (or more extreme) values under the null hypothesis. This important distinction means you cannot multiply p-values to obtain the joint probability of several tests.\nFirst, I‚Äôll write a simple function to generate two sets of n samples from a normal distribution with the same mean and SD, then return the p-value for a t-test.\nnullp \u0026lt;- function(n) { a = rnorm(n) b = rnorm(n) t = t.test(a, b) t$p.value } I‚Äôll run this simulation 10000 times with samples of n = 1000 to get a good distribution of p-values under the null hypothesis. The histogram shows that this is a unifrom distribution.\nps \u0026lt;- replicate(10000, nullp(1000)) hist(ps) Then sample 1000 p-values from this distributions once, twice, thrice, and whatever the word is for four times. This should convince you that the cumulative p-value cannot provide the joint probability of the null hypothesis for multiple tests.\ntibble( x1 = sample(ps, 1000), x2 = sample(ps, 1000) * sample(ps, 1000), x3 = sample(ps, 1000) * sample(ps, 1000) * sample(ps, 1000), x4 = sample(ps, 1000) * sample(ps, 1000) * sample(ps, 1000) * sample(ps, 1000) ) %\u0026gt;% gather(\u0026quot;n_tests\u0026quot;, \u0026quot;cum_p\u0026quot;, x1:x4) %\u0026gt;% ggplot(aes(cum_p, fill=n_tests)) + geom_density(alpha = 0.5) + labs(x =\u0026quot;Cumulative p-value\u0026quot;)  Figure 1: Cumulative p-value distribution under the null hypothesis  ","date":1501113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501113600,"objectID":"1260084b4813ba6a5abf0e99f60a5f21","permalink":"https://debruine.github.io/post/cumulative-p/","publishdate":"2017-07-27T00:00:00Z","relpermalink":"/post/cumulative-p/","section":"post","summary":"EJ Wagenmakers started an interesting debate last night with a twitter poll on p-values. Some responses suggested you can multiply p-values from several tests to create a sort of cumulative p-value that is the joint probability of the null hypothesis.","tags":["p-value"],"title":"Cumulative p","type":"post"},{"authors":null,"categories":["rstats"],"content":" First, let‚Äôs make a data frame with two variables, a and b that are both sampled from a normal distribution with a mean of 0 and SD of 1. The variablle n will be how many samples we‚Äôll take (100). Then we can run a t-test to see if they are different.\nlibrary(tidyverse) ## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ ## ‚úì ggplot2 3.3.2 ‚úì purrr 0.3.4 ## ‚úì tibble 3.0.3 ‚úì dplyr 1.0.2 ## ‚úì tidyr 1.1.1 ‚úì stringr 1.4.0 ## ‚úì readr 1.3.1 ‚úì forcats 0.5.0 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() n = 100 data \u0026lt;- data.frame( a = rnorm(n, 0, 1), b = rnorm(n, 0, 1) ) t \u0026lt;- t.test(data$a,data$b) t$p.value ## [1] 0.1527518 Now let‚Äôs repeat that procedure 1000 times. The easiest way to do that is to make a function that returns the information you want.\ntPower \u0026lt;- function() { n = 100 data \u0026lt;- data.frame( a = rnorm(n, 0, 1), b = rnorm(n, 0, 1) ) t \u0026lt;- t.test(data$a,data$b) return(t$p.value) } tPower() ## [1] 0.7583175 mySample \u0026lt;- data.frame( p = replicate(10000, tPower()) ) mySample %\u0026gt;% ggplot(aes(p)) + geom_histogram(bins = 20, boundary = 0) mean(mySample$p \u0026lt; .05) ## [1] 0.0528 What if you induced a small effect of 0.2 SD?\ntPower2 \u0026lt;- function() { n = 100 data \u0026lt;- data.frame( a = rnorm(n, 0, 1), b = rnorm(n, 0.2, 1) ) t \u0026lt;- t.test(data$a,data$b) return(t$p.value) } tPower2() ## [1] 0.9142489 mySample2 \u0026lt;- data.frame( p = replicate(10000, tPower2()) ) mySample2 %\u0026gt;% ggplot(aes(p)) + geom_histogram(bins = 20, boundary = 0) mean(mySample2$p \u0026lt; .05) ## [1] 0.2929 Hmm, you only get a p-value less than .05 30% of the time. That means that your study would only have 30% power to detect an effect this big with 100 subjects. Let‚Äôs make a new function to give you the p-value of a study with any number of subjects (you put the N inside the parentheses of the function).\ntPowerN \u0026lt;- function(n) { data \u0026lt;- data.frame( a = rnorm(n, 0, 1), b = rnorm(n, 0.2, 1) ) t \u0026lt;- t.test(data$a,data$b) return(t$p.value) } tPowerN(200) ## [1] 0.2969539 mySampleN \u0026lt;- data.frame( p200 = replicate(10000, tPowerN(200)) ) mySampleN %\u0026gt;% ggplot(aes(p200)) + geom_histogram(bins = 20, boundary = 0) mean(mySampleN$p200 \u0026lt; .05) ## [1] 0.5137 nlist \u0026lt;- seq(200, 1000, by = 100) remove(mySampleN) for (n in nlist) { temp \u0026lt;- data.frame( n = n, p = replicate(1000, tPowerN(n)) ) if (exists(\u0026quot;mySampleN\u0026quot;)) { mySampleN \u0026lt;- rbind(mySampleN, temp) } else { mySampleN \u0026lt;- temp } remove(temp) print(n) } ## [1] 200 ## [1] 300 ## [1] 400 ## [1] 500 ## [1] 600 ## [1] 700 ## [1] 800 ## [1] 900 ## [1] 1000 mySampleN %\u0026gt;% ggplot(aes(p)) + geom_histogram(bins = 20, boundary = 0) + facet_wrap(~n, nrow = 3) ","date":1501027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501027200,"objectID":"041b3565413e825a6048c9faec10745a","permalink":"https://debruine.github.io/post/sample/","publishdate":"2017-07-26T00:00:00Z","relpermalink":"/post/sample/","section":"post","summary":"First, let‚Äôs make a data frame with two variables, a and b that are both sampled from a normal distribution with a mean of 0 and SD of 1. The variablle n will be how many samples we‚Äôll take (100).","tags":["R","simulation"],"title":"sample()","type":"post"},{"authors":null,"categories":["rstats"],"content":" I often find myself needing to recode variables. I wrote previously about recoding a characters into a numbers using various coding schemes. But sometimes I want to recode numeric values into characters; this is particularly useful for graphing and for double-checking the meaning of your variable levels.\nFirst, I‚Äôll create a data frame with 50 subjects and randomly choose their genders from a list of 4 possibilities with the population proportions 40% male, 40% female, 10% non-binary, and 10% missing data.\nsuppressMessages( library(tidyverse) ) set.seed(12) # for reproducibility; delete when running simulations genders \u0026lt;- c(\u0026quot;male\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;nonbinary\u0026quot;, NA) df \u0026lt;- data.frame( id = rep(1:50), gender = sample(genders, 50, replace = TRUE, prob = c(.4, .4, .1, .1)) ) I‚Äôll graph it to make sure it looks like I expect. This is one of the few times a bar plot is appropriate.\ndf %\u0026gt;% ggplot(aes(gender)) + geom_bar(fill=\u0026quot;red\u0026quot;) Now I‚Äôm going to transform the character variables into numbers and graph it again. As you can see, when a categorical variable is coded with numbers, the missing values are omitted from the graph.\ndf2 \u0026lt;- df %\u0026gt;% mutate( gender.num = recode(gender, \u0026quot;male\u0026quot; = 1, \u0026quot;female\u0026quot; = 2, \u0026quot;nonbinary\u0026quot; = 3) ) df2 %\u0026gt;% ggplot(aes(gender.num)) + geom_bar(fill=\u0026quot;darkorange\u0026quot;) ## Warning: Removed 3 rows containing non-finite values (stat_count). Now I‚Äôm going to recode the numeric column back into words.\n# this won\u0026#39;t work df3 \u0026lt;- df2 %\u0026gt;% mutate( gender.cat = recode(gender.num, 1 = \u0026quot;male\u0026quot;, 2 = \u0026quot;female\u0026quot;, 3 = \u0026quot;nonbinary\u0026quot;) ) That didn‚Äôt work. You‚Äôll get an error that looks like:\nError: unexpected '=' in: \" mutate( gender.cat = recode(gender.num, 1 =\" recode() requires that the left side of the equal sign be in quotes. Let‚Äôs try this again and graph it.\ndf3 \u0026lt;- df2 %\u0026gt;% mutate( gender.cat = recode(gender.num, \u0026quot;1\u0026quot; = \u0026quot;male\u0026quot;, \u0026quot;2\u0026quot; = \u0026quot;female\u0026quot;, \u0026quot;3\u0026quot; = \u0026quot;nonbinary\u0026quot;) ) df3 %\u0026gt;% ggplot(aes(gender.cat)) + geom_bar(fill=\u0026quot;goldenrod\u0026quot;) What if you want your variables in a different order? You can use the factor() function to set the order of the levels.\ndf4 \u0026lt;- df3 %\u0026gt;% mutate( gender.ordered = factor(gender.cat, levels = c(\u0026quot;nonbinary\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;male\u0026quot;)) ) df4 %\u0026gt;% ggplot(aes(gender.ordered)) + geom_bar(fill=\u0026quot;darkgreen\u0026quot;) Let‚Äôs put it all together to see how you can go from numeric to character values and get them in the order you want. We‚Äôll start with an ‚Äúoriginal‚Äù dataframe of just the numerically coded genders from the previous data. Then we‚Äôll make a new data frame by recoding the numeric column into words and then ordering this.\nNote that I‚Äôve given the new column the name gender.ordered and then redefined this column with the reordered levels. This is a nice feature of the tidyverse. You could put all that code on one line with complicated brackets, but it‚Äôs easier to manipulate a variable in steps and you can use previously created variables in subsequent steps of a mutate() function.\ndata.original \u0026lt;- df4 %\u0026gt;% select(gender.num) data.recoded \u0026lt;- data.original %\u0026gt;% mutate( gender.ordered = recode(gender.num, \u0026quot;1\u0026quot; = \u0026quot;male\u0026quot;, \u0026quot;2\u0026quot; = \u0026quot;female\u0026quot;, \u0026quot;3\u0026quot; = \u0026quot;nonbinary\u0026quot;), gender.ordered = factor(gender.ordered, levels = c(\u0026quot;nonbinary\u0026quot;, \u0026quot;female\u0026quot;, \u0026quot;male\u0026quot;)) ) data.recoded %\u0026gt;% ggplot(aes(gender.ordered)) + geom_bar(fill=\u0026quot;blue\u0026quot;) ","date":1499990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499990400,"objectID":"9ea208b3a93bc089fee014717a060894","permalink":"https://debruine.github.io/post/recode/","publishdate":"2017-07-14T00:00:00Z","relpermalink":"/post/recode/","section":"post","summary":"I often find myself needing to recode variables. I wrote previously about recoding a characters into a numbers using various coding schemes. But sometimes I want to recode numeric values into characters; this is particularly useful for graphing and for double-checking the meaning of your variable levels.","tags":["r","tidyverse","recoding","categorical"],"title":"recode()","type":"post"},{"authors":null,"categories":["rstats"],"content":" Download the Rmd notebook for this example\nPutting together this page made me realise I still don‚Äôt know anything about PCA and factor analysis.\nI use the psych package for SPSS-style PCA.\nlibrary(tidyverse) library(psych) library(viridis) First, I‚Äôll simulate some data with an underlying structure of three factors.\nset.seed(444) # for reproducibility; delete when running simulations a \u0026lt;- rnorm(100, 0, 1) b \u0026lt;- rnorm(100, 0, 1) c \u0026lt;- rnorm(100, 0, 1) df \u0026lt;- data.frame( id = seq(1,100), a1 = a + rnorm(100, 0, 1), a2 = a + rnorm(100, 0, .8), a3 = a + rnorm(100, 0, .6), a4 = -a + rnorm(100, 0, .4), b1 = b + rnorm(100, 0, 1), b2 = b + rnorm(100, 0, .8), b3 = b + rnorm(100, 0, .6), b4 = -b + rnorm(100, 0, .4), c1 = c + rnorm(100, 0, 1), c2 = c + rnorm(100, 0, .8), c3 = c + rnorm(100, 0, .6), c4 = -c + rnorm(100, 0, .4) ) Select just the columns you want for your PCA. You can visualise their correlations with cor() and ggplot().\ntraits \u0026lt;- df %\u0026gt;% select(-id) traits %\u0026gt;% cor() %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1)) Determine the number of factors to extract. Here I use the SPSS-style default criterion of Eigenvalues \u0026gt; 1\nev \u0026lt;- eigen(cor(traits)); nfactors \u0026lt;- length(ev$values[ev$values \u0026gt; 1]); nfactors ## [1] 3 Principal components analysis (SPSS-style) principal(rotation = ‚Äúnone‚Äù) traits.principal \u0026lt;- principal(traits, nfactors=nfactors, rotate=\u0026quot;none\u0026quot;, scores=TRUE) traits.principal ## Principal Components Analysis ## Call: principal(r = traits, nfactors = nfactors, rotate = \u0026quot;none\u0026quot;, scores = TRUE) ## Standardized loadings (pattern matrix) based upon correlation matrix ## PC1 PC2 PC3 h2 u2 com ## a1 -0.63 0.24 0.42 0.63 0.37 2.1 ## a2 -0.72 0.12 0.50 0.77 0.23 1.8 ## a3 -0.65 0.26 0.55 0.79 0.21 2.3 ## a4 0.73 -0.23 -0.49 0.83 0.17 2.0 ## b1 0.14 0.75 -0.19 0.62 0.38 1.2 ## b2 0.09 0.83 -0.16 0.71 0.29 1.1 ## b3 0.10 0.89 -0.16 0.83 0.17 1.1 ## b4 -0.12 -0.88 0.15 0.81 0.19 1.1 ## c1 0.64 0.04 0.50 0.66 0.34 1.9 ## c2 0.77 0.10 0.42 0.78 0.22 1.6 ## c3 0.70 0.08 0.54 0.79 0.21 1.9 ## c4 -0.80 -0.04 -0.49 0.88 0.12 1.7 ## ## PC1 PC2 PC3 ## SS loadings 4.05 3.02 2.03 ## Proportion Var 0.34 0.25 0.17 ## Cumulative Var 0.34 0.59 0.76 ## Proportion Explained 0.45 0.33 0.22 ## Cumulative Proportion 0.45 0.78 1.00 ## ## Mean item complexity = 1.6 ## Test of the hypothesis that 3 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.05 ## with the empirical chi square 33.59 with prob \u0026lt; 0.44 ## ## Fit based upon off diagonal values = 0.98 scores.principal \u0026lt;- traits.principal$scores cor(scores.principal, traits) %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1))  principal(rotation = ‚Äúvarimax‚Äù) traits.varimax \u0026lt;- principal(traits, nfactors=nfactors, rotate=\u0026quot;varimax\u0026quot;, scores=TRUE) traits.varimax ## Principal Components Analysis ## Call: principal(r = traits, nfactors = nfactors, rotate = \u0026quot;varimax\u0026quot;, ## scores = TRUE) ## Standardized loadings (pattern matrix) based upon correlation matrix ## RC1 RC3 RC2 h2 u2 com ## a1 -0.15 0.78 0.06 0.63 0.37 1.1 ## a2 -0.16 0.86 -0.09 0.77 0.23 1.1 ## a3 -0.07 0.89 0.05 0.79 0.21 1.0 ## a4 0.17 -0.90 -0.02 0.83 0.17 1.1 ## b1 0.03 -0.05 0.79 0.62 0.38 1.0 ## b2 0.02 0.03 0.84 0.71 0.29 1.0 ## b3 0.03 0.05 0.91 0.83 0.17 1.0 ## b4 -0.05 -0.03 -0.90 0.81 0.19 1.0 ## c1 0.81 -0.08 0.00 0.66 0.34 1.0 ## c2 0.85 -0.21 0.09 0.78 0.22 1.1 ## c3 0.88 -0.09 0.04 0.79 0.21 1.0 ## c4 -0.92 0.20 -0.02 0.88 0.12 1.1 ## ## RC1 RC3 RC2 ## SS loadings 3.09 3.03 2.98 ## Proportion Var 0.26 0.25 0.25 ## Cumulative Var 0.26 0.51 0.76 ## Proportion Explained 0.34 0.33 0.33 ## Cumulative Proportion 0.34 0.67 1.00 ## ## Mean item complexity = 1 ## Test of the hypothesis that 3 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.05 ## with the empirical chi square 33.59 with prob \u0026lt; 0.44 ## ## Fit based upon off diagonal values = 0.98 scores.varimax \u0026lt;- traits.varimax$scores cor(scores.varimax, traits) %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1))   Here are some other functions for PCA/Factor Analysis princomp() traits.princomp \u0026lt;- princomp(traits) traits.princomp$loadings[,1:nfactors] ## Comp.1 Comp.2 Comp.3 ## a1 0.33006521 0.181709692 0.45906811 ## a2 0.29151833 0.067518916 0.38086462 ## a3 0.23950762 0.132057875 0.38289101 ## a4 -0.25823681 -0.112938603 -0.32926216 ## b1 -0.10631062 0.507810878 -0.12639281 ## b2 -0.07370167 0.500188081 -0.09771759 ## b3 -0.06894907 0.491029731 -0.08032005 ## b4 0.07460353 -0.426344256 0.07374535 ## c1 -0.44100481 -0.021914387 0.38825383 ## c2 -0.42646359 0.010511567 0.23488306 ## c3 -0.35757417 -0.001802824 0.29574993 ## c4 0.38827130 0.026358392 -0.24163371 scores.princomp \u0026lt;- traits.princomp$scores[,1:nfactors] cor(scores.princomp, traits) %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1))  factanal(rotation = ‚Äúnone‚Äù) traits.fa \u0026lt;- factanal(traits, nfactors, rotation=\u0026quot;none\u0026quot;, scores=\u0026quot;regression\u0026quot;) print(traits.fa, digits=2, cutoff=0, sort=FALSE) ## ## Call: ## factanal(x = traits, factors = nfactors, scores = \u0026quot;regression\u0026quot;, rotation = \u0026quot;none\u0026quot;) ## ## Uniquenesses: ## a1 a2 a3 a4 b1 b2 b3 b4 c1 c2 c3 c4 ## 0.52 0.32 0.26 0.18 0.53 0.40 0.18 0.23 0.50 0.27 0.32 0.08 ## ## Loadings: ## Factor1 Factor2 Factor3 ## a1 -0.46 0.26 0.45 ## a2 -0.55 0.17 0.60 ## a3 -0.47 0.32 0.64 ## a4 0.57 -0.30 -0.64 ## b1 0.09 0.63 -0.25 ## b2 0.07 0.74 -0.21 ## b3 0.08 0.87 -0.24 ## b4 -0.10 -0.84 0.24 ## c1 0.66 0.03 0.25 ## c2 0.83 0.09 0.19 ## c3 0.77 0.08 0.29 ## c4 -0.92 -0.05 -0.28 ## ## Factor1 Factor2 Factor3 ## SS loadings 3.65 2.71 1.86 ## Proportion Var 0.30 0.23 0.16 ## Cumulative Var 0.30 0.53 0.68 ## ## Test of the hypothesis that 3 factors are sufficient. ## The chi square statistic is 22.21 on 33 degrees of freedom. ## The p-value is 0.923 scores.fa \u0026lt;- traits.fa$scores cor(scores.fa, traits) %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1))  factanal(rotation = ‚Äúvarimax‚Äù) traits.fa.vm \u0026lt;- factanal(traits, nfactors, rotation=\u0026quot;varimax\u0026quot;, scores=\u0026quot;regression\u0026quot;) print(traits.fa.vm, digits=2, cutoff=0, sort=FALSE) ## ## Call: ## factanal(x = traits, factors = nfactors, scores = \u0026quot;regression\u0026quot;, rotation = \u0026quot;varimax\u0026quot;) ## ## Uniquenesses: ## a1 a2 a3 a4 b1 b2 b3 b4 c1 c2 c3 c4 ## 0.52 0.32 0.26 0.18 0.53 0.40 0.18 0.23 0.50 0.27 0.32 0.08 ## ## Loadings: ## Factor1 Factor2 Factor3 ## a1 -0.16 0.67 0.06 ## a2 -0.18 0.80 -0.08 ## a3 -0.08 0.85 0.05 ## a4 0.17 -0.89 -0.03 ## b1 0.02 -0.04 0.68 ## b2 0.03 0.04 0.77 ## b3 0.04 0.05 0.91 ## b4 -0.05 -0.03 -0.87 ## c1 0.70 -0.10 0.00 ## c2 0.82 -0.21 0.09 ## c3 0.82 -0.11 0.04 ## c4 -0.94 0.19 -0.02 ## ## Factor1 Factor2 Factor3 ## SS loadings 2.82 2.73 2.67 ## Proportion Var 0.23 0.23 0.22 ## Cumulative Var 0.23 0.46 0.68 ## ## Test of the hypothesis that 3 factors are sufficient. ## The chi square statistic is 22.21 on 33 degrees of freedom. ## The p-value is 0.923 scores.fa.vm \u0026lt;- traits.fa.vm$scores cor(scores.fa.vm, traits) %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, a1:c4) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(-1, 1))   How do they compare? Here, I‚Äôll plot the absolute value of all the correlations (since the sign on factors/PCs is arbitrary).\nThe functions principal(rotation = ‚Äúvarimax‚Äù) and factanal(rotation = ‚Äúvarimax‚Äù) are nearly (but not perfectly) identical.\nscores.fa \u0026lt;- traits.fa$scores colnames(scores.principal) \u0026lt;- c(\u0026quot;principal() 1\u0026quot;, \u0026quot;principal() 2\u0026quot;, \u0026quot;principal() 3\u0026quot;) colnames(scores.varimax) \u0026lt;- c(\u0026quot;principal(vm) 1\u0026quot;, \u0026quot;principal(vm) 2\u0026quot;, \u0026quot;principal(vm) 3\u0026quot;) colnames(scores.princomp) \u0026lt;- c(\u0026quot;princomp() 1\u0026quot;, \u0026quot;princomp() 2\u0026quot;, \u0026quot;princomp() 3\u0026quot;) colnames(scores.fa) \u0026lt;- c(\u0026quot;factanal() 1\u0026quot;, \u0026quot;factanal() 2\u0026quot;, \u0026quot;factanal() 3\u0026quot;) colnames(scores.fa.vm) \u0026lt;- c(\u0026quot;factanal(vm) 1\u0026quot;, \u0026quot;factanal(vm) 2\u0026quot;, \u0026quot;factanal(vm) 3\u0026quot;) cbind( scores.princomp, scores.principal, scores.fa, scores.varimax, scores.fa.vm ) %\u0026gt;% cor() %\u0026gt;% as.data.frame() %\u0026gt;% mutate(var1 = rownames(.)) %\u0026gt;% gather(\u0026quot;var2\u0026quot;, \u0026quot;value\u0026quot;, 1:15) %\u0026gt;% mutate(var1 = factor(var1), var1 = factor(var1, levels = rev(levels(var1)))) %\u0026gt;% mutate(value = abs(value)) %\u0026gt;% ggplot(aes(var2, var1, fill=value)) + geom_tile() + scale_x_discrete(position = \u0026quot;top\u0026quot;) + xlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + scale_fill_viridis(limits=c(0, 1)) + geom_hline(yintercept = 3.5, color=\u0026quot;white\u0026quot;) + geom_hline(yintercept = 6.5, color=\u0026quot;white\u0026quot;) + geom_hline(yintercept = 9.5, color=\u0026quot;white\u0026quot;) + geom_hline(yintercept = 12.5, color=\u0026quot;white\u0026quot;) + geom_vline(xintercept = 3.5, color=\u0026quot;white\u0026quot;) + geom_vline(xintercept = 6.5, color=\u0026quot;white\u0026quot;) + geom_vline(xintercept = 9.5, color=\u0026quot;white\u0026quot;) + geom_vline(xintercept = 12.5, color=\u0026quot;white\u0026quot;) + theme(axis.text.x=element_text(angle=90,hjust=1))  ","date":1498435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498435200,"objectID":"9887c301935939f850acf35ae9825e1b","permalink":"https://debruine.github.io/post/pca/","publishdate":"2017-06-26T00:00:00Z","relpermalink":"/post/pca/","section":"post","summary":"Download the Rmd notebook for this example\nPutting together this page made me realise I still don‚Äôt know anything about PCA and factor analysis.\nI use the psych package for SPSS-style PCA.","tags":["r","pca","princomp","psych","factanal"],"title":"PCA","type":"post"},{"authors":null,"categories":["rstats"],"content":"  library(tidyverse) library(lmerTest) How you choose to code categorical variables changes how you can interpret the intercept and effects of those variables. My favourite tutorial on coding schemes explains things in detail. I‚Äôm just adding some concrete examples below.\nFirst, I simulated a data frame of 100 raters rating 100 faces each. Female faces get ratings with a mean of 6; male faces get ratings with a mean of 5 (I know, ratings are usually ordinal integers, but let‚Äôs pretend we used something like a slider). To simulate random effects, both raters and faces have random intercepts with SDs of 1.\nset.seed(555) # for reproducibility; delete when running simulations n_raters \u0026lt;- 100 n_faces \u0026lt;- 100 female_mean \u0026lt;- 6 male_mean \u0026lt;- 5 raters \u0026lt;- tibble( rater_id = 1:n_raters, rater_i = rnorm(n_raters) ) faces \u0026lt;- tibble( face_id = 1:n_faces, face_i = rnorm(n_faces), face_sex = rep(c(\u0026quot;female\u0026quot;, \u0026quot;male\u0026quot;), each = n_faces/2) ) df \u0026lt;- expand.grid( face_id = faces$face_id, rater_id = raters$rater_id ) %\u0026gt;% left_join(faces, by = \u0026quot;face_id\u0026quot;) %\u0026gt;% left_join(raters, by = \u0026quot;rater_id\u0026quot;) %\u0026gt;% mutate( face_sex_i = ifelse(face_sex==\u0026quot;male\u0026quot;, male_mean, female_mean), error = rnorm(nrow(.)), rating = face_i + rater_i + face_sex_i + error ) Calculate the means and SDs of the female and male faces.\n  face_sex mean SD    female 5.940 1.767  male 5.114 1.649    Always graph your data to confirm you simulated it correctly.\ndf %\u0026gt;% ggplot(aes(face_sex, rating)) + geom_violin() + geom_boxplot(width=0.2) Recode face sex using treatment, sum, or effect coding.\ndf2 \u0026lt;- df %\u0026gt;% mutate( face_sex.tr = recode(face_sex, \u0026quot;female\u0026quot; = 1, \u0026quot;male\u0026quot; = 0), face_sex.sum = recode(face_sex, \u0026quot;female\u0026quot; = -1, \u0026quot;male\u0026quot; = 1), face_sex.e = recode(face_sex, \u0026quot;female\u0026quot; = -0.5, \u0026quot;male\u0026quot; = 0.5) ) Now we analyse the data using each of the 4 styles of coding. I‚Äôm just going to show the table of fixed effects.\nCategorical coding m1 \u0026lt;- lmerTest::lmer(rating ~ face_sex + (1 | face_id) + (1 + face_sex | rater_id), data = df2)    Estimate Std. Error df t value Pr(\u0026gt;|t|)    (Intercept) 5.940 0.174 173.360 34.080 0  face_sexmale -0.826 0.203 98.586 -4.069 0    Note that the intercept coefficient is equal to the female mean (5.94) and the effect of face sex is how much less the male mean is (5.114 - 5.94 = -0.826).\n Treatment coding m.tr \u0026lt;- lmerTest::lmer(rating ~ face_sex.tr + (1 | face_id) + (1 + face_sex.tr | rater_id), data = df2)    Estimate Std. Error df t value Pr(\u0026gt;|t|)    (Intercept) 5.114 0.172 169.515 29.720 0  face_sex.tr 0.826 0.203 98.611 4.069 0    Treatment coding is the same as categorical coding, but gives you more control over what the reference category is. Here, the reference category is male and the ‚Äútreatment‚Äù category is female, so the intercept coefficient is equal to the male mean (5.114) and the effect of face sex is how much more the female mean is (5.94 - 5.114 = 0.826).\n Sum coding m.sum \u0026lt;- lmerTest::lmer(rating ~ face_sex.sum + (1 | face_id) + (1 + face_sex.sum | rater_id), data = df2)    Estimate Std. Error df t value Pr(\u0026gt;|t|)    (Intercept) 5.527 0.140 194.675 39.387 0  face_sex.sum -0.413 0.102 98.601 -4.069 0    With sum coding, the intercept coefficient is equal to the overall mean ignoring face sex (i.e., (5.94 + 5.114)/2 = 5.527) and the effect of face sex is how much above and below that each of the two face sexes differ from the mean (i.e., (5.94 - 5.114)/2 = 0.413).\n Effect coding m.e \u0026lt;- lmerTest::lmer(rating ~ face_sex.e + (1 | face_id) + (1 + face_sex.e | rater_id), data = df2)    Estimate Std. Error df t value Pr(\u0026gt;|t|)    (Intercept) 5.527 0.140 194.683 39.387 0  face_sex.e -0.826 0.203 98.604 -4.069 0    With effect coding, the intercept coefficient is the same as sum coding and the effect of face sex is how much the two face sexes differ from each other (i.e., 5.94 - 5.114 = 0.826). Note that this coefficient is double that from the sum coding.\n ","date":1498176000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498176000,"objectID":"b88b848c7b023c68f787c89c70ac4c98","permalink":"https://debruine.github.io/post/coding-schemes/","publishdate":"2017-06-23T00:00:00Z","relpermalink":"/post/coding-schemes/","section":"post","summary":"library(tidyverse) library(lmerTest) How you choose to code categorical variables changes how you can interpret the intercept and effects of those variables. My favourite tutorial on coding schemes explains things in detail.","tags":["r","coding","effect","treatment","lmer","mixed effects","simulation"],"title":"Coding Schemes","type":"post"},{"authors":null,"categories":["rstats"],"content":"  You can use scale() to center and/or scale (i.e., Z-score) a vector of numbers. Z-score a list of numbers\nx \u0026lt;- c(10, 12, 14, 16, 18) scale(x) ## [,1] ## [1,] -1.2649111 ## [2,] -0.6324555 ## [3,] 0.0000000 ## [4,] 0.6324555 ## [5,] 1.2649111 ## attr(,\u0026quot;scaled:center\u0026quot;) ## [1] 14 ## attr(,\u0026quot;scaled:scale\u0026quot;) ## [1] 3.162278 However, the result contains the mean and SD. This can cause problems if you want to assign it to a new column in a data frame, which you can fix using as.vector()\nas.vector(scale(x)) ## [1] -1.2649111 -0.6324555 0.0000000 0.6324555 1.2649111 I find it more straightforward to just use the equation for a Z-score\n( x - mean(x) ) / sd(x) ## [1] -1.2649111 -0.6324555 0.0000000 0.6324555 1.2649111 You can just center the numbers without scaling.\nas.vector(scale(x, center=TRUE, scale=FALSE)) ## [1] -4 -2 0 2 4 ( x - mean(x) ) ## [1] -4 -2 0 2 4 Scaling without centering divides numbers by their root mean square.\nas.vector(scale(x, center=FALSE, scale=TRUE)) ## [1] 0.6262243 0.7514691 0.8767140 1.0019589 1.1272037 x / sqrt(sum(x^2)/(length(x)-1)) ## [1] 0.6262243 0.7514691 0.8767140 1.0019589 1.1272037 Set the scale to a number to divide by that number\nas.vector(scale(x, center=FALSE, scale=3)) ## [1] 3.333333 4.000000 4.666667 5.333333 6.000000 x / 3 ## [1] 3.333333 4.000000 4.666667 5.333333 6.000000 Create new columns in a dataframe with the scaled or centered variable\nsuppressMessages( library(tidyverse) ) df \u0026lt;- data.frame(id = seq(1,5), x = x) df.s \u0026lt;- df %\u0026gt;% mutate( x.s = as.vector(scale(x)), x.c = as.vector(scale(x, scale=F)), x.z = (x - mean(x)) / sd(x) ) df.s ## id x x.s x.c x.z ## 1 1 10 -1.2649111 -4 -1.2649111 ## 2 2 12 -0.6324555 -2 -0.6324555 ## 3 3 14 0.0000000 0 0.0000000 ## 4 4 16 0.6324555 2 0.6324555 ## 5 5 18 1.2649111 4 1.2649111 ","date":1498089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498089600,"objectID":"e000502ce52d0a12dabb6ddd50f926e8","permalink":"https://debruine.github.io/post/scale/","publishdate":"2017-06-22T00:00:00Z","relpermalink":"/post/scale/","section":"post","summary":"You can use scale() to center and/or scale (i.e., Z-score) a vector of numbers. Z-score a list of numbers\nx \u0026lt;- c(10, 12, 14, 16, 18) scale(x) ## [,1] ## [1,] -1.","tags":["R","scale"],"title":"scale()","type":"post"},{"authors":null,"categories":["rstats"],"content":" rep(x, times = 1, length.out = NA, each = 1) is pretty useful for simulating data. Here are some common recipes:\n Repeat a single number (1) a number of times (10)  rep(1, 10) ## [1] 1 1 1 1 1 1 1 1 1 1  Repeat a series of numbers (1:5) a number of times (2)  rep(1:5, 2) ## [1] 1 2 3 4 5 1 2 3 4 5 rep(1:5, times=2) ## [1] 1 2 3 4 5 1 2 3 4 5  If times is not an integer, it is truncated (not rounded).  rep(1:5, times=2.9) ## [1] 1 2 3 4 5 1 2 3 4 5  Repeat a series of numbers (1:5) a number of times each (2)  rep(1:5, each=2) ## [1] 1 1 2 2 3 3 4 4 5 5 rep(1:5, 1, NA, 2) ## [1] 1 1 2 2 3 3 4 4 5 5  Repeat a list of numbers (0, 3, 6) a number of times (2)  rep(c(0, 3, 6), times=2) ## [1] 0 3 6 0 3 6  Repeat a list of strings (‚Äúa‚Äù, ‚Äúb‚Äù, ‚Äúc‚Äù) a number of times (2)  rep(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;), times=2) ## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot;  Repeat a list of strings (‚Äúa‚Äù, ‚Äúb‚Äù, ‚Äúc‚Äù) a number of times each (2)  rep(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;), each=2) ## [1] \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; \u0026quot;c\u0026quot;  Repeat a list of strings (‚Äúa‚Äù, ‚Äúb‚Äù) a number of times each (2) a number of times (3)  rep(c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;), each=2, times=3) ## [1] \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;b\u0026quot; \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;b\u0026quot; \u0026quot;a\u0026quot; \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;b\u0026quot;  Repeat a series of numbers (1:5) until you have a specific total (12)  rep(1:5, length.out=12) ## [1] 1 2 3 4 5 1 2 3 4 5 1 2 rep_len(1:5, 12) ## [1] 1 2 3 4 5 1 2 3 4 5 1 2  length.out overrides times  rep(1:5, length.out=12, times=500) ## [1] 1 2 3 4 5 1 2 3 4 5 1 2  Repeat a sequence of numbers (0:10 by 5s) a number of times (3)  rep(seq(0, 10, by=5), 3) ## [1] 0 5 10 0 5 10 0 5 10 ","date":1498003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498003200,"objectID":"97be367b028602dced6691219d18d17d","permalink":"https://debruine.github.io/post/rep/","publishdate":"2017-06-21T00:00:00Z","relpermalink":"/post/rep/","section":"post","summary":"rep(x, times = 1, length.out = NA, each = 1) is pretty useful for simulating data. Here are some common recipes:\n Repeat a single number (1) a number of times (10)  rep(1, 10) ## [1] 1 1 1 1 1 1 1 1 1 1  Repeat a series of numbers (1:5) a number of times (2)  rep(1:5, 2) ## [1] 1 2 3 4 5 1 2 3 4 5 rep(1:5, times=2) ## [1] 1 2 3 4 5 1 2 3 4 5  If times is not an integer, it is truncated (not rounded).","tags":["R","rep"],"title":"rep()","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://debruine.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"Do you want to take your R coding skills to the next level in a fun atmosphere where we learn by doing? Join the Coding Club!\nWe\u0026rsquo;ll be starting from the very basics to use the shiny R package to create an interactive web app that can read from a Google Form and display tables and plots describing your data.\nWhen: Every other Wednesday 14:00-15:00, starting 6 October 2021.\nFAQ Do I have enough experience? Don\u0026rsquo;t worry if you\u0026rsquo;re new to R coding; as long as you can open RStudio and load the shiny package, you\u0026rsquo;ll be able to participate. All levels are welcome, including undergraduate students and staff.\nWill it be recorded? Yes, if you\u0026rsquo;re staff or a student at the University of Glasgow, join the Methods \u0026amp; Metascience Team with the code j2z7m4w in Teams to access recordings on the Coding Club channel.\nWhat computing resources do I need? You need to have access to R and RStudio. We will use these packages to start: shiny, shinydashboard, tidyverse. See instructions for installing on your own computer or use a university computer or RStudio Cloud.\nI have more questions Join the Methods \u0026amp; MetaScience Team (it\u0026rsquo;s open to all at UofG) with the join code j2z7m4w in Teams and post questions in the Coding Club channel or email Lisa.DeBruine@glasgow.ac.uk\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e1dbbf71e24029fc8d2c2a1b9ab2b64f","permalink":"https://debruine.github.io/project/shiny/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/shiny/","section":"project","summary":"Do you want to take your R coding skills to the next level in a fun atmosphere where we learn by doing? Join the Coding Club!\nWe\u0026rsquo;ll be starting from the very basics to use the shiny R package to create an interactive web app that can read from a Google Form and display tables and plots describing your data.","tags":["R","shiny"],"title":"Coding Club","type":"project"},{"authors":null,"categories":null,"content":"Experimentum is an open-source, online platform for psychology studies.\nLisa DeBruine, Rebecca Lai, Benedict Jones, Rifah Abdullah, Gaby Mahrholz. (2020). Experimentum (Version v.0.2). Zenodo. doi:10.5281/zenodo.2634355\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"df30cd3a299a6dfe2c205d32efb1ca8a","permalink":"https://debruine.github.io/project/experimentum/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/experimentum/","section":"project","summary":"An open-source, online platform for psychology studies.","tags":["open science","psychology","experiment"],"title":"Experimentum","type":"project"},{"authors":null,"categories":null,"content":"It is useful to be able to simulate data with a specified structure. The faux package provides some functions to make this process easier for factorial designs and single- or multilevel data.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c7ec1477ef28a14afe1b04b6e720be08","permalink":"https://debruine.github.io/project/faux/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/faux/","section":"project","summary":"R functions for simulating factorial datasets.","tags":["R","faux","simulation"],"title":"Faux","type":"project"},{"authors":null,"categories":null,"content":"The PSA is a globally distributed network of psychological science laboratories that coordinates data collection for democratically selected studies.\nI was a founding member and was elected to a 3-year term as an Associate Director in 2021. I also was one of the lead researchers on the first project.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0f6a8b423a55553b8b49401f355d7e5f","permalink":"https://debruine.github.io/project/psa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/psa/","section":"project","summary":"A globally distributed network of psychological science laboratories that coordinates data collection for democratically selected studies.","tags":["team science"],"title":"Psychological Science Accelerator","type":"project"},{"authors":null,"categories":null,"content":"The psyTeachR team at the University of Glasgow School of Psychology and Institute of Neuroscience and Psychology has successfully made the transition to teaching reproducible research using R across all undergraduate and postgraduate levels. Our curriculum now emphasizes essential ‚Äòdata science‚Äô graduate skills that have been overlooked in traditional approaches to teaching, including programming skills, data visualisation, data wrangling and reproducible reports. Students learn about probability and inference through data simulation as well as by working with real datasets.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8029a3a143de51d9df356d3d40bd6732","permalink":"https://debruine.github.io/project/psyteachr/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/psyteachr/","section":"project","summary":"A community that aims to rebuild the psychology methods curriculum upon a foundation of openness and reproducibility.","tags":["R","teaching","open research"],"title":"psyTeachR","type":"project"},{"authors":null,"categories":null,"content":"The goal of WebMorph and the associated R package, webmorphR, is to make the construction of image stimuli more reproducible, with a focus on face stimuli.\nWebMorph is currently down while I file data protection paperwork. This development of this package was funded by ERC grant #647910 (KINSHIP).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"cc04b914a94abcade41db9a7c2512676","permalink":"https://debruine.github.io/project/webmorph/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/webmorph/","section":"project","summary":"An open source, online tool for morphing and transforming faces.","tags":["R","faces","reproducibility","KINSHIP"],"title":"WebMorph","type":"project"}]