<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>simulation | Lisa DeBruine</title>
    <link>https://debruine.github.io/tag/simulation/</link>
      <atom:link href="https://debruine.github.io/tag/simulation/index.xml" rel="self" type="application/rss+xml" />
    <description>simulation</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 25 May 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://debruine.github.io/media/icon_hud41de7153c7fa400a999f8d222dc5c78_8091_512x512_fill_lanczos_center_3.png</url>
      <title>simulation</title>
      <link>https://debruine.github.io/tag/simulation/</link>
    </image>
    
    <item>
      <title>Data Simulation Workshops</title>
      <link>https://debruine.github.io/project/datasim/</link>
      <pubDate>Wed, 25 May 2022 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/project/datasim/</guid>
      <description>&lt;h2 id=&#34;data-simulation-for-factorial-designs&#34;&gt;Data simulation for factorial designs&lt;/h2&gt;
&lt;p&gt;This session will cover the basics of simulation using {faux}. We will simulate data with factorial designs by specifying the within and between-subjects factor structure, each cell mean and standard deviation, and correlations between cells where appropriate. This can be used to create simulated data sets to be used in preparing the analysis code for pre-registrations or registered reports. We will also create data sets for simulation-based power analyses. Students will need to have very basic knowledge of R and R Markdown, and have installed {faux}, {afex} and {tidyverse}.&lt;/p&gt;
&lt;h2 id=&#34;data-simulation-for-mixed-designs&#34;&gt;Data simulation for mixed designs&lt;/h2&gt;
&lt;p&gt;This session will cover simulating data for a mixed design, where trials are crossed with subjects. We will learn how to analyse this using {lme4}, with a focus on understanding how the simulation parameters correspond to the output. Finally, we will learn how to use simulation to calculate power. Students will need to have basic knowledge of R and R Markdown, some familiarity with mixed designs (even if they don’t currently analyse them with mixed models) and have installed {faux}, {afex}, {tidyverse}, and {lme4}.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Simulation Workshops</title>
      <link>https://debruine.github.io/talk/data-simulation-workshops/</link>
      <pubDate>Wed, 27 Apr 2022 09:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/talk/data-simulation-workshops/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mixed effects models for designs with randomly sampled stimuli</title>
      <link>https://debruine.github.io/talk/mixed-effects-models-for-designs-with-randomly-sampled-stimuli/</link>
      <pubDate>Tue, 05 Oct 2021 16:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/talk/mixed-effects-models-for-designs-with-randomly-sampled-stimuli/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Faux</title>
      <link>https://debruine.github.io/project/faux/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/project/faux/</guid>
      <description>&lt;p&gt;It is useful to be able to simulate data with a specified structure. The faux package provides some functions to make this process easier for factorial designs and single- or multilevel data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding mixed effects models through data simulation</title>
      <link>https://debruine.github.io/publication/lmem-ampps/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/publication/lmem-ampps/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mann-Whitney False Positives</title>
      <link>https://debruine.github.io/post/mann-whitney/</link>
      <pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/mann-whitney/</guid>
      <description>


&lt;p&gt;One of my favourite colleagues, &lt;a href=&#34;https://twitter.com/McAleerP&#34;&gt;Phil McAleer&lt;/a&gt;, asked about unequal sample sizes for Mann-Whitney tests on our group chat today. I had no idea, so, as always, I thought “This is a job for simulations!”&lt;/p&gt;
&lt;p&gt;I started by loading tidyverse, since I know I’ll need to wrangle data and plot things. I’m starting to get more comfortable with base R for package development, and it can make things faster, but tidyverse is my favourite for a quick analysis or a pipeline where understandability is more important than speed.&lt;/p&gt;
&lt;p&gt;And I set my favourite seed so my simulations will give me a reproducible answer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
set.seed(8675309)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I wrote a wee function to simulate data with the parameters I’m interested in varying, run a Mann-Whitney test, and return the p-value (all I need to look at power and false positives).&lt;/p&gt;
&lt;p&gt;First, I just wanted to look at false positives for different sample size, so I set &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; as arguments and set &lt;code&gt;alternative&lt;/code&gt; with a default of “two.sided”. The function &lt;code&gt;wilcox.test&lt;/code&gt; runs a Mann-Whitney test for independent samples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mw &amp;lt;- function(n1, n2, alternative = &amp;quot;two.sided&amp;quot;) {
  x1 &amp;lt;- rnorm(n1)
  x2 &amp;lt;- rnorm(n2)
  w &amp;lt;- wilcox.test(x1, x2, alternative = alternative)
  w$p.value
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I need to set up a table with all of the values I want to run simulations for. I set &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; to the numbers 10 to 100 in steps of ten. This was crossed with the number of replications I wanted to run (1000). I then removed the values where &lt;code&gt;n2&lt;/code&gt; &amp;gt; &lt;code&gt;n1&lt;/code&gt;, since they’re redundant with the opposite version (e.g., &lt;code&gt;n1 = 10, n2 = 20&lt;/code&gt; is the same as &lt;code&gt;n1 = 20, n2 = 10&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;params &amp;lt;- expand.grid(
  n1 = seq(10, 100, 10), 
  n2 = seq(10, 100, 10),
  reps = 1:1000
) %&amp;gt;%
  filter(n1 &amp;lt;= n2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;n1&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n2&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;reps&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;…&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;…&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;…&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;90&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;100&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I then used the &lt;code&gt;pmap_dbl&lt;/code&gt; function from &lt;code&gt;purrr&lt;/code&gt; to map the values from &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; onto &lt;code&gt;mw&lt;/code&gt;, then grouped the results by &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt; and calculated &lt;code&gt;false_pos&lt;/code&gt; as the proportion of &lt;code&gt;p&lt;/code&gt; less than &lt;code&gt;alpha&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha &amp;lt;- 0.05

mw1 &amp;lt;- params %&amp;gt;%
  mutate(p = pmap_dbl(list(n1, n2), mw)) %&amp;gt;%
  group_by(n1, n2) %&amp;gt;%
  summarise(false_pos = mean(p &amp;lt; alpha), .groups = &amp;quot;drop&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I plotted the false positive rate for each combination against the difference between &lt;code&gt;n1&lt;/code&gt; and &lt;code&gt;n2&lt;/code&gt;. You can see that the false positive rate is approximately nominal, or equal to the specified &lt;code&gt;alpha&lt;/code&gt; of 0.05.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mw1, aes(n2 - n1, false_pos)) +
  geom_point(aes(color = as.factor(n1))) +
  geom_smooth(formula = y ~ x, method = lm, color = &amp;quot;black&amp;quot;) +
  labs(x = &amp;quot;N2 - N1&amp;quot;, 
         y = &amp;quot;False Positive Rate&amp;quot;,
         color = &amp;quot;N1&amp;quot;) +
  ylim(0, .1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/mann-whitney_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But what if data aren’t drawn from a normal distribution? We can change the &lt;code&gt;mw()&lt;/code&gt; function to simulate data from a different distribtion, such as uniform, and run the whole process again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mw &amp;lt;- function(n1, n2, alternative = &amp;quot;two.sided&amp;quot;) {
  x1 &amp;lt;- runif(n1)
  x2 &amp;lt;- runif(n2)
  w &amp;lt;- wilcox.test(x1, x2, alternative = alternative)
  w$p.value
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The rest of our code is identical to above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mw2 &amp;lt;- params %&amp;gt;%
  mutate(p = pmap_dbl(list(n1, n2), mw)) %&amp;gt;%
  group_by(n1, n2) %&amp;gt;%
  summarise(false_pos = mean(p &amp;lt; alpha), .groups = &amp;quot;drop&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This doesn’t seem to make much difference.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/mann-whitney_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if the variance between the two samples is different? First, let’s adjust the &lt;code&gt;mw()&lt;/code&gt; function to vary the SD of the two samples. We’ll give &lt;code&gt;sd1&lt;/code&gt; a default value of 1 and &lt;code&gt;sd2&lt;/code&gt; will default to the same as &lt;code&gt;sd1&lt;/code&gt;. We might as well add the option to change the means, so default &lt;code&gt;m1&lt;/code&gt; to 0 and &lt;code&gt;m2&lt;/code&gt; to the same as &lt;code&gt;m1&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mw &amp;lt;- function(n1, m1 = 0, sd1 = 1, 
               n2 = n1, m2 = m1, sd2 = sd1,
               alternative = &amp;quot;two.sided&amp;quot;) {
  x1 &amp;lt;- rnorm(n1, m1, sd1)
  x2 &amp;lt;- rnorm(n2, m2, sd2)
  w &amp;lt;- wilcox.test(x1, x2, alternative = alternative)
  w$p.value
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we need to set up a new list of parameters to change. The Ns didn’t make much difference last time, so let’s vary them in steps of 20 this time. We’ll vary &lt;code&gt;sd1&lt;/code&gt; and &lt;code&gt;sd2&lt;/code&gt; from 0.5 to 2 in steps of 0.5, and also only keep combinations where &lt;code&gt;sd1&lt;/code&gt; is less than or equal to &lt;code&gt;sd2&lt;/code&gt; to avoid redundancy.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;params &amp;lt;- expand.grid(
  reps = 1:1000,
  n1 = seq(10, 100, 20), 
  n2 = seq(10, 100, 20),
  sd1 = seq(0.5, 2, 0.5),
  sd2 = seq(0.5, 2, 0.5)
) %&amp;gt;%
  filter(n1 &amp;lt;= n2, sd1 &amp;lt;= sd2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mw3 &amp;lt;- params %&amp;gt;%
  mutate(p = pmap_dbl(list(n1, 0, sd1, n2, 0, sd2), mw)) %&amp;gt;%
  group_by(n1, n2, sd1, sd2) %&amp;gt;%
  summarise(false_pos = mean(p &amp;lt; alpha), .groups = &amp;quot;drop&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It looks like differences in SD make a big difference in the false positive rate, and the effect is bigger as Ns and SDs get more unequal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(mw3, aes(sd2 - sd1, false_pos, color = as.factor(n2-n1))) +
  geom_point() +
  geom_smooth(formula = y ~ x, method = lm) +
  labs(x = &amp;quot;SD2 - SD1&amp;quot;, 
         y = &amp;quot;False Positive Rate&amp;quot;,
         color = &amp;quot;N2-N1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/mann-whitney_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’ll leave it to the enterprising reader to simulate power for different effect sizes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How many simulations in my power analysis?</title>
      <link>https://debruine.github.io/post/how-many-sims/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/how-many-sims/</guid>
      <description>


&lt;p&gt;Today I was trying to figure out how to advise on the number of simulations to run when calculating power by simulation.&lt;/p&gt;
&lt;p&gt;I tackled this question by running a simulation (of course).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr) # I love pipes
set.seed(8675309)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wanted to figure out how close to the true power was the calculated power from a simulation where the number of replications ranges from 100 to 10K (in steps of 100) and power ranges from 0.5 to 1 in steps of .05 (the result is symmetric around 50%, so the figures below for 80% power also apply to 20% power)..&lt;/p&gt;
&lt;p&gt;First, I made all possible combinations of replications and power.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- expand.grid(
  reps = seq(100, 1e4, 100),
  power = seq(0.5, 1, .05)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, for each combination, I calculated the proportion of significant analyses in 10K simulations. I assumed this would have a binomial distribution where size is the number of replications in each simulation and probability is the true power. I then calculated the absolute difference from the true value of power and reported the mean (I find it more intuitive than SD or variance).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x$diff &amp;lt;- mapply(function(size, prob) {
  sig &amp;lt;- rbinom(1e4, size, prob) / size
  diff &amp;lt;- abs(sig - prob)
  mean(diff)
}, size = x$reps, prob = x$power)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I plotted the results to see if they make sense. As the number of replications per simulation increases, the mean difference from the true power decreases. Accuracy is higher for larger values of power.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/how-many-sims_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I also calculated the minimum number of replications to get a result that is, on average, less than 1% off from a power of 80%&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(x, power == .8, diff &amp;lt; .01) %&amp;gt;% 
  pull(reps) %&amp;gt;%  min()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I also calculated the .95 quantile to see how many replications you need to run to get within 1% of the true value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x$q95 &amp;lt;- mapply(function(size, prob) {
  sig &amp;lt;- rbinom(1e4, size, prob) / size
  diff &amp;lt;- abs(sig - prob)
  quantile(diff, .95)
}, size = x$reps, prob = x$power)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/how-many-sims_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Turns out you need a lot more.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(x, power == .8, q95 &amp;lt; .01) %&amp;gt;% 
  pull(reps) %&amp;gt;%  min()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6300&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Inputting data table rows as function arguments</title>
      <link>https://debruine.github.io/post/pmap_df/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/pmap_df/</guid>
      <description>


&lt;p&gt;I was working on a simulation project with an undergraduate dissertation student today (I’m so amazed at what our students can do now!) and wanted to show her how to efficiently run simulations for all combinations of a range of parameters. It took 20 minutes of googling map functions in purrr to figure it out. I find I have to do this every time I want to use this pattern, so I decided to write a quick tutorial on it.&lt;/p&gt;
&lt;p&gt;You’ll need functions from the purrr library, as well as some dplyr and tidyr functions, so I just load the whole tidyverse.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fisrt, I need to define the function I want to run for the imulation. I’ll make a relatively simple one, that takes the samples sizes, means and standard deviations for two samples, simulates data, and returns the sample effect size, t-value, p-value, and degrees of freedom from &lt;code&gt;t.test&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_t_sim &amp;lt;- function(n1 = 100, m1 = 0, sd1 = 1,
                     n2 = 100, m2 = 0, sd2 = 1) {
  # simulate data
  grp1 &amp;lt;- rnorm(n1, m1, sd1)
  grp2 &amp;lt;- rnorm(n2, m2, sd2)
  
  # analyse
  tt &amp;lt;- t.test(grp1, grp2)
  
  # calculate cohens d for independent samples
  s_pooled &amp;lt;- sqrt(((n1-1) * sd(grp1)^2 + (n2-1) *
                      sd(grp2)^2)/(n1+n2))
  d &amp;lt;- (tt$estimate[[1]] - tt$estimate[[2]]) / s_pooled
  
  # return named list of values
  list(d = d,
       t  = tt$statistic[[1]],
       df = tt$parameter[[1]],
       p  = tt$p.value)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we can simulate a study with 20 observations in each group and an effect size of 0.5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_t_sim(n1 = 20, m1 = 100, sd1 = 10, 
         n2 = 20, m2 = 105, sd2 = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $d
## [1] -0.7037
## 
## $t
## [1] -2.169
## 
## $df
## [1] 33.89
## 
## $p
## [1] 0.0372&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want to run it 100 times, you can use the &lt;code&gt;map_df()&lt;/code&gt; function to create a data frame of the results for each repeat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- map_df(1:100, ~my_t_sim(n1 = 20, m1 = 100, sd1 = 10, 
                                   n2 = 20, m2 = 105, sd2 = 10))&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;d&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.6277&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.9346&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34.22&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0613&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.2027&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.6247&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;38.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5359&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.1913&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.5898&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35.22&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5591&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.7094&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.1865&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;37.58&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0351&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.4612&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.4215&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;38.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1633&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.9266&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.8560&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;37.52&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0070&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;But this only lets you run one set of arguments for n1, n2, m1, m2, sd1, and sd2. What if you want to run the function 100 times for each of a range of parameters?&lt;/p&gt;
&lt;p&gt;First, set up a data frame that contains every combination of parameters you want to explore using the &lt;code&gt;crossing()&lt;/code&gt; function. The function &lt;code&gt;seq()&lt;/code&gt; makes a vector ranging from the first argument to the second, in steps of the third (e.g., &lt;code&gt;seq(30, 60, 5)&lt;/code&gt; makes the vector &lt;code&gt;c(30, 35, 40, 45, 50, 55, 60)&lt;/code&gt;). If you don’t want to vary a parameter, set it to a single value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;params &amp;lt;- crossing(
  n1 = seq(30, 120, 5),
  m1 = seq(0, 0.5, 0.1),
  sd1 = 1,
  m2 = 0,
  sd2 = 1
) %&amp;gt;%
  mutate(n2 = n1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can now use the function &lt;code&gt;pmap_dfr&lt;/code&gt; to iterate over the rows of the &lt;code&gt;params&lt;/code&gt; data table, using the values as arguments to the function &lt;code&gt;my_t_sim&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- pmap_dfr(params, my_t_sim)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;d&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.2321&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.8836&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;55.35&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3807&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.3326&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.2663&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;53.97&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2108&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.2874&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0944&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;56.30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2784&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.2734&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0410&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3028&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.5160&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.9647&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0542&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.1670&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6361&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.81&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5273&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You can also wrap this in an anonymous function and do some more processing on the results, like running each combination 100 times and adding the parameters to the data table.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- pmap_dfr(params, function(...) {
  args &amp;lt;- list(...) # get list of named arguments
  # run 500 replications per set of parameters
  map_df(1:500, ~my_t_sim(n1 = args$n1, m1 = args$m1, sd1 = args$sd1,
                        n2 = args$n2, m2 = args$m2, sd2 = args$sd2)) %&amp;gt;%
    mutate(!!!args) # add columns to specify arguments
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The three dots in &lt;code&gt;function(...)&lt;/code&gt; lets this function takes any named arguments. You need to assign that list of arguments using &lt;code&gt;args &amp;lt;- list(...)&lt;/code&gt; and then you can use the arguments in your code (e.g., &lt;code&gt;args$n1&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The triple bang (&lt;code&gt;!!!&lt;/code&gt;) expands a list in tidyverse functions. For example, &lt;code&gt;mutate(!!!args)&lt;/code&gt; is equivalent to &lt;code&gt;mutate(n1 = args$n1, m1 = args$m1, sd1 = args$sd1, n2 = args$n2, m2 = args$m2, sd2 = args$sd2)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now you have a data table with 57000 results. You can summarise or graph these results to look at how varying parameters systematically affects things like effect size or power.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results %&amp;gt;%
  group_by(n1, n2, m1, m2) %&amp;gt;%
  summarise(power = mean(p &amp;lt; .05)) %&amp;gt;%
  ggplot(aes(n1, power, color = as.factor(m1))) +
  geom_hline(yintercept = 0.05) +
  geom_hline(yintercept = 0.80) +
  geom_point() +
  geom_line() +
  scale_color_discrete(name = &amp;quot;Effect Size&amp;quot;) +
  xlab(&amp;quot;Number of observations per group&amp;quot;) +
  scale_y_continuous(breaks = seq(0,1,.2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/pmap_dfr_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Composite Images</title>
      <link>https://debruine.github.io/post/composite-images/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/composite-images/</guid>
      <description>
&lt;script src=&#34;https://debruine.github.io/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently responded to a &lt;a href=&#34;https://twitter.com/PsychoSchmitt/status/1221883383778811906?s=20&#34;&gt;tweet&lt;/a&gt; about a preprint about whether people can see Dark Triad traits (narcissism, Machiavellianism, and psychopathy) in facial appearance.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Can you tell a Dark Triad person from the face? Apparently so (data from USA and Turkey). &lt;a href=&#34;https://t.co/BxZUcJ9cTY&#34;&gt;https://t.co/BxZUcJ9cTY&lt;/a&gt; &lt;a href=&#34;https://t.co/xh1pcmyB5E&#34;&gt;pic.twitter.com/xh1pcmyB5E&lt;/a&gt;
&lt;/p&gt;
— David Schmitt (&lt;span class=&#34;citation&#34;&gt;@PsychoSchmitt&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/PsychoSchmitt/status/1221883383778811906?ref_src=twsrc%5Etfw&#34;&gt;January 27, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;The &lt;a href=&#34;https://psyarxiv.com/c3ngz/&#34;&gt;preprint&lt;/a&gt; by Alper, Bayrak, and Yilmaz used faces from the &lt;a href=&#34;http://www.nickholtzman.com/faceaurus.htm&#34;&gt;Faceaurus database&lt;/a&gt; (Holtzman, 2011). “Holtzman (2011) standardized the assessment scores, computed average scores of self- and peer-reports, and ranked the face images based on the resulting scores. Then, prototypes for each of the personality dimensions were created by digitally combining 10 faces with the highest and 10 faces with the lowest scores on the personality trait in question (Holtzman, 2011).” This was done separately for male and female faces.&lt;/p&gt;
&lt;p&gt;Since scores on the three dark triad traits are positively correlated, the three pairs of composite faces are not independent. Indeed, Holtzman states that 5 individuals were in all three low composites for the male faces, while the overlap was less extreme in other cases. With 105 observers, Holtzman found that the ability to detect the composite higher in a dark triad trait was greater than chance.&lt;/p&gt;
&lt;p&gt;While I commend both Holtzman and Alper, Bayrak, and Yilmaz for their transparency, data sharing, and material sharing, &lt;strong&gt;I am arguing that this test has an effective N of 2, and that further replications using these images, such as those done by Alper, Bayrak, and Yilmaz, regardless of number of observers or preregistered status, lend no further weight of evidence to the assertion that dark triad traits are visible in physical appearance.&lt;/strong&gt;&lt;/p&gt;
&lt;div id=&#34;womens-height&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Women’s height&lt;/h3&gt;
&lt;p&gt;Let’s go back to my favourite example for demonstrating the problems with aggregating ratings before analysis, &lt;a href=&#34;https://debruine.github.io/tutorials/aggregate.html&#34;&gt;Armenian women’s height&lt;/a&gt;. The problem is the same here, but we’ve just averaged the stimuli before rating, rather than averaging the ratings of individual stimuli.&lt;/p&gt;
&lt;p&gt;First, we’re going to simulate a sample of 20 women from a population with a mean height of 158.1 cm and an SD of 5.7. Half are born on odd days and half on even days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(8675309)

stim_n &amp;lt;- 10
height_m &amp;lt;- 158.1
height_sd &amp;lt;- 5.7

odd &amp;lt;- rnorm(stim_n, height_m, height_sd)
even &amp;lt;- rnorm(stim_n, height_m, height_sd)

t.test(odd, even)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  odd and even
## t = 1.7942, df = 17.409, p-value = 0.09016
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.7673069  9.5977215
## sample estimates:
## mean of x mean of y 
##  161.1587  156.7435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A t-test shows no significant difference, which is unsurprising. We simulated the data from the same distributions, so we know for sure there is no real difference here. Now we’re going to average the height of the women with odd and even birthdays.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;odd_mean &amp;lt;- mean(odd)
even_mean &amp;lt;- mean(even)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So if we create a composite of women born on odd days, she would be 161.2 cm tall, and a composite of women born on even days would be 156.7 cm tall.&lt;/p&gt;
&lt;p&gt;If we ask 100 observers to look at these two composites and judge which one looks taller, what do you imagine would happen? Let’s say that observers are pretty bad with height estimation, and their estimates for each composite have error with a standard deviation of 10 cm. They then judge whether, by their estimation, the odd-birthday composite looks taller than the even-birthday composite.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs_n &amp;lt;-100
error_sd &amp;lt;- 10

odd_estimate &amp;lt;- odd_mean + rnorm(obs_n, 0, error_sd)
even_estimate &amp;lt;- even_mean + rnorm(obs_n, 0, error_sd)

judgment &amp;lt;- odd_estimate &amp;gt; even_estimate

bt &amp;lt;- binom.test(sum(judgment), obs_n, p = 0.5) %&amp;gt;% print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Exact binomial test
## 
## data:  sum(judgment) and obs_n
## number of successes = 65, number of trials = 100, p-value = 0.003518
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.5481506 0.7427062
## sample estimates:
## probability of success 
##                   0.65&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A binomial test shows that they are significantly better than chance at this (p = 0.004). What’s going on?&lt;/p&gt;
&lt;p&gt;We can be sure that by chance alone, our two composites will be at least slightly different on any measure, even if they are drawn from identical populations. The mean (unsigned) size of this difference is larger, the smaller the number of stimuli that go into each composite. The graph below shows simulations of the unsigned difference between composites for 1000 samples per number of stimuli per composite.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/post/composite_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- replicate(10000, mean(rnorm(10))-mean(rnorm(10)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With only 10 stimuli per composite, the mean unsigned effect size of the difference between composites is 0.36 (in units of SD of the original trait distribution). 65% of random pairs have a difference of greater than 0.2 SD. If our observers are accurate enough at perceiving this difference or we run a very large number of observers, we are virtually guarateed to find significant results every time, and we have a 50% chance that all of these results will be in the predicted direction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;personality-traits-and-faces&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Personality Traits and Faces&lt;/h3&gt;
&lt;p&gt;So what does this mean for studies of the link between personality traits and facial appearance? The analogy with birth date and height holds. As long as there are facial morphologies that are even slightly consistently associated with the perception of a trait, then composites will not be identical in that morphology, even if it is totally unassociated with the trait as measured by, e.g., personality scales or peer report.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The smaller the number of stimuli that go into each composite, the greater the chance that they will be visibly different in morphology related to the judgment of interest, just by chance alone.&lt;/li&gt;
&lt;li&gt;The larger the number of observers or the better observers are at detecting small differences in this morphology, the more likley that “detection” will be significantly above chance.&lt;/li&gt;
&lt;li&gt;Repeating this with a new set of observers does not increase the amount of evidence you have for the association between the face morphology and the measured trait. You’ve only measured it once in one population of faces.&lt;/li&gt;
&lt;li&gt;If observers are your unit of analyses, you are making conclusions about whether the population of observers can detect the difference between your stimuli, you cannot generalise this to new stimulus sets.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;Alper, S., Bayrak, F., &amp;amp; Yilmaz, O. (2020, January 27). All the Dark Triad and Some of the Big Five Traits are Visible in the Face. &lt;a href=&#34;https://doi.org/10.31234/osf.io/c3ngz&#34; class=&#34;uri&#34;&gt;https://doi.org/10.31234/osf.io/c3ngz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Holtzman, N. S. (2011). Facing a psychopath: Detecting the dark triad from emotionally-neutral faces, using prototypes from the Personality Faceaurus. Journal of Research in Personality, 45, 648-654. &lt;a href=&#34;https://doi.org/10.1016/j.jrp.2011.09.002&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.jrp.2011.09.002&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s wrong with aggregating data?</title>
      <link>https://debruine.github.io/post/aggregating/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/aggregating/</guid>
      <description>
&lt;script src=&#34;https://debruine.github.io/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p class=&#34;info&#34;&gt;
&lt;a href=&#34;http://shiny.psy.gla.ac.uk/debruine/anova_vs_lmer/&#34;&gt;Shiny app&lt;/a&gt; for a face-rating example.
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lmerTest)
set.seed(90210)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imagine you want to find out if Armenian women born on an even-numbered day are taller than women born on an odd-numbered day. (I’ve chosen Armenian women because they’re the first row in &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0018962&#34;&gt;this paper&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;First, let’s simulate a group of 20 women born on even-numbered days and 20 women born on odd-numbered days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stim_n &amp;lt;- 20
# height stats from https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018962
height_m &amp;lt;- 158.1
height_sd &amp;lt;- 5.7

stim &amp;lt;- tibble(
  stim_id = 1:(stim_n*2),
  birthday = rep(c(&amp;quot;odd&amp;quot;, &amp;quot;even&amp;quot;), stim_n),
  height = rnorm(stim_n*2, height_m, height_sd)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/post/aggregation_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Obviously, the oddness of date of birth is not going to have any effect on women’s actual height and a two-sample t-test confirms this. However, there is a small difference between the means of the groups just due to chance (2.81 cm).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(stim$height ~ stim$birthday)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  stim$height by stim$birthday
## t = -1.5, df = 38, p-value = 0.1
## alternative hypothesis: true difference in means between group even and group odd is not equal to 0
## 95 percent confidence interval:
##  -6.4997  0.8767
## sample estimates:
## mean in group even  mean in group odd 
##              154.9              157.7&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;measurement-with-error&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Measurement with Error&lt;/h3&gt;
&lt;p&gt;But what if we don’t measure height from each women once, but have a few different raters estimate it? The raters will each have their own bias, systematically overestimating or underestimating height on average. Let’s simulate 20 raters who have biases with an SD of 2 cm.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rater_n &amp;lt;- 20
rater_bias_sd &amp;lt;- 2

rater &amp;lt;- tibble(
  rater_id = 1:rater_n,
  rater_bias = rnorm(rater_n, 0, rater_bias_sd)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/post/aggregation_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;New we can get each rater to estimate the height of each woman. Their estimate is the woman’s actual height, plus the rater’s bias, plus some error (sampled from a normal distribution with a mean of 0 and an SD of 4 cm, since estimating height is hard).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- expand.grid(
  rater_id = rater$rater_id,
  stim_id = stim$stim_id
) %&amp;gt;%
  left_join(rater, by = &amp;quot;rater_id&amp;quot;) %&amp;gt;%
  left_join(stim, by = &amp;quot;stim_id&amp;quot;) %&amp;gt;%
  mutate(
    error = rnorm(nrow(.), 0, 4),
    estimate = height + rater_bias + error
  )&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregating-by-stimuli&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aggregating by Stimuli&lt;/h3&gt;
&lt;p&gt;You can aggregate by stimuli, that is, average the 20 raters’ estimate for each stimulus. You now have 40 mean estimates that are fairly well-correlated with the women’s actual heights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_agg_by_stim &amp;lt;- dat %&amp;gt;%
  group_by(stim_id, birthday, height) %&amp;gt;%
  summarise(mean_estimate = mean(estimate))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;stim_id&amp;#39;, &amp;#39;birthday&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/post/aggregation_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You get pretty much the same result when you compare these mean estimates between the groups of women with odd and even birthdays.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(dat_agg_by_stim$mean_estimate ~ dat_agg_by_stim$birthday)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dat_agg_by_stim$mean_estimate by dat_agg_by_stim$birthday
## t = -1.4, df = 38, p-value = 0.2
## alternative hypothesis: true difference in means between group even and group odd is not equal to 0
## 95 percent confidence interval:
##  -6.473  1.130
## sample estimates:
## mean in group even  mean in group odd 
##              155.2              157.9&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregating-by-raters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aggregating by Raters&lt;/h3&gt;
&lt;p&gt;Alternatively, you can aggregate by raters, that is, average the 20 odd-group estimates and 20 even-group estimates for each rater. Now raters are your unit of analysis, so you’ve increased your power by having 20 raters and a within-subject design (each rater estimates heights for both odd- and even-birthday groups).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_agg_by_rater &amp;lt;- dat %&amp;gt;%
  group_by(rater_id, birthday) %&amp;gt;%
  summarise(mean_estimate = mean(estimate)) %&amp;gt;%
  spread(birthday, mean_estimate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;rater_id&amp;#39;. You can override using the `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(dat_agg_by_rater$odd, dat_agg_by_rater$even, paired = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Paired t-test
## 
## data:  dat_agg_by_rater$odd and dat_agg_by_rater$even
## t = 11, df = 19, p-value = 0.000000002
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  2.145 3.198
## sample estimates:
## mean of the differences 
##                   2.672&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the difference between the odd- and even-birthday groups is highly significant! What’s going is that you now have a relatively accurate estimate of the chance mean difference between the 20 women in the odd-birthday group and the 20 women in the even-birthday group. Since raters are the unit of analysis, this effect is likely to generalise to the larger population of potential raters, but only when they are rating &lt;strong&gt;these exact stimuli&lt;/strong&gt;. Your conclusions cannot generalise beyond the stimulus set used here.&lt;/p&gt;
&lt;p&gt;While this seems like an obvious problem when the question is whether Armenian women with odd birthdays are taller or shorter than Armenian women with even birthdays, the problem is not so obvious for other questions, like whether boxers who won their last match have more masculine faces than boxers who lost their last match. The point of this tutorial isn’t to call out any particular studies (I’ve certainly done this wrong myself plenty of times in the past), but to illustrate the enormous problem with this method and to explain the solution.&lt;/p&gt;
&lt;p&gt;The larger the number of raters, the larger this false positive problem becomes because you’re increasing power to detect the small chance diffference between the two groups. You can play around with how changing parameters changes the power and false positive rates for by-stimulus, by-rater, and mixed effect designs at &lt;a href=&#34;http://shiny.psy.gla.ac.uk/debruine/anova_vs_lmer/&#34;&gt;this shiny app&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mixed-effect-model&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mixed Effect Model&lt;/h3&gt;
&lt;p&gt;In the particular case above, we’re only interested in the between-stimulus (and within-rater) main effect of birthday oddness. Therefore, aggregating by stimuli doesn’t inflate your false positive rate, while aggregating by rater does. However, other designs might have increased false positives for aggregating by stimuli but not by rater, or when aggregating by either.&lt;/p&gt;
&lt;p&gt;A mixed effects model avoids the problems of aggregation completely by modelling random variation for both the stimuli and raters, as well as random variation in the size of within-group effects.&lt;/p&gt;
&lt;p class=&#34;info&#34;&gt;
I &lt;a href=&#34;https://debruine.github.io/posts/coding-schemes/&#34;&gt;effect code&lt;/a&gt; the &lt;code&gt;birthday&lt;/code&gt; variable to make interpretation of the effects easier).
&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# effect-code birthday
dat$birthday.e &amp;lt;- recode(dat$birthday, &amp;quot;odd&amp;quot; = 0.5, &amp;quot;even&amp;quot; = -0.5)

mod &amp;lt;- lmer(estimate ~ birthday.e +
              # random slope for effect of birthday, random intercept for rater bias
              (1 + birthday.e || rater_id) + 
              # random intercept for variation in stim height
              (1 | stim_id), 
            data = dat)

summary(mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Linear mixed model fit by REML. t-tests use Satterthwaite&amp;#39;s method [
## lmerModLmerTest]
## Formula: estimate ~ birthday.e + (1 + birthday.e || rater_id) + (1 | stim_id)
##    Data: dat
## 
## REML criterion at convergence: 4687
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.8414 -0.6590  0.0102  0.6776  2.6231 
## 
## Random effects:
##  Groups     Name        Variance      Std.Dev.
##  stim_id    (Intercept) 34.4640965341 5.870613
##  rater_id   birthday.e   0.0000000214 0.000146
##  rater_id.1 (Intercept) 10.0890113704 3.176320
##  Residual               15.8201186615 3.977451
## Number of obs: 800, groups:  stim_id, 40; rater_id, 20
## 
## Fixed effects:
##             Estimate Std. Error     df t value Pr(&amp;gt;|t|)    
## (Intercept)   156.55       1.18  55.02  132.98   &amp;lt;2e-16 ***
## birthday.e      2.67       1.88  38.00    1.42     0.16    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Correlation of Fixed Effects:
##            (Intr)
## birthday.e 0.000 
## optimizer (nloptwrap) convergence code: 0 (OK)
## boundary (singular) fit: see ?isSingular&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The estimate for &lt;code&gt;(Intercept)&lt;/code&gt; is just the mean height estimate (156.55 cm) and the estimate for &lt;code&gt;birthday.e&lt;/code&gt; is the mean difference between the odd and even birthday groups (2.67 cm). You can now generalise the conclusions of this mixed effects model to both the population of raters and the population of stimuli.&lt;/p&gt;
&lt;p class=&#34;info&#34;&gt;
Thanks to &lt;a href=&#34;https://twitter.com/lpsatchell&#34;&gt;Liam Satchell&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/AlexJonesPhD&#34;&gt;Alex Jones&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/Ben_C_J&#34;&gt;Ben Jones&lt;/a&gt; for the stimulating late-night Twitter discussion that prompted this blog post!
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;Plenty of papers have made this point much more thoroughly &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-Wolsiefer2017&#34; role=&#34;doc-biblioref&#34;&gt;Wolsiefer, Westfall, and Judd&lt;/a&gt; (&lt;a href=&#34;#ref-Wolsiefer2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-KeepItMaximal&#34; class=&#34;csl-entry&#34;&gt;
Barr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. &lt;span&gt;“Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.”&lt;/span&gt; &lt;em&gt;Journal of Memory and Language&lt;/em&gt; 68 (3): 10.1016/j.jml.2012.11.001.
&lt;/div&gt;
&lt;div id=&#34;ref-Coleman1964&#34; class=&#34;csl-entry&#34;&gt;
Coleman, E. B. 1964. &lt;span&gt;“Generalizing to a Language Population.”&lt;/span&gt; &lt;em&gt;Psychological Reports&lt;/em&gt; 14 (1): 219–26. &lt;a href=&#34;https://doi.org/10.2466/pr0.1964.14.1.219&#34;&gt;https://doi.org/10.2466/pr0.1964.14.1.219&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-Judd2012&#34; class=&#34;csl-entry&#34;&gt;
Judd, Charles M., Jacob Westfall, and David A. Kenny. 2012. &lt;span&gt;“Treating Stimuli as a Random Factor in Social Psychology: A New and Comprehensive Solution to a Pervasive but Largely Ignored Problem.”&lt;/span&gt; &lt;em&gt;Journal of Personality and Social Psychology&lt;/em&gt; 103 (1): 54–69. &lt;a href=&#34;https://doi.org/doi:10.1037/a0028347&#34;&gt;https://doi.org/doi:10.1037/a0028347&lt;/a&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-Wolsiefer2017&#34; class=&#34;csl-entry&#34;&gt;
Wolsiefer, Katie, Jacob Westfall, and Charles M. Judd. 2017. &lt;span&gt;“Modeling Stimulus Variation in Three Common Implicit Attitude Tasks.”&lt;/span&gt; &lt;em&gt;Behavior Research Methods&lt;/em&gt; 49 (4): 1193–1209. &lt;a href=&#34;https://doi.org/10.3758/s13428-016-0779-0&#34;&gt;https://doi.org/10.3758/s13428-016-0779-0&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Random Slopes</title>
      <link>https://debruine.github.io/post/simulating-random-slopes/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/simulating-random-slopes/</guid>
      <description>


&lt;p&gt;This tutorial has been moved to the &lt;a href=&#34;https://debruine.github.io/tutorials/&#34;&gt;tutorials&lt;/a&gt; section.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simulate from Existing Data</title>
      <link>https://debruine.github.io/post/simdf/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/simdf/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(faux)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I added a new function to the package &lt;a href=&#34;https://github.com/debruine/faux&#34;&gt;&lt;code&gt;faux&lt;/code&gt;&lt;/a&gt; to generate a new dataframe from an existing dataframe, simulating all numeric columns from normal distributions with the same mean and SD as the existing data and the same correlation structure as the existing data. (Update: faux is now on CRAN!)&lt;/p&gt;
&lt;p&gt;For example, here is the relationship between speed and distance in the built-in dataset &lt;code&gt;cars&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cars %&amp;gt;%
  ggplot(aes(speed, dist)) + 
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-cars-orig&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://debruine.github.io/posts/simdf_files/figure-html/plot-cars-orig-1.png&#34; alt=&#34;Original cars dataset&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Original cars dataset
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can create a new sample with the same parameters and 500 rows with the code &lt;code&gt;sim_df(cars, 500)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_df(cars, 500) %&amp;gt;%
  ggplot(aes(speed, dist)) + 
    geom_point() +
    geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-cars-sim&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://debruine.github.io/posts/simdf_files/figure-html/plot-cars-sim-1.png&#34; alt=&#34;Simulated cars dataset&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Simulated cars dataset
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can also optionally add grouping variables. For example, here is the relationship between sepal length and width in the built-in dataset &lt;code&gt;iris&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;iris %&amp;gt;%
  ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-iris-orig&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://debruine.github.io/posts/simdf_files/figure-html/plot-iris-orig-1.png&#34; alt=&#34;Original iris dataset&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Original iris dataset
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;And here is a new sample with 50 observations of each species, made with the code &lt;code&gt;sim_df(iris, 100, &#34;Species&#34;)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_df(iris, 50, between = &amp;quot;Species&amp;quot;) %&amp;gt;%
  ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-iris-sim&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://debruine.github.io/posts/simdf_files/figure-html/plot-iris-sim-1.png&#34; alt=&#34;Simulated iris dataset&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Simulated iris dataset
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For now, the function only creates new variables sampled from a continuous normal distribution. I hope to add in other sampling distributions in the future. So you’d need to do any rounding or truncating yourself.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_df(iris, 50, between = &amp;quot;Species&amp;quot;) %&amp;gt;%
  mutate_if(is.numeric, round, 1) %&amp;gt;%
  ggplot(aes(Sepal.Width, Sepal.Length, color = Species)) +
  geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:plot-iris-sim-round&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://debruine.github.io/posts/simdf_files/figure-html/plot-iris-sim-round-1.png&#34; alt=&#34;Simulated iris dataset (rounded)&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Simulated iris dataset (rounded)
&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Mixed Effects</title>
      <link>https://debruine.github.io/post/simulating-mixed-effects/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/simulating-mixed-effects/</guid>
      <description>


&lt;p&gt;This tutorial has been moved to the &lt;a href=&#34;https://debruine.github.io/tutorials/&#34;&gt;tutorials&lt;/a&gt; section.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simulating Multiple Vectors</title>
      <link>https://debruine.github.io/post/rnorm_multi/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/rnorm_multi/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(faux)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m working on a package for simulations called &lt;a href=&#34;https://github.com/debruine/faux&#34;&gt;faux&lt;/a&gt;. (Update: faux is now on CRAN!)&lt;/p&gt;
&lt;p&gt;The first function, &lt;code&gt;rnorm_multi&lt;/code&gt;, makes multiple normally distributed vectors with specified relationships and takes the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt; = the number of samples required (required)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vars&lt;/code&gt; = the number of variables to return (default = &lt;code&gt;3&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cors&lt;/code&gt; = the correlations among the variables (can be a single number, vars*vars matrix, vars*vars vector, or a vars*(vars-1)/2 vector; default = &lt;code&gt;0&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mu&lt;/code&gt; = a vector giving the means of the variables (numeric vector of length 1 or vars; default = &lt;code&gt;0&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sd&lt;/code&gt; = the standard deviations of the variables (numeric vector of length 1 or vars; default = &lt;code&gt;1&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;varnames&lt;/code&gt; = optional names for the variables (string vector of length vars; default = &lt;code&gt;NULL&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;empirical&lt;/code&gt; = logical. If true, mu, sd and cors specify the empirical not population mean, sd and covariance (default = &lt;code&gt;FALSE&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1&lt;/h2&gt;
&lt;p&gt;The following example creates a 100-row dataframe of 3 columns names &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, and &lt;code&gt;C&lt;/code&gt;, with means = 0, SDs = 1, and where r&lt;sub&gt;AB&lt;/sub&gt; = 0.2, r&lt;sub&gt;AC&lt;/sub&gt; = -0.5, and r&lt;sub&gt;BC&lt;/sub&gt; = 0.5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ex1 &amp;lt;- rnorm_multi(100, 3, c(0.2, -0.5, 0.5), varnames=c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;correlation-matrix-of-sample-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlation Matrix of Sample Data&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;A&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;B&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;C&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.087499&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1202283&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0874990&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0157210&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1202283&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.015721&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2&lt;/h2&gt;
&lt;p&gt;The following example calculates the correlation matrix, means, and SDs from the &lt;code&gt;iris&lt;/code&gt; dataset and uses them to simulate a dataset of 100 rows with the same parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- select_if(iris, is.numeric)

iris_sim &amp;lt;- rnorm_multi(
  n = 100, 
  vars = ncol(dat), 
  r = cor(dat),
  mu = summarise_all(dat, mean) %&amp;gt;% t(), 
  sd = summarise_all(dat, sd) %&amp;gt;% t(), 
  varnames = names(dat)
)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;correlation-matrix-of-original-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlation Matrix of Original Data&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sepal.Length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sepal.Width&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Petal.Length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Petal.Width&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sepal.Length&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1175698&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8717538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8179411&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sepal.Width&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1175698&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4284401&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3661259&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Petal.Length&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8717538&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4284401&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9628654&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Petal.Width&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8179411&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3661259&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9628654&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-matrix-of-sample-data-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlation Matrix of Sample Data&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sepal.Length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sepal.Width&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Petal.Length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Petal.Width&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sepal.Length&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1591051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8491459&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7544625&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sepal.Width&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1591051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4527400&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3513351&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Petal.Length&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.8491459&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.4527400&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9485627&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Petal.Width&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7544625&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.3513351&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9485627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>sample()</title>
      <link>https://debruine.github.io/post/sample/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/sample/</guid>
      <description>


&lt;p&gt;First, let’s make a data frame with two variables, &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; that are both sampled from a normal distribution with a mean of 0 and SD of 1. The variablle &lt;code&gt;n&lt;/code&gt; will be how many samples we’ll take (100). Then we can run a t-test to see if they are different.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
## ✓ tidyr   1.1.1     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ───────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = 100

data &amp;lt;- data.frame(
  a = rnorm(n, 0, 1),
  b = rnorm(n, 0, 1)
)

t &amp;lt;- t.test(data$a,data$b)

t$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1527518&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s repeat that procedure 1000 times. The easiest way to do that is to make a function that returns the information you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tPower &amp;lt;- function() {
  n = 100

  data &amp;lt;- data.frame(
    a = rnorm(n, 0, 1),
    b = rnorm(n, 0, 1)
  )

  t &amp;lt;- t.test(data$a,data$b)
  
  return(t$p.value)
}

tPower()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7583175&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mySample &amp;lt;- data.frame(
  p = replicate(10000, tPower())
) 

mySample %&amp;gt;%
  ggplot(aes(p)) +
  geom_histogram(bins = 20, boundary = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/power_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(mySample$p &amp;lt; .05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0528&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What if you induced a small effect of 0.2 SD?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tPower2 &amp;lt;- function() {
  n = 100

  data &amp;lt;- data.frame(
    a = rnorm(n, 0, 1),
    b = rnorm(n, 0.2, 1)
  )

  t &amp;lt;- t.test(data$a,data$b)
  
  return(t$p.value)
}

tPower2()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9142489&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mySample2 &amp;lt;- data.frame(
  p = replicate(10000, tPower2())
) 

mySample2 %&amp;gt;%
  ggplot(aes(p)) +
  geom_histogram(bins = 20, boundary = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/power_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(mySample2$p &amp;lt; .05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2929&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hmm, you only get a p-value less than .05 30% of the time. That means that your study would only have 30% power to detect an effect this big with 100 subjects. Let’s make a new function to give you the p-value of a study with any number of subjects (you put the N inside the parentheses of the function).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tPowerN &amp;lt;- function(n) {

  data &amp;lt;- data.frame(
    a = rnorm(n, 0, 1),
    b = rnorm(n, 0.2, 1)
  )

  t &amp;lt;- t.test(data$a,data$b)
  
  return(t$p.value)
}

tPowerN(200)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2969539&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mySampleN &amp;lt;- data.frame(
  p200 = replicate(10000, tPowerN(200))
) 

mySampleN %&amp;gt;%
  ggplot(aes(p200)) +
  geom_histogram(bins = 20, boundary = 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/power_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(mySampleN$p200 &amp;lt; .05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5137&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlist &amp;lt;- seq(200, 1000, by = 100)

remove(mySampleN)
for (n in nlist) {
  temp &amp;lt;- data.frame(
    n = n,
    p = replicate(1000, tPowerN(n))
  ) 
  
  if (exists(&amp;quot;mySampleN&amp;quot;)) {
    mySampleN &amp;lt;- rbind(mySampleN, temp)
  } else {
    mySampleN &amp;lt;- temp
  }
  remove(temp)
  print(n)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 200
## [1] 300
## [1] 400
## [1] 500
## [1] 600
## [1] 700
## [1] 800
## [1] 900
## [1] 1000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mySampleN %&amp;gt;%
  ggplot(aes(p)) +
  geom_histogram(bins = 20, boundary = 0) +
  facet_wrap(~n, nrow = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/posts/power_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coding Schemes</title>
      <link>https://debruine.github.io/post/coding-schemes/</link>
      <pubDate>Fri, 23 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://debruine.github.io/post/coding-schemes/</guid>
      <description>
&lt;script src=&#34;https://debruine.github.io/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lmerTest)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How you choose to code categorical variables changes how you can interpret the intercept and effects of those variables. My favourite &lt;a href=&#34;http://talklab.psy.gla.ac.uk/tvw/catpred/&#34;&gt;tutorial on coding schemes&lt;/a&gt; explains things in detail. I’m just adding some concrete examples below.&lt;/p&gt;
&lt;p&gt;First, I simulated a data frame of 100 raters rating 100 faces each. Female faces get ratings with a mean of 6; male faces get ratings with a mean of 5 (I know, ratings are usually ordinal integers, but let’s pretend we used something like a slider). To simulate random effects, both raters and faces have random intercepts with SDs of 1.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(555)  # for reproducibility; delete when running simulations

n_raters &amp;lt;- 100
n_faces &amp;lt;- 100

female_mean &amp;lt;- 6
male_mean &amp;lt;- 5

raters &amp;lt;- tibble(
  rater_id = 1:n_raters,
  rater_i = rnorm(n_raters)
)

faces &amp;lt;- tibble(
  face_id = 1:n_faces,
  face_i = rnorm(n_faces),
  face_sex = rep(c(&amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;), each = n_faces/2)
)

df &amp;lt;- expand.grid(
  face_id = faces$face_id,
  rater_id = raters$rater_id
) %&amp;gt;%
  left_join(faces, by = &amp;quot;face_id&amp;quot;) %&amp;gt;%
  left_join(raters, by = &amp;quot;rater_id&amp;quot;) %&amp;gt;%
  mutate(
    face_sex_i = ifelse(face_sex==&amp;quot;male&amp;quot;, male_mean, female_mean),
    error = rnorm(nrow(.)),
    rating = face_i + rater_i + face_sex_i + error
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculate the means and SDs of the female and male faces.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;face_sex&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;mean&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;SD&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.940&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.767&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.114&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.649&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Always graph your data to confirm you simulated it correctly.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df %&amp;gt;% 
  ggplot(aes(face_sex, rating)) + 
  geom_violin() +
  geom_boxplot(width=0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://debruine.github.io/post/coding_files/figure-html/coding-orig-data-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Recode face sex using treatment, sum, or effect coding.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df2 &amp;lt;- df %&amp;gt;%
  mutate(
    face_sex.tr = recode(face_sex, &amp;quot;female&amp;quot; = 1, &amp;quot;male&amp;quot; = 0),
    face_sex.sum = recode(face_sex, &amp;quot;female&amp;quot; = -1, &amp;quot;male&amp;quot; = 1),
    face_sex.e = recode(face_sex, &amp;quot;female&amp;quot; = -0.5, &amp;quot;male&amp;quot; = 0.5)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we analyse the data using each of the 4 styles of coding. I’m just going to show the table of fixed effects.&lt;/p&gt;
&lt;div id=&#34;categorical-coding&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Categorical coding&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m1 &amp;lt;- lmerTest::lmer(rating ~ face_sex + 
                       (1 | face_id) + 
                       (1 + face_sex | rater_id), 
                     data = df2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Std. Error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pr(&amp;gt;|t|)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.940&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.174&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;173.360&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;34.080&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;face_sexmale&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.826&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.203&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98.586&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that the intercept coefficient is equal to the female mean (5.94) and the effect of face sex is how much less the male mean is (5.114 - 5.94 = -0.826).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;treatment-coding&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Treatment coding&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m.tr &amp;lt;- lmerTest::lmer(rating ~ face_sex.tr + 
               (1 | face_id) + 
               (1 + face_sex.tr | rater_id), 
             data = df2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Std. Error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pr(&amp;gt;|t|)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.114&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.172&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;169.515&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;29.720&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;face_sex.tr&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.826&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.203&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98.611&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Treatment coding is the same as categorical coding, but gives you more control over what the reference category is. Here, the reference category is &lt;code&gt;male&lt;/code&gt; and the “treatment” category is &lt;code&gt;female&lt;/code&gt;, so the intercept coefficient is equal to the male mean (5.114) and the effect of face sex is how much more the female mean is (5.94 - 5.114 = 0.826).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sum-coding&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sum coding&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m.sum &amp;lt;- lmerTest::lmer(rating ~ face_sex.sum + 
                (1 | face_id) + 
                (1 + face_sex.sum | rater_id), 
              data = df2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Std. Error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pr(&amp;gt;|t|)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.527&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.140&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;194.675&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;39.387&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;face_sex.sum&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.413&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.102&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98.601&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With sum coding, the intercept coefficient is equal to the overall mean ignoring face sex (i.e., (5.94 + 5.114)/2 = 5.527) and the effect of face sex is how much above and below that each of the two face sexes differ from the mean (i.e., (5.94 - 5.114)/2 = 0.413).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;effect-coding&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Effect coding&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m.e &amp;lt;- lmerTest::lmer(rating ~ face_sex.e + 
              (1 | face_id) + 
              (1 + face_sex.e | rater_id), 
            data = df2)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Std. Error&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;df&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;t value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Pr(&amp;gt;|t|)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.527&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.140&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;194.683&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;39.387&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;face_sex.e&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.826&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.203&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;98.604&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With effect coding, the intercept coefficient is the same as sum coding and the effect of face sex is how much the two face sexes differ from each other (i.e., 5.94 - 5.114 = 0.826). Note that this coefficient is double that from the sum coding.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
