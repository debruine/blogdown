@Article{Wolsiefer2017,
  author="Wolsiefer, Katie
  and Westfall, Jacob
  and Judd, Charles M.",
  title="Modeling stimulus variation in three common implicit attitude tasks",
  journal="Behavior Research Methods",
  year="2017",
  month="Aug",
  day="01",
  volume="49",
  number="4",
  pages="1193--1209",
  abstract="We explored the consequences of ignoring the sampling variation due to stimuli in the domain of implicit attitudes. A large literature in psycholinguistics has examined the statistical treatment of random stimulus materials, but the recommendations from this literature have not been applied to the social psychological literature on implicit attitudes. This is partly because of inherent complications in applying crossed random-effect models to some of the most common implicit attitude tasks, and partly because no work to date has demonstrated that random stimulus variation is in fact consequential in implicit attitude measurement. We addressed this problem by laying out statistically appropriate and practically feasible crossed random-effect models for three of the most commonly used implicit attitude measures---the Implicit Association Test, affect misattribution procedure, and evaluative priming task---and then applying these models to large datasets (average N = 3,206) that assess participants' implicit attitudes toward race, politics, and self-esteem. We showed that the test statistics from the traditional analyses are substantially (about 60 {\%}) inflated relative to the more-appropriate analyses that incorporate stimulus variation. Because all three tasks used the same stimulus words and faces, we could also meaningfully compare the relative contributions of stimulus variation across the tasks. In an appendix, we give syntax in R, SAS, and SPSS for fitting the recommended crossed random-effects models to data from all three tasks, as well as instructions on how to structure the data file.",
  issn="1554-3528",
  doi="10.3758/s13428-016-0779-0",
  url="https://doi.org/10.3758/s13428-016-0779-0"
}

@article{Coleman1964,
  author = {E. B. Coleman},
  title ={Generalizing to a Language Population},
  journal = {Psychological Reports},
  volume = {14},
  number = {1},
  pages = {219-226},
  year = {1964},
  doi = {10.2466/pr0.1964.14.1.219},
  URL = {https://doi.org/10.2466/pr0.1964.14.1.219},
  eprint = {https://doi.org/10.2466/pr0.1964.14.1.219},
  abstract = { Many studies of verbal behavior have little scientific point if their conclusions have to be restricted to the specific language materials that were used in the experiment. It has not been customary, however, to perform significance tests that permit generalization beyond these specific materials, and thus there is little statistical evidence that such studies could be successfully replicated if a different sample of language materials were used. Three tests are described that will allow generalization to a population of language materials. }
}

@article{Judd2012,
  title = { Treating stimuli as a random factor in social psychology: A new and comprehensive solution to a pervasive but largely ignored problem. },
  journal = { Journal of Personality and Social Psychology },
  author = { Charles M. Judd and Jacob Westfall and David A. Kenny },
  volume = {103},
  number = {1},
  pages = {54-69},
  year = {2012},
  abstract = {Throughout social and cognitive psychology, participants are routinely asked to respond in some way to experimental stimuli that are thought to represent categories of theoretical interest. For instance, in measures of implicit attitudes, participants are primed with pictures of specific African American and White stimulus persons sampled in some way from possible stimuli that might have been used. Yet seldom is the sampling of stimuli taken into account in the analysis of the resulting data, in spite of numerous warnings about the perils of ignoring stimulus variation (Clark, 1973; Kenny, 1985; Wells & Windschitl, 1999). Part of this failure to attend to stimulus variation is due to the demands imposed by traditional analysis of variance procedures for the analysis of data when both participants and stimuli are treated as random factors. In this article, we present a comprehensive solution using mixed models for the analysis of data with crossed random factors (e.g., participants and stimuli). We show the substantial biases inherent in analyses that ignore one or the other of the random factors, and we illustrate the substantial advantages of the mixed models approach with both hypothetical and actual, well-known data sets in social psychology (Bem, 2011; Blair, Chapleau, & Judd, 2005; Correll, Park, Judd, & Wittenbrink, 2002).},
  doi = {doi:10.1037/a0028347}
}


@article{KeepItMaximal,
	Author = {Barr, Dale J and Levy, Roger and Scheepers, Christoph and Tily, Harry J},
	Journal = {Journal of memory and language},
	Month = {04},
	Number = {3},
	Pages = {10.1016/j.jml.2012.11.001},
	Title = {Random effects structure for confirmatory hypothesis testing: Keep it maximal},
	Volume = {68},
	Year = {2013}
}
